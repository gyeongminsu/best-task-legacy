{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yclCebBQFn2I"
   },
   "source": [
    "# CNNbasic Assignment#1\n",
    "\n",
    "\n",
    "마크다운과 코드 속 `???` 를 채워주시면 됩니다!-!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 제출자: 20기 황태연\n",
    "- 제출 일자: 2023.09.05. (화)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet\n",
    "\n",
    "모델 구조 사진과 논문 사이트입니다.\n",
    "\n",
    "- paper: http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf\n",
    "\n",
    "- dataset: http://image-net.org/challenges/LSVRC/2012/index#task\n",
    "\n",
    "- Model architecture\n",
    "\n",
    "<img src=\"01.png\">\n",
    "\n",
    "![model_architecture2](https://t1.daumcdn.net/cfile/tistory/99FEB93C5C80B5192E)\n",
    "\n",
    "- The second convolutional layer takes as input the (response-normalized\n",
    "and pooled) output of the first convolutional layer and filters it with 256 kernels of size 5 × 5 × 48.\n",
    "The third, fourth, and fifth convolutional layers are connected to one another without any intervening\n",
    "pooling or normalization layers. The third convolutional layer has 384 kernels of size 3 × 3 ×\n",
    "256 connected to the (normalized, pooled) outputs of the second convolutional layer. The fourth\n",
    "convolutional layer has 384 kernels of size 3 × 3 × 192 , and the fifth convolutional layer has 256\n",
    "kernels of size 3 × 3 × 192. The fully-connected layers have 4096 neurons each.\n",
    "\n",
    "\n",
    "### Naive Version\n",
    "CONV_1 - POOL_1 - CONV_2 - POOL_2 - CONV_3 - CONV_4 - CONV_5 - POOL_3 - FC1 - FC2 - FC3 (->SOFTMAX)\n",
    "\n",
    "### detailed\n",
    "CONV_1(ReLU) - POOL_1 - CONV_2(ReLU) - POOL_2 - CONV_3(ReLU) - CONV_4(ReLU) - CONV_5(ReLU) - POOL_3 -(Flatten) FC1(ReLU) - FC2(ReLU) - FC3(->SOFTMAX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 논문 리뷰: ImageNet Classification with Deep Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ILSVRC(ImageNet Large Scale Visual Recognition Challenge)**: 이미지 인식 기술을 겨루는 대회\n",
    "    - ILSVRC 2012년 대회에서 딥러닝에 기초한 AlexNet이 압도적으로 우승하면서 이후의 ILSVRC 대회의 주역은 딥러닝이 되었다.\n",
    "    \n",
    "- **이미지넷(ImageNet)**: 100만 장이 넘는 이미지를 담고 있는 데이터셋\n",
    "<img src=\"02.png\" width=70% height=70%>\n",
    "(출처: https://opus.nci.org.au/display/DAE/Introduction+to+ImageNet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ILSVRC 대회에는 ImageNet의 데이터를 사용하는 대회로, 다음과 같은 시험 항목이 있다.  \n",
    "    1. **Image Classification(이미지 분류)**\n",
    "        - 가장 기본적인 시험 항목으로, 많은 연구자들이 참여한다.\n",
    "        - 주어진 이미지를 1000개의 클래스 중 하나로 분류한다.\n",
    "        - 분류 성능은 Top-1 Error와 Top-5 Error로 측정된다.\n",
    "            - Top-1 Error: 모델이 예측한 클래스 중 실제 클래스와 일치하지 않는 것의 비율\n",
    "            - Top-5 Error: 모델이 예측한 상위 5개의 클래스 중 실제 클래스가 포함되지 않은 것의 비율\n",
    "    2. Object Detection(물체 검출)\n",
    "        - 주어진 이미지에서 물체의 위치와 종류를 예측한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. ReLU Nonlinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Saturating nonlinearities**: 비선형 함수 중에서, 입력 값이 크거나 작아질수록 출력 값이 포화(saturation)되는 함수\n",
    "    - 예: sigmoid 함수(입력 값이 작을 때에는 0, 클 때에는 1에 가까워져서 값이 매우 크거나 작을 때에는 포화 상태에 빠져서 출력 값이 거의 변하지 않는다.)\n",
    "- **Non-saturating nonlinearities**: 출력 값이 포화되지 않는 함수\n",
    "    - 예: ReLU 함수\n",
    "- 이 논문에서는 활성화 함수로 ReLU 함수를 사용하는 것이 훨씬 빠른 학습이 가능하다는 것을 보여준다.\n",
    "<center><img src=\"03.png\" width=30% height=30%></center>\n",
    "\n",
    "- 위 그림은 CIFAR-10에 대한 훈련 데이터 오류율이다.\n",
    "- 활성화 함수로 ReLU(실선)를 사용한 것이 tanh(점선)을 사용한 것보다 오류율 25%에 6배 빨리 도달하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Training on Multiple GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AlexNet은 **두 개의 GTX 580 GPU**를 사용해서 학습한다.\n",
    "- 각 GPU는 배치 사이즈의 절반에 해당하는 데이터를 나눠서 학습한다.\n",
    "    - 이에 따라 GPU의 메모리 문제를 해결하고, 학습 시간을 단축할 수 있었다.\n",
    "- **Cross-GPU parallelization**: AlexNet에서는 두 개의 GPU가 각각 학습을 하지만, **3번째 CNN 레이어**에서 **서로 소통**하여 각 GPU에서 계산한 **출력(feature map)을 절반씩 나눠**갖는다. \n",
    "    - Cross-GPU parallelization을 사용하여 top-1 오류율을 1.7%, top-5 오류율을 1.2% 감소시켰다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Local Response Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 활성화 함수 ReLU는 너무 큰 input을 그대로 output으로 반환한다는 특징이 있다.\n",
    "- 이런 큰 값은 Conv 계산이나 Pooling 연산에서 주변 값에 지나친 영향을 줄 가능성이 있다.\n",
    "- 이를 막기 위해 Local Response Normalization을 이용한다.\n",
    "$$b_{x, y}^{i} = a_{x, y}^{i} / \\left( k + \\alpha \\sum_{j = max(0, i-n/2)}^{min(N-1, i+n/2)} (a_{x, y}^{j})^2\\right)^{\\beta}$$\n",
    "\n",
    "($b_{x, y}^{i}$: LRN의 결과, $a_{x, y}^{i}$: 활성화 함수의 output, $i$: 현재 filter,  \n",
    "$N$: filter의 총 개수, $n$: 정규화할 filter 수, $\\alpha, \\beta, k, n$: hyperparameters)\n",
    "\n",
    "- 최근에는 LRN 대신 **Batch Normalization**을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Overlapping Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Overlapping Pooling**: 인접한 Pooling 영역이 중첩되도록 설정하여 사용하는 방법\n",
    "- 기존의 CNN을 사용한 모델의 Pooling layer에서는 영역이 겹치지 않도록 하였다.\n",
    "- 이 논문에서는 Maxpooling을 진행할 때 서로 영역이 겹치도록 **stride: 2, kernel size: 3x3**으로 설정하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Overall Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GPU 2개를 이용하는 AlexNet의 구조\n",
    "<center><img src=\"04.png\" width=70% height=70%></center>\n",
    "\n",
    "- **주의!**: AlexNet과 관련된 여러 자료들이 input이 224 x 224 x 3이 아니라 **227 x 227 x 3**이 올바르다고 언급했다. 실제로 후자가 수학적으로 올바르다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Reducing Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 첫 번째 데이터 증강 방법: **수평 반전** & **crop**\n",
    "<center><img src=\"05.png\" width=50% height=50%></center>\n",
    "\n",
    "- 1) 먼저 모든 이미지를 256x256으로 resize한다.\n",
    "- 2) 수평 반전으로 이미지를 2배 증강한다.\n",
    "- 3) 224x224로 random crop하여 32x32배 증강한다.\n",
    "- 이렇게 총 이미지를 **2048배 증강**할 수 있다.\n",
    "- 단, 추론 시에는 수평 반전과 네 모서리 및 중앙 crop으로 10개의 이미지를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 두 번째 데이터 증강 방법: **Fancy PCA**\n",
    "- **PCA(Principal Component Analysis)**: 데이터의 주성분(principal component)을 찾아내어 데이터의 차원을 축소하는 기술\n",
    "    - 1) 공분산 행렬 구하기\n",
    "    - 2) 고유값 분해 (고유값과 고유벡터를 각각 구한다.)\n",
    "    - 3) 주성분 선택 (상위 k개의 고유값에 대한 고유벡터들로 데이터의 차원을 축소할 수 있다.)\n",
    "- **Fancy PCA**: 이미지의 RGB 값에 PCA와 가우시안 랜덤 변수를 적용하여 이미지를 증강하는 기법\n",
    "<center><img src=\"06.png\" width=70% height=70%></center>\n",
    "\n",
    "- Fancy PCA는 자연스러운 반면, Random Augmentation은 색에 대한 왜곡이 발생한다.\n",
    "\n",
    "- 식은 다음과 같다.\n",
    "\n",
    "$$I'_{xy} = [I_{xy}^{R}, I_{xy}^{G}, I_{xy}^{B}]^T + [\\mathbf{p}_{1}, \\mathbf{p}_{2}, \\mathbf{p}_{3}][\\alpha_{1} \\lambda_{1}, \\alpha_{2} \\lambda_{2}, \\alpha_{3} \\lambda_{3}]^{T}$$\n",
    "\n",
    "($I'_{xy}$: Fancy PCA로 생성된 이미지의 $xy$위치의 RGB값,  \n",
    "\n",
    "$I_{xy}$: 원본 이미지의 $xy$위치의 RGB값,  \n",
    "\n",
    "$\\mathbf{p}_{i}$: 3x3 공분산 행렬의 고유벡터,\n",
    "\n",
    "$\\lambda_{i}$: 3x3 공분산 행렬의 고유값,\n",
    "\n",
    "$\\alpha_{i}$: 평균이 0, 표준편차가 0.1인 가우시안 랜덤 변수)\n",
    "\n",
    "- 이 기술이 top-1 오류율을 1% 이상 감소시켰다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dropout는 앞의 노드와 그와 연결된 가중치를 제거하는 방식으로 작동한다.\n",
    "- AlexNet에서는 첫 번째와 두 번째 FC 앞에서 Dropout을 적용하여 과적합을 방지했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고 자료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. AlexNet 논문: https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf\n",
    "2. AlexNet Wikipedia: https://en.wikipedia.org/wiki/AlexNet\n",
    "3. https://killerwhale0917.tistory.com/14\n",
    "4. https://taeguu.tistory.com/29\n",
    "5. https://daeun-computer-uneasy.tistory.com/33\n",
    "6. Data Augmentation: https://learnopencv.com/understanding-alexnet/\n",
    "7. Fancy PCA: https://pixelatedbrian.github.io/2018-04-29-fancy_pca/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정확한 AlexNet의 Layer를 보여주는 그림은 다음과 같다.\n",
    "<img src=\"07.png\" width=70% height=70%>\n",
    "(출처: https://medium.com/analytics-vidhya/concept-of-alexnet-convolutional-neural-network-6e73b4f9ee30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다음 식을 이용해서 **convolution layer의 output size**를 계산한다.\n",
    "$$\n",
    "OW = \\frac{W+2P-FW}{S} + 1\n",
    "$$\n",
    "($OW$: Output Width, $W$: Width, $P$: Padding, $FW$: Filter Width, $S$: Stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다음 식을 이용해서 **convolution layer의 parameter 수**를 계산할 수 있다.\n",
    "\n",
    "$$\n",
    "(K \\times C_{input} + B) \\times C_{output}\n",
    "$$\n",
    "($K$: kernel size, $C$: number of channel, $B$: bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다음 함수는 **Convolution layer**의 output_size와 parameter 수를 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2d(input_size, num_filters, filter_size, stride, padding):\n",
    "    I = input_size # ex: (227, 227, 3)\n",
    "    N = num_filters # ex: 96\n",
    "    F = filter_size # ex: (11, 11)\n",
    "    S = stride # ex: 4\n",
    "    P = padding # ex: 0\n",
    "    \n",
    "    # output_size\n",
    "    I_width = int(I[0])\n",
    "    O_width = int((I_width + 2*P - F[0]) / S) + 1\n",
    "    output_size = (O_width, O_width, N) # (output_width, output_width, output_channel), output_channel = num_of_filters\n",
    "    \n",
    "    # num_of_parameters\n",
    "    I_channel = I[2]\n",
    "    num_parameters = (F[0]*F[1] * I_channel + 1) * N\n",
    "    \n",
    "    print('Output Size:',output_size)\n",
    "    print('Number of Parameters:', num_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Pooling Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다음 식을 이용해서 **max pooling layer의 output_size**를 계산한다.\n",
    "$$\n",
    "OW = \\frac{W - FW}{S} + 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다음 함수는 Max pooling의 output_size를 출력한다. max pooling layer에서는 학습하는 파라미터가 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaxPool2d(input_size, filter_size, stride):\n",
    "    I = input_size # ex: (55, 55, 96)\n",
    "    F = filter_size # ex: (3, 3)\n",
    "    S = stride # ex: 2\n",
    "    \n",
    "    I_width = int(I[0])\n",
    "    O_width = int((I_width - F[0]) / S) + 1\n",
    "    output_size = (O_width, O_width, I[2])\n",
    "    \n",
    "    print('Output Size:', output_size)\n",
    "    print('Number of Parameters:', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다음 식을 이용하여 **fully connected layer의 parameter 수**를 계산할 수 있다.\n",
    "$$\n",
    "(I + 1) \\times O\n",
    "$$\n",
    "($I$: Input size, $O$: Output size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다음 함수는 **fully connected layer**의 parameter 수를 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Linear(input_size, output_size):\n",
    "    num_parameters = (input_size + 1) * output_size\n",
    "    print('Number of Parameters:', num_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "exDZxL9QFn2L"
   },
   "source": [
    "## Layer 1 is a Convolution Layer_1\n",
    "\n",
    "- **Input Image size**     `(227, 227, 3)`\n",
    "\n",
    "- **Number of filters**     `96`\n",
    "\n",
    "- **Filter size**     `(11, 11)`\n",
    "\n",
    "- **Stride**     `4`\n",
    "\n",
    "- **Layer 1 Output**     `(55, 55, 96)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Size: (55, 55, 96)\n",
      "Number of Parameters: 34944\n"
     ]
    }
   ],
   "source": [
    "## TODO ##\n",
    "\n",
    "######################################################\n",
    "#  Calculate the number of parameters in this layer  #\n",
    "######################################################\n",
    "\n",
    "Conv_1 = Conv2d((227, 227, 3), 96, (11, 11), 4, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XvlIbO-uFn2V"
   },
   "source": [
    "## Layer 2 is a Max Pooling_1 Followed by Convolution_1\n",
    "\n",
    "- **Input**     `(54, 54, 96)`\n",
    "\n",
    "- **Max pooling**     `(3, 3)`  \n",
    "\n",
    "- **Pooling size** (overlapping)      `1` (filter size가 3x3이고 stride가 2이면 겹치는 구간의 너비는 1이다.)\n",
    "\n",
    "    * overlapping 중첩되어서 지나감\n",
    "\n",
    "- **Stride**     `2`\n",
    "\n",
    "- **Layer 2 Output**     `(27, 27, 96)`\n",
    "    \n",
    "    * 차원은 변함 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Size: (27, 27, 96)\n",
      "Number of Parameters: 0\n"
     ]
    }
   ],
   "source": [
    "## TODO \n",
    "\n",
    "######################################################\n",
    "#  Calculate the number of parameters in this layer  #\n",
    "######################################################\n",
    "\n",
    "Max_pool_1 = MaxPool2d((55, 55, 96), (3, 3), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r70OGeViFn2Z"
   },
   "source": [
    "## Layer 3 is a Convolution Layer_2\n",
    "\n",
    "- **Input**     `(27, 27, 96)`\n",
    "\n",
    "- **Number of filters**     `256`\n",
    "\n",
    "- **Filter size**     `(5, 5)`\n",
    "\n",
    "- **Stride**     `1`\n",
    "\n",
    "- **padding**     `2`\n",
    "\n",
    "- **Layer 3 Output**     `(27, 27, 256)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Size: (27, 27, 256)\n",
      "Number of Parameters: 614656\n"
     ]
    }
   ],
   "source": [
    "## TODO \n",
    "\n",
    "######################################################\n",
    "#  Calculate the number of parameters in this layer  #\n",
    "######################################################\n",
    "\n",
    "Conv_2 = Conv2d((27, 27, 96), 256, (5, 5), 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DQZhwY4eFn2e"
   },
   "source": [
    "## Layer 4 is a Max Pooling_2 Followed by Convolution_2\n",
    "\n",
    "- **Input**     `(27, 27, 256)`\n",
    "\n",
    "- **Max pooling**     `(3, 3)`  \n",
    "\n",
    "- **Pooling size**(overlapping)     `1`\n",
    "\n",
    "- **Stride**     `2`\n",
    "\n",
    "- **Layer 4 Output**     `(13, 13, 256)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Size: (13, 13, 256)\n",
      "Number of Parameters: 0\n"
     ]
    }
   ],
   "source": [
    "## TODO \n",
    "\n",
    "######################################################\n",
    "#  Calculate the number of parameters in this layer  #\n",
    "######################################################\n",
    "\n",
    "Max_pool_2 = MaxPool2d((27, 27, 256), (3, 3), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xPm4PRFAFn2i"
   },
   "source": [
    "## Layer 5 is a Convolution Layer_3\n",
    "\n",
    "- **Input**     `(13, 13, 256)`\n",
    "\n",
    "- **Number of filters**     `384`\n",
    "\n",
    "- **Filter size**     `(3, 3)`\n",
    "\n",
    "- **Stride**     `1`\n",
    "\n",
    "- **padding**     `1`\n",
    "\n",
    "- **Layer 5 Output**     `(13, 13, 384)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Size: (13, 13, 384)\n",
      "Number of Parameters: 885120\n"
     ]
    }
   ],
   "source": [
    "## TODO \n",
    "\n",
    "######################################################\n",
    "#  Calculate the number of parameters in this layer  #\n",
    "######################################################\n",
    "\n",
    "Conv_3 = Conv2d((13, 13, 256), 384, (3, 3), 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yv57b2vxFn2o"
   },
   "source": [
    "## Layer 6 is  a Convolution Layer_4\n",
    "\n",
    "- **Input**     `(13, 13, 384)`\n",
    "\n",
    "- **Number of filters**     `384`\n",
    "\n",
    "- **Filter size**     `(3, 3)`\n",
    "\n",
    "- **Stride**     `1`\n",
    "\n",
    "- **padding**     `1`\n",
    "\n",
    "- **Layer 6 Output**     `(13, 13, 384)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Size: (13, 13, 384)\n",
      "Number of Parameters: 1327488\n"
     ]
    }
   ],
   "source": [
    "## TODO \n",
    "\n",
    "######################################################\n",
    "#  Calculate the number of parameters in this layer  #\n",
    "######################################################\n",
    "\n",
    "Conv_4 = Conv2d((13, 13, 384), 384, (3, 3), 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NiQL84J_Fn2s"
   },
   "source": [
    "## Layer 7 is a Convolution Layer_5\n",
    "\n",
    "- **Input**     `(13, 13, 384)`\n",
    "\n",
    "- **Number of filters**     `256`\n",
    "\n",
    "- **Filter size**     `(3, 3)`\n",
    "\n",
    "- **Stride**     `1`\n",
    "\n",
    "- **padding**     `1`\n",
    "\n",
    "- **Layer 7 Output**     `(13, 13, 256)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Size: (13, 13, 256)\n",
      "Number of Parameters: 884992\n"
     ]
    }
   ],
   "source": [
    "## TODO \n",
    "\n",
    "######################################################\n",
    "#  Calculate the number of parameters in this layer  #\n",
    "######################################################\n",
    "\n",
    "Conv_5 = Conv2d((13, 13, 384), 256, (3, 3), 1, 1)\n",
    "Conv_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WSTe-0IxFn2w"
   },
   "source": [
    "## Layer 8 is a Max Pooling_3 Followed by Convolution_5\n",
    "\n",
    "- **Input**     `(13, 13, 256)`\n",
    "\n",
    "- **Max pooling**     `(3, 3)`  \n",
    "\n",
    "- **Pooling size**(overlapping)     `1`\n",
    "\n",
    "- **Stride**     `2`\n",
    "\n",
    "- **Layer 8 Output**     `(6, 6, 256)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Size: (6, 6, 256)\n",
      "Number of Parameters: 0\n"
     ]
    }
   ],
   "source": [
    "## TODO \n",
    "\n",
    "######################################################\n",
    "#  Calculate the number of parameters in this layer  #\n",
    "######################################################\n",
    "\n",
    "Max_pool_3 = MaxPool2d((13, 13, 256), (3, 3), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "798N3vBYFn21"
   },
   "source": [
    "## Layer 9 is a Fully_Connected layer_1\n",
    "\n",
    "- **input**     `(6, 6, 256)`\n",
    "\n",
    "- **flatten**     `6*6*256 = 9216`\n",
    "\n",
    "- **output size**     `4096`\n",
    "\n",
    "- **N** Number of input data      `9216`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Parameters: 37752832\n"
     ]
    }
   ],
   "source": [
    "## TODO \n",
    "\n",
    "######################################################\n",
    "#  Calculate the number of parameters in this layer  #\n",
    "######################################################\n",
    "\n",
    "FC1 = Linear(6*6*256, 4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kIfvpHPTFn25"
   },
   "source": [
    "## Layer 10 is a Fully_Connected layer_2\n",
    "\n",
    "- **input**     `4096`\n",
    "\n",
    "- **output size**     `4096`\n",
    "\n",
    "- **N** Number of input data =      `4096`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Parameters: 16781312\n"
     ]
    }
   ],
   "source": [
    "## TODO \n",
    "\n",
    "######################################################\n",
    "#  Calculate the number of parameters in this layer  #\n",
    "######################################################\n",
    "\n",
    "FC2 = Linear(4096, 4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N8TaZQTBFn29"
   },
   "source": [
    "## Layer 11 is a Fully_Connected layer_3\n",
    "\n",
    "- **input**     `4096`\n",
    "\n",
    "- **output size**     `1000`\n",
    "\n",
    "- **N** Number of input data =      `4096`\n",
    "\n",
    "- **Num_classes** Number of labels =      `1000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Parameters: 4097000\n"
     ]
    }
   ],
   "source": [
    "## TODO \n",
    "\n",
    "######################################################\n",
    "#  Calculate the number of parameters in this layer  #\n",
    "######################################################\n",
    "\n",
    "FC3 = Linear(4096, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNbasic Assignment#2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 제출자: 20기 황태연\n",
    "- 제출 일자: 2023.09.05. (화)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet 구현\n",
    "\n",
    "모델 구현 후 summary로 전체 모델 구조 출력과 주석으로 간단한 설명을 달아주시면 됩니다.\n",
    "\n",
    "프레임워크는 자유이고, 기본 tensforflow와 pytorch tutorial 사이트를 아래에 첨부해 드립니다.\n",
    "\n",
    "이 외 각 프레임워크 별 summary 등 추가적인 사용 방법은 구글링으로 찾아주세요!-!\n",
    "\n",
    "- Tensorflow Tutorial: https://www.tensorflow.org/tutorials?hl=ko\n",
    "\n",
    "- Pytorch Tutorial: https://tutorials.pytorch.kr/\n",
    "\n",
    "<img src=\"01.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 아래에서 구현할 모델을 다음 그림이 가장 잘 표현하고 있습니다.\n",
    "<img src=\"07.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AlexNet에는 Dropout이 구현되어 있지만, 과제에서 제시한 모델 구조에 맞도록 구현하기 위해 Dropout을 추가하지 않겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "urleB2cT-c0i"
   },
   "source": [
    "## Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 96, 55, 55]          34,944\n",
      "              ReLU-2           [-1, 96, 55, 55]               0\n",
      "         MaxPool2d-3           [-1, 96, 27, 27]               0\n",
      "            Conv2d-4          [-1, 256, 27, 27]         614,656\n",
      "              ReLU-5          [-1, 256, 27, 27]               0\n",
      "         MaxPool2d-6          [-1, 256, 13, 13]               0\n",
      "            Conv2d-7          [-1, 384, 13, 13]         885,120\n",
      "              ReLU-8          [-1, 384, 13, 13]               0\n",
      "            Conv2d-9          [-1, 384, 13, 13]       1,327,488\n",
      "             ReLU-10          [-1, 384, 13, 13]               0\n",
      "           Conv2d-11          [-1, 256, 13, 13]         884,992\n",
      "             ReLU-12          [-1, 256, 13, 13]               0\n",
      "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
      "           Linear-14                 [-1, 4096]      37,752,832\n",
      "             ReLU-15                 [-1, 4096]               0\n",
      "           Linear-16                 [-1, 4096]      16,781,312\n",
      "             ReLU-17                 [-1, 4096]               0\n",
      "           Linear-18                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 62,378,344\n",
      "Trainable params: 62,378,344\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.59\n",
      "Forward/backward pass size (MB): 10.99\n",
      "Params size (MB): 237.95\n",
      "Estimated Total Size (MB): 249.53\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "# device 설정 (cuda or cpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2))\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2))\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2))\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(6*6*256, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc3 = nn.Linear(4096, 1000)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# pytorch summary\n",
    "model = AlexNet(1000).to(device)\n",
    "summary(model, (3, 227, 227))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_assignment1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
