################랜덤포레스트 과제################
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import load_breast_cancer
import numpy as np
import pandas as pd
from sklearn import metrics
load_breast_cancer()
cancer = load_breast_cancer()
dat = pd.concat([pd.DataFrame(cancer.data, columns= cancer.feature_names),
        pd.DataFrame(cancer.target, columns=["is_cancer"])], axis=1)
 
test, train = train_test_split(dat, test_size = 0.7, random_state = 930904)
test.shape
# (170, 31)
train.shape
# (399, 31)
 
def my_rf(train, test, n_estimators, max_features):
    result = []
    col = train.columns
    compare = np.zeros((n_estimators, len(test))) # 트리들의 예측값들을 모아 vote(이자 비교)하기 위해 만든 임시 array
    for i in range(n_estimators):
        select = np.random.choice(col[:-1], max_features, replace=False)
        # 비복원 추출로 변수 뽑기
        tree = DecisionTreeClassifier()
        tree.fit(X=train[select], y=train[col[-1]])
        pred = tree.predict(X=test[select])
        # n_estimators 수만큼 트리모델(일부 변수만을 뽑은)을 생성하고 test set의 모든 관측치들에 대해 예측
        compare[i] = pred
    compare = pd.DataFrame(compare) # 밑의 코드를 실행하기 위해서는 데이터프레임화를 할 필요가 있습니다.
    for j in range(len(test)):
        result.append(compare[j].value_counts().index[0])
        # 각 트리들의 예측값들을 데이터프레임의 열마다 vote해 다수결 결과값을 예측결과 리스트에 저장
    return(result)
 
my_pred = my_rf(train, test, 10, 6)
my_pred
#[1.0, 0.0, 0.0, 1.0, 1.0,  0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, ..., 0.0]
print(metrics.classification_report(my_pred, test['is_cancer']))
#             precision    recall  f1-score   support
 
#        0.0       0.85      0.98      0.91        59
#        1.0       0.99      0.91      0.95       111
 
#avg / total       0.94      0.94      0.94       170
 
#RandomForestClassifier 모듈과 거의 흡사한 결과를 보입니다!
