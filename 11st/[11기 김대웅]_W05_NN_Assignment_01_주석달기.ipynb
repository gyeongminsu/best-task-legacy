{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToBig's_11th_W05_Neural_Network_실습\n",
    "## Assignment_01 : 주석달기\n",
    "### 11기 김대웅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행렬 X에 가중치 벡터 W를 내적해 Hidden layer H 생성\n",
    "# <=> H = w_1 * x_1 + w_2 * x_2 + ... + w_d * x_d\n",
    "def linear(X, W):\n",
    "    H = np.dot(X, W)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation function : 시그모이드 함수\n",
    "def sigmoid(H):\n",
    "    p = 1 / (1 + np.exp(-H))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 Feature는 1 X 2 행렬\n",
    "X = np.array([1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#가중치 행렬 W는 1 X 2 행렬\n",
    "W = np.array([2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "0.9996646498695336\n"
     ]
    }
   ],
   "source": [
    "# 입력 Feature x_i에 각각 가중치 w_i를 곱하여 Hidden layer H 계산 (1 * 1)\n",
    "# H값이 양수일 경우. Sigmoid는 1에 가까운 값\n",
    "H = linear(X, W)\n",
    "print(H)\n",
    "# H에 activation function : sigmoid\n",
    "p = sigmoid(H)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.array([-4, -3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10\n",
      "4.5397868702434395e-05\n"
     ]
    }
   ],
   "source": [
    "# H값이 음수일 경우, Sigmoid는 0에 가까운 값\n",
    "H = linear(X, W)\n",
    "print(H)\n",
    "p = sigmoid(H)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iris 자료 load\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[\"data\"]\n",
    "y = data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X (150, 4)\n",
    "x[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y (150, )\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        # Parameter 저장할 Dict\n",
    "        self.params = {}\n",
    "        # 임의 가중치 행렬 W (4 x 3) (Hidden layer의 Node 수 : 3개)\n",
    "        self.params['W'] = 0.0001 * np.random.randn(4, 3)\n",
    "        # Bias 항으로 초기값 1을 부여함. \n",
    "        # WX가 (150 X 3) 행렬이므로 각 bias의 개수는 hidden layer의 Node 수(3)와 동일 \n",
    "        self.params['b'] = np.ones(3)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # parameter dict에서 Weight와 Bias를 가져와 local variable W와 b에 할당\n",
    "        W = self.params['W']\n",
    "        b = self.params['b']\n",
    "\n",
    "        # Hidden layer = Weight * Features  + Bias // H = XW + b\n",
    "        # H : (150, 3)\n",
    "        h = np.dot(X, W) + b\n",
    "        # Softmax probability 계산을 위해 지수함수 변환 : exp(H)\n",
    "        # A : (150, 3)\n",
    "        a = np.exp(h)\n",
    "        # stable_a = np.exp(h - np.max(h, axis = 1).reshape(-1,1))\n",
    "        # 각각의 probability.\n",
    "        # P : (150, 3)\n",
    "        p = a/np.sum(a, axis = 1, keepdims=True)\n",
    "        # cf. keepdims = True : a의 원래 형태 유지. (열벡터)\n",
    "        return p\n",
    "    \n",
    "    # Softmax-with-loss Node\n",
    "    def loss(self, X, T):\n",
    "        # 예측확률 p를 계산\n",
    "        p = self.forward(X)\n",
    "        # 전체 자료 길이 n \n",
    "        n = T.shape[0]\n",
    "        \n",
    "        # Cross Entropy 오차의 계산 \n",
    "    \n",
    "        # Error = -log(정답 label의 Softmax probability)의 총 합계\n",
    "        # log내에 들어가는 확률값이 1에 가까울수록 -log변환의 값은 작다.\n",
    "        # 즉 정답레이블에 대해 정답으로 예측할 확률이 클수록(1에 가까울수록)\n",
    "        # -log(Softmax probability)는 0에 가깝기 때문에 이렇게 설정\n",
    "        \n",
    "        log_likelihood = 0\n",
    "        log_likelihood -= np.log(p[np.arange(n), T]).sum()\n",
    "        # loss를 Sample Size N으로 나눔 (개별 자료에 대한 loss를 나타내기 위해)\n",
    "        Loss = log_likelihood / n\n",
    "\n",
    "        return Loss\n",
    "    \n",
    "    def accuracy(self, X, T):\n",
    "        p = self.forward(X) # Softmax prob : P (150, 3)\n",
    "        # predict (150, 1) : 분류 결과 : 가장 큰 확률값을 가지는 index\n",
    "        predict = np.argmax(p, axis = 1) #예측 결과 index 1darray 로 출력 \n",
    "        \n",
    "        # 정분류율(Accuracy) = 1 - (오분류율)\n",
    "        return 1 - np.count_nonzero(predict - T)/len(T)\n",
    "        \n",
    "    def gradient(self, X, T, learning_rate = 0.0001):\n",
    "        # Softmax prob 계산 p에 할당\n",
    "        p = self.forward(X)\n",
    "\n",
    "        # Softmax-Loss Node의 입력값(H) 각각의 Loss에 대한 Gradient\n",
    "        # (H : 150, 3)\n",
    "        # (P : 150, 3)\n",
    "        # dp (150, 3) : derivate of Loss w.r.t. h_i ( i = 1, 2, ... , 150 )\n",
    "        dp = p.copy()\n",
    "        dp[np.arange(len(T)), T] -= 1\n",
    "        \n",
    "        # Softmax-loss의 입력단 : h_1, h_2, h_3 각각의 Gradient를 구합니다.\n",
    "        # 이 때 각 자료에 대해서 Gradient값이 구해지며, update를 위해선 150개 자료의 각 Gradient의 평균값을 사용합니다.\n",
    "        # 각 Gradient의 평균값을 구하기 위해 batch size로 나눠줍니다(뒤에서 총합을 내어 mean이 됨)\n",
    "        # cf. 여기서는 전체 자료를 사용하기 때문에 batch size = 150. SGD의 mini bath의 경우 mini batch size로 나누어줌\n",
    "        \n",
    "        dp /= len(T)\n",
    "        \n",
    "        #목적함수에 대한 가중치 미분값을 담을 zero array 생성\n",
    "        grads = {}\n",
    "        \n",
    "        #목적함수에 대한 가중치 미분값 합 구하기\n",
    "        # {partial L} over {partial W} = [X^T]product dot[{partial L} over {partial H}]\n",
    "        # X : (150, 4), dp : (150, 3)\n",
    "        # grads[\"W\"] : (4, 3)\n",
    "        #     row : input feature 4\n",
    "        #     col : Softmax-loss node input 3\n",
    "        \n",
    "        grads['W'] = np.dot(X.T, dp)\n",
    "        # {partial L} over {partial b} = 1 * [{partial L} over {partial H} = dp]\n",
    "        # grads[\"b\"] : (1, 3)\n",
    "        grads['b'] = np.sum(dp, axis = 0)\n",
    "        #p-t 대신 dp 사용 가능\n",
    "        \n",
    "        # parameter update \n",
    "        self.params['W'] -= learning_rate * grads['W']\n",
    "        self.params['b'] -= learning_rate * grads['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 학습중입니다.\n",
      "Accuracy :  0.33333333333333337\n",
      "Loss :      1.0987191201522015\n",
      "[[ 4.71958896e-05  4.22167250e-05 -2.19067037e-04]\n",
      " [-2.01014883e-04 -4.52424608e-05 -9.59231972e-05]\n",
      " [ 1.26014621e-04  1.63714011e-04  1.26605259e-04]\n",
      " [ 1.20505533e-04 -1.07729572e-05  3.49531937e-05]]\n",
      "1000 번째 학습중입니다.\n",
      "Accuracy :  0.33999999999999997\n",
      "Loss :      1.0202038815448475\n",
      "[[-0.00317786  0.00063262  0.00241559]\n",
      " [ 0.02382499 -0.0107081  -0.01345908]\n",
      " [-0.05771192  0.01480966  0.04331859]\n",
      " [-0.02531247  0.00348564  0.02197151]]\n",
      "2000 번째 학습중입니다.\n",
      "Accuracy :  0.6666666666666667\n",
      "Loss :      0.9647084317168441\n",
      "[[ 0.00863864 -0.00038477 -0.00838352]\n",
      " [ 0.05390199 -0.02184066 -0.03240351]\n",
      " [-0.10180242  0.02763717  0.07458158]\n",
      " [-0.04582038  0.00630861  0.03965645]]\n",
      "3000 번째 학습중입니다.\n",
      "Accuracy :  0.6666666666666667\n",
      "Loss :      0.9164501352728479\n",
      "[[ 0.02158507 -0.00161939 -0.02009533]\n",
      " [ 0.08303009 -0.03268098 -0.0506913 ]\n",
      " [-0.14174623  0.03947414  0.10268843]\n",
      " [-0.06455972  0.00871589  0.05598851]]\n",
      "4000 번째 학습중입니다.\n",
      "Accuracy :  0.6666666666666667\n",
      "Loss :      0.8742632140637108\n",
      "[[ 0.03373164 -0.00257516 -0.03128614]\n",
      " [ 0.11030433 -0.04295052 -0.06769599]\n",
      " [-0.17902846  0.05060488  0.12883991]\n",
      " [-0.08203859  0.01079531  0.07138797]]\n",
      "5000 번째 학습중입니다.\n",
      "Accuracy :  0.6666666666666667\n",
      "Loss :      0.8373072649312102\n",
      "[[ 0.04487407 -0.00316372 -0.04184   ]\n",
      " [ 0.13571959 -0.05260229 -0.08345949]\n",
      " [-0.21401289  0.06108979  0.15333943]\n",
      " [-0.09840465  0.01256778  0.08598155]]\n",
      "6000 번째 학습중입니다.\n",
      "Accuracy :  0.6666666666666667\n",
      "Loss :      0.8048282376261181\n",
      "[[ 0.055084   -0.00340759 -0.05180607]\n",
      " [ 0.15941936 -0.06165844 -0.0981031 ]\n",
      " [-0.24689277  0.07094103  0.17636806]\n",
      " [-0.11375152  0.01404146  0.09985475]]\n",
      "7000 번째 학습중입니다.\n",
      "Accuracy :  0.6666666666666667\n",
      "Loss :      0.7761658628062562\n",
      "[[ 0.06446909 -0.00334854 -0.0612502 ]\n",
      " [ 0.18156506 -0.07015801 -0.11174923]\n",
      " [-0.2778347   0.08017224  0.19807879]\n",
      " [-0.12816359  0.0152265   0.11308177]]\n",
      "8000 번째 학습중입니다.\n",
      "Accuracy :  0.6666666666666667\n",
      "Loss :      0.7507534565425263\n",
      "[[ 0.0731311  -0.00302702 -0.07023373]\n",
      " [ 0.20231024 -0.07814315 -0.12450926]\n",
      " [-0.30699729  0.08880539  0.21860823]\n",
      " [-0.14172091  0.0161365   0.1257291 ]]\n",
      "9000 번째 학습중입니다.\n",
      "Accuracy :  0.6666666666666667\n",
      "Loss :      0.7281107187133207\n",
      "[[ 0.08115934 -0.0024784  -0.07881059]\n",
      " [ 0.2217949  -0.08565508 -0.136482  ]\n",
      " [-0.33453084  0.09686886  0.23807831]\n",
      " [-0.15449864  0.01678734  0.13785598]]\n",
      "10000 번째 학습중입니다.\n",
      "Accuracy :  0.6799999999999999\n",
      "Loss :      0.707833528326286\n",
      "[[ 0.08863073 -0.00173288 -0.0870275 ]\n",
      " [ 0.24014464 -0.09273267 -0.14775414]\n",
      " [-0.36057541  0.10439465  0.2565971 ]\n",
      " [-0.1665662   0.017196    0.14951488]]\n",
      "11000 번째 학습중입니다.\n",
      "Accuracy :  0.6799999999999999\n",
      "Loss :      0.6895830951760701\n",
      "[[ 0.09561124 -0.00081609 -0.09492481]\n",
      " [ 0.25747114 -0.0994119  -0.15840143]\n",
      " [-0.38525975  0.11141618  0.27425991]\n",
      " [-0.17798693  0.01737963  0.16075198]]\n",
      "12000 번째 학습중입니다.\n",
      "Accuracy :  0.6799999999999999\n",
      "Loss :      0.6730756978092477\n",
      "[[ 1.02157397e-01  2.50199312e-04 -1.02537251e-01]\n",
      " [ 2.73873383e-01 -1.05725675e-01 -1.68489889e-01]\n",
      " [-4.08701065e-01  1.17966850e-01  2.91150549e-01]\n",
      " [-1.88818139e-01  1.73549915e-02  1.71607833e-01]]\n",
      "13000 번째 학습중입니다.\n",
      "Accuracy :  0.6799999999999999\n",
      "Loss :      0.6580735534247617\n",
      "[[ 0.10831773  0.00144743 -0.10989481]\n",
      " [ 0.28943883 -0.11170395 -0.17807707]\n",
      " [-0.43100539  0.12407906  0.30734266]\n",
      " [-0.19911144  0.01713808  0.18211805]]\n",
      "14000 번째 학습중입니다.\n",
      "Accuracy :  0.7\n",
      "Loss :      0.6443769797432279\n",
      "[[ 0.114134    0.00275975 -0.1170234 ]\n",
      " [ 0.30424482 -0.11737382 -0.18721317]\n",
      " [-0.45226828  0.12978366  0.32290095]\n",
      " [-0.20891315  0.01674396  0.19231387]]\n",
      "15000 번째 학습중입니다.\n",
      "Accuracy :  0.7066666666666667\n",
      "Loss :      0.6318178101435428\n",
      "[[ 0.11964229  0.0041735  -0.12394545]\n",
      " [ 0.3183597  -0.1227598  -0.19594209]\n",
      " [-0.47257569  0.13510964  0.33788238]\n",
      " [-0.21826475  0.01618664  0.2022228 ]]\n",
      "16000 번째 학습중입니다.\n",
      "Accuracy :  0.7333333333333334\n",
      "Loss :      0.6202539339796078\n",
      "[[ 0.12487386  0.00567693 -0.13068044]\n",
      " [ 0.33184405 -0.12788398 -0.20430225]\n",
      " [-0.49200485  0.14008403  0.35233716]\n",
      " [-0.22720342  0.01547908  0.21186903]]\n",
      "17000 번째 학습중입니다.\n",
      "Accuracy :  0.76\n",
      "Loss :      0.6095648045606545\n",
      "[[ 0.1298559   0.0072598  -0.13724535]\n",
      " [ 0.34475158 -0.13276632 -0.21232744]\n",
      " [-0.51062516  0.14473183  0.36630966]\n",
      " [-0.23576248  0.01463321  0.22127396]]\n",
      "18000 번째 학습중입니다.\n",
      "Accuracy :  0.76\n",
      "Loss :      0.5996477583092449\n",
      "[[ 0.13461216  0.00891321 -0.14365502]\n",
      " [ 0.35713006 -0.13742485 -0.22004739]\n",
      " [-0.52849904  0.14907615  0.37983923]\n",
      " [-0.2439718   0.01365997  0.23045652]]\n",
      "19000 번째 학습중입니다.\n",
      "Accuracy :  0.78\n",
      "Loss :      0.5904150034077227\n",
      "[[ 0.13916347  0.01062936 -0.14992248]\n",
      " [ 0.36902208 -0.14187586 -0.2274884 ]\n",
      " [-0.5456827   0.15313822  0.39296081]\n",
      " [-0.25185824  0.01256939  0.23943354]]\n",
      "20000 번째 학습중입니다.\n",
      "Accuracy :  0.7866666666666666\n",
      "Loss :      0.5817911558447363\n",
      "[[ 0.14352813  0.01240141 -0.15605919]\n",
      " [ 0.3804657  -0.1461341  -0.23467378]\n",
      " [-0.56222681  0.15693758  0.40570556]\n",
      " [-0.25944594  0.01137063  0.24822   ]]\n",
      "21000 번째 학습중입니다.\n",
      "Accuracy :  0.8\n",
      "Loss :      0.5737112206718602\n",
      "[[ 0.14772233  0.01422328 -0.16207526]\n",
      " [ 0.391495   -0.15021293 -0.24162424]\n",
      " [-0.57817714  0.16049216  0.41810131]\n",
      " [-0.26675669  0.01007209  0.25682929]]\n",
      "22000 번째 학습중입니다.\n",
      "Accuracy :  0.8\n",
      "Loss :      0.566118934433708\n",
      "[[ 0.15176039  0.01608963 -0.16797968]\n",
      " [ 0.4021406  -0.1541245  -0.24835828]\n",
      " [-0.59357512  0.16381841  0.43017305]\n",
      " [-0.27381015  0.00868143  0.26527341]]\n",
      "23000 번째 학습중입니다.\n",
      "Accuracy :  0.8066666666666666\n",
      "Loss :      0.5589654004053126\n",
      "[[ 0.15565506  0.01799568 -0.1737804 ]\n",
      " [ 0.41243008 -0.15787983 -0.25489244]\n",
      " [-0.60845832  0.16693144  0.44194321]\n",
      " [-0.28062414  0.00720568  0.27356315]]\n",
      "24000 번째 학습중입니다.\n",
      "Accuracy :  0.8133333333333334\n",
      "Loss :      0.5522079613718698\n",
      "[[ 0.15941771  0.01993719 -0.17948455]\n",
      " [ 0.42238835 -0.16148899 -0.26124154]\n",
      " [-0.62286085  0.16984515  0.45343203]\n",
      " [-0.2872148   0.00565126  0.28170822]]\n",
      "25000 번째 학습중입니다.\n",
      "Accuracy :  0.8200000000000001\n",
      "Loss :      0.5458092654281474\n",
      "[[ 0.16305849  0.02191035 -0.1850985 ]\n",
      " [ 0.43203793 -0.16496117 -0.26741895]\n",
      " [-0.63681378  0.17257231  0.4646578 ]\n",
      " [-0.29359681  0.00402408  0.28971741]]\n",
      "26000 번째 학습중입니다.\n",
      "Accuracy :  0.84\n",
      "Loss :      0.5397364889775457\n",
      "[[ 0.16658655  0.02391174 -0.19062795]\n",
      " [ 0.44139927 -0.16830475 -0.27343671]\n",
      " [-0.65034545  0.17512466  0.47563713]\n",
      " [-0.29978355  0.00232954  0.2975987 ]]\n",
      "27000 번째 학습중입니다.\n",
      "Accuracy :  0.8533333333333333\n",
      "Loss :      0.5339606881098402\n",
      "[[ 1.70010086e-01  2.59383086e-02 -1.96078049e-01]\n",
      " [ 4.50490967e-01 -1.71527426e-01 -2.79305721e-01]\n",
      " [-6.63481765e-01  1.77513029e-01  4.86385070e-01]\n",
      " [-3.05787224e-01  5.72596618e-04  3.05359313e-01]]\n",
      "28000 번째 학습중입니다.\n",
      "Accuracy :  0.8533333333333333\n",
      "Loss :      0.5284562551423805\n",
      "[[ 0.17333651  0.02798727 -0.20145344]\n",
      " [ 0.45932996 -0.17463627 -0.28503588]\n",
      " [-0.67624644  0.17974741  0.49691537]\n",
      " [-0.311619   -0.00124217  0.31300585]]\n",
      "29000 번째 학습중입니다.\n",
      "Accuracy :  0.86\n",
      "Loss :      0.5232004615904267\n",
      "[[ 0.17657254  0.03005614 -0.20675833]\n",
      " [ 0.46793174 -0.17763775 -0.29063616]\n",
      " [-0.68866125  0.18183702  0.50724056]\n",
      " [-0.31728911 -0.00311055  0.32054435]]\n",
      "30000 번째 학습중입니다.\n",
      "Accuracy :  0.8666666666666667\n",
      "Loss :      0.5181730724125541\n",
      "[[ 0.17972423  0.03214264 -0.21199653]\n",
      " [ 0.47631046 -0.18053787 -0.29611477]\n",
      " [-0.70074619  0.18379039  0.51737213]\n",
      " [-0.32280695 -0.00502867  0.32798031]]\n",
      "31000 번째 학습중입니다.\n",
      "Accuracy :  0.8733333333333333\n",
      "Loss :      0.5133560192395078\n",
      "[[ 0.18279713  0.03424472 -0.2171715 ]\n",
      " [ 0.48447913 -0.18334213 -0.30147919]\n",
      " [-0.71251969  0.18561541  0.52732061]\n",
      " [-0.32818115 -0.00699296  0.33531879]]\n",
      "32000 번째 학습중입니다.\n",
      "Accuracy :  0.8733333333333333\n",
      "Loss :      0.5087331225868008\n",
      "[[ 0.18579626  0.0363605  -0.22228641]\n",
      " [ 0.4924497  -0.18605562 -0.30673626]\n",
      " [-0.72399876  0.1873194   0.53709569]\n",
      " [-0.33341969 -0.0090001   0.34256447]]\n",
      "33000 번째 학습중입니다.\n",
      "Accuracy :  0.8733333333333333\n",
      "Loss :      0.5042898548900816\n",
      "[[ 0.18872621  0.03848829 -0.22734416]\n",
      " [ 0.50023316 -0.18868307 -0.31189228]\n",
      " [-0.7351991   0.18890915  0.54670628]\n",
      " [-0.33852991 -0.01104703  0.34972162]]\n",
      "34000 번째 학습중입니다.\n",
      "Accuracy :  0.88\n",
      "Loss :      0.5000131376810941\n",
      "[[ 0.1915912   0.04062653 -0.23234739]\n",
      " [ 0.50783967 -0.19122884 -0.31695301]\n",
      " [-0.74613525  0.19039098  0.55616061]\n",
      " [-0.34351861 -0.01313091  0.3567942 ]]\n",
      "35000 번째 학습중입니다.\n",
      "Accuracy :  0.88\n",
      "Loss :      0.49589116741456507\n",
      "[[ 0.19439508  0.0427738  -0.23729854]\n",
      " [ 0.51527858 -0.19369699 -0.32192377]\n",
      " [-0.75682071  0.19177075  0.5654663 ]\n",
      " [-0.34839209 -0.01524911  0.36378589]]\n",
      "36000 번째 학습중입니다.\n",
      "Accuracy :  0.88\n",
      "Loss :      0.4919132654208474\n",
      "[[ 0.19714138  0.0449288  -0.24219984]\n",
      " [ 0.52255859 -0.1960913  -0.32680947]\n",
      " [-0.76726799  0.19305393  0.57463039]\n",
      " [-0.3531562  -0.0173992   0.37070008]]\n",
      "37000 번째 학습중입니다.\n",
      "Accuracy :  0.8866666666666667\n",
      "Loss :      0.4880697482416156\n",
      "[[ 0.19983337  0.04709033 -0.24705335]\n",
      " [ 0.52968774 -0.19841528 -0.33161464]\n",
      " [-0.77748873  0.19424563  0.58365944]\n",
      " [-0.35781635 -0.01957889  0.37753993]]\n",
      "38000 번째 학습중입니다.\n",
      "Accuracy :  0.8933333333333333\n",
      "Loss :      0.484351815242689\n",
      "[[ 0.20247403  0.04925731 -0.25186099]\n",
      " [ 0.53667351 -0.20067221 -0.33634348]\n",
      " [-0.78749379  0.1953506   0.59255952]\n",
      " [-0.36237761 -0.02178608  0.38430837]]\n",
      "39000 번째 학습중입니다.\n",
      "Accuracy :  0.9\n",
      "Loss :      0.4807514509179769\n",
      "[[ 0.20506614  0.05142873 -0.25662452]\n",
      " [ 0.54352282 -0.20286514 -0.34099986]\n",
      " [-0.79729328  0.19637332  0.60133629]\n",
      " [-0.36684467 -0.02401879  0.39100814]]\n",
      "40000 번째 학습중입니다.\n",
      "Accuracy :  0.9066666666666666\n",
      "Loss :      0.477261339724378\n",
      "[[ 0.20761225  0.05360367 -0.26134558]\n",
      " [ 0.55024217 -0.20499693 -0.34558742]\n",
      " [-0.80689664  0.19731793  0.60999504]\n",
      " [-0.37122193 -0.02627518  0.3976418 ]]\n",
      "41000 번째 학습중입니다.\n",
      "Accuracy :  0.9066666666666666\n",
      "Loss :      0.4738747916373982\n",
      "[[ 0.21011474  0.05578127 -0.26602567]\n",
      " [ 0.55683758 -0.20707027 -0.35010949]\n",
      " [-0.81631271  0.19818836  0.61854069]\n",
      " [-0.37551349 -0.02855355  0.40421172]]\n",
      "42000 번째 학습중입니다.\n",
      "Accuracy :  0.9066666666666666\n",
      "Loss :      0.47058567690573067\n",
      "[[ 0.21257581  0.05796075 -0.27066622]\n",
      " [ 0.56331467 -0.20908765 -0.35456921]\n",
      " [-0.82554976  0.19898825  0.62697785]\n",
      " [-0.37972319 -0.03085228  0.41072015]]\n",
      "43000 번째 학습중입니다.\n",
      "Accuracy :  0.9066666666666666\n",
      "Loss :      0.46738836872159945\n",
      "[[ 0.21499749  0.06014139 -0.27526854]\n",
      " [ 0.56967873 -0.21105143 -0.35896948]\n",
      " [-0.83461555  0.19972105  0.63531083]\n",
      " [-0.38385462 -0.03316987  0.41716918]]\n",
      "44000 번째 학습중입니다.\n",
      "Accuracy :  0.92\n",
      "Loss :      0.46427769272158753\n",
      "[[ 0.21738168  0.06232252 -0.27983385]\n",
      " [ 0.57593469 -0.21296383 -0.36331304]\n",
      " [-0.84351735  0.20039     0.64354369]\n",
      " [-0.38791116 -0.03550493  0.42356078]]\n",
      "45000 번째 학습중입니다.\n",
      "Accuracy :  0.92\n",
      "Loss :      0.4612488823973604\n",
      "[[ 0.21973014  0.06450352 -0.28436331]\n",
      " [ 0.58208715 -0.21482692 -0.36760241]\n",
      " [-0.852262    0.20099813  0.65168021]\n",
      " [-0.39189598 -0.03785613  0.4298968 ]]\n",
      "46000 번째 학습중입니다.\n",
      "Accuracy :  0.92\n",
      "Loss :      0.45829753963315817\n",
      "[[ 0.22204452  0.06668383 -0.288858  ]\n",
      " [ 0.58814047 -0.21664266 -0.37183999]\n",
      " [-0.86085593  0.2015483   0.65972396]\n",
      " [-0.39581204 -0.04022225  0.43617897]]\n",
      "47000 번째 학습중입니다.\n",
      "Accuracy :  0.92\n",
      "Loss :      0.45541959970201085\n",
      "[[ 0.22432635  0.0688629  -0.29331891]\n",
      " [ 0.59409871 -0.2184129  -0.37602799]\n",
      " [-0.8693052   0.20204323  0.66767831]\n",
      " [-0.39966215 -0.04260211  0.44240895]]\n",
      "48000 번째 학습중입니다.\n",
      "Accuracy :  0.92\n",
      "Loss :      0.4526113001492574\n",
      "[[ 0.22657707  0.07104027 -0.29774699]\n",
      " [ 0.5999657  -0.22013937 -0.38016851]\n",
      " [-0.87761552  0.20248544  0.67554642]\n",
      " [-0.40344894 -0.04499464  0.44858827]]\n",
      "49000 번째 학습중입니다.\n",
      "Accuracy :  0.92\n",
      "Loss :      0.44986915307329167\n",
      "[[ 0.22879802  0.07321546 -0.30214314]\n",
      " [ 0.60574506 -0.22182373 -0.3842635 ]\n",
      " [-0.88579228  0.20287735  0.68333127]\n",
      " [-0.40717491 -0.04739881  0.4547184 ]]\n",
      "50000 번째 학습중입니다.\n",
      "Accuracy :  0.9266666666666666\n",
      "Loss :      0.44718992038215655\n",
      "[[ 0.23099046  0.07538807 -0.30650819]\n",
      " [ 0.61144017 -0.22346753 -0.38831482]\n",
      " [-0.89384056  0.20322122  0.69103567]\n",
      " [-0.41084239 -0.04981365  0.46080072]]\n",
      "51000 번째 학습중입니다.\n",
      "Accuracy :  0.9266666666666666\n",
      "Loss :      0.44457059166275203\n",
      "[[ 0.23315556  0.0775577  -0.31084292]\n",
      " [ 0.61705426 -0.22507224 -0.3923242 ]\n",
      " [-0.90176516  0.20351922  0.69866228]\n",
      " [-0.41445361 -0.05223826  0.46683655]]\n",
      "52000 번째 학습중입니다.\n",
      "Accuracy :  0.9333333333333333\n",
      "Loss :      0.44200836434879953\n",
      "[[ 0.23529443  0.079724   -0.31514808]\n",
      " [ 0.62259033 -0.22663925 -0.39629326]\n",
      " [-0.90957066  0.20377336  0.70621363]\n",
      " [-0.41801066 -0.05467179  0.47282713]]\n",
      "53000 번째 학습중입니다.\n",
      "Accuracy :  0.9333333333333333\n",
      "Loss :      0.4395006259157017\n",
      "[[ 0.2374081   0.08188662 -0.31942438]\n",
      " [ 0.62805126 -0.22816989 -0.40022355]\n",
      " [-0.91726134  0.20398559  0.71369209]\n",
      " [-0.42151552 -0.05711342  0.47877363]]\n",
      "54000 번째 학습중입니다.\n",
      "Accuracy :  0.94\n",
      "Loss :      0.4370449378662983\n",
      "[[ 0.23949756  0.08404526 -0.32367247]\n",
      " [ 0.63343974 -0.22966541 -0.40411651]\n",
      " [-0.92484129  0.20415771  0.72109992]\n",
      " [-0.42497007 -0.05956241  0.48467717]]\n",
      "55000 번째 학습중입니다.\n",
      "Accuracy :  0.94\n",
      "Loss :      0.4346390213021606\n",
      "[[ 0.24156371  0.08619963 -0.32789299]\n",
      " [ 0.63875835 -0.231127   -0.40797352]\n",
      " [-0.9323144   0.20429147  0.72843926]\n",
      " [-0.42837611 -0.06201802  0.49053882]]\n",
      "56000 번째 학습중입니다.\n",
      "Accuracy :  0.94\n",
      "Loss :      0.43228074390136934\n",
      "[[ 0.24360742  0.08834946 -0.33208654]\n",
      " [ 0.64400949 -0.2325558  -0.41179588]\n",
      " [-0.93968433  0.20438852  0.73571215]\n",
      " [-0.4317353  -0.0644796   0.49635959]]\n",
      "57000 번째 학습중입니다.\n",
      "Accuracy :  0.94\n",
      "Loss :      0.4299681081462967\n",
      "[[ 0.24562951  0.0904945  -0.33625367]\n",
      " [ 0.64919549 -0.23395287 -0.4155848 ]\n",
      " [-0.94695458  0.20445041  0.74292051]\n",
      " [-0.43504927 -0.06694649  0.50214044]]\n",
      "58000 번째 학습중입니다.\n",
      "Accuracy :  0.94\n",
      "Loss :      0.42769924066437814\n",
      "[[ 0.24763075  0.09263453 -0.34039493]\n",
      " [ 0.65431851 -0.23531925 -0.41934144]\n",
      " [-0.95412848  0.20447863  0.75006618]\n",
      " [-0.43831953 -0.06941809  0.5078823 ]]\n",
      "59000 번째 학습중입니다.\n",
      "Accuracy :  0.94\n",
      "Loss :      0.4254723825616489\n",
      "[[ 0.24961185  0.09476932 -0.34451083]\n",
      " [ 0.65938064 -0.23665591 -0.4230669 ]\n",
      " [-0.96120918  0.2044746   0.75715092]\n",
      " [-0.44154753 -0.07189382  0.51358604]]\n",
      "60000 번째 학습중입니다.\n",
      "Accuracy :  0.94\n",
      "Loss :      0.4232858806433537\n",
      "[[ 0.25157352  0.09689869 -0.34860186]\n",
      " [ 0.66438383 -0.23796379 -0.42676223]\n",
      " [-0.96819969  0.20443965  0.76417638]\n",
      " [-0.44473465 -0.07437316  0.51925249]]\n",
      "61000 번째 학습중입니다.\n",
      "Accuracy :  0.94\n",
      "Loss :      0.4211381794285335\n",
      "[[ 0.25351638  0.09902244 -0.35266848]\n",
      " [ 0.66932998 -0.23924377 -0.43042839]\n",
      " [-0.97510289  0.20437508  0.77114414]\n",
      " [-0.44788221 -0.07685558  0.52488247]]\n",
      "62000 번째 학습중입니다.\n",
      "Accuracy :  0.9466666666666667\n",
      "Loss :      0.4190278138764374\n",
      "[[ 0.25544107  0.1011404  -0.35671113]\n",
      " [ 0.67422086 -0.2404967  -0.43406633]\n",
      " [-0.98192149  0.20428209  0.77805573]\n",
      " [-0.45099146 -0.07934059  0.53047674]]\n",
      "63000 번째 학습중입니다.\n",
      "Accuracy :  0.9466666666666667\n",
      "Loss :      0.416953402752126\n",
      "[[ 0.25734816  0.10325242 -0.36073024]\n",
      " [ 0.67905817 -0.2417234  -0.43767694]\n",
      " [-0.98865812  0.20416187  0.78491259]\n",
      " [-0.45406359 -0.08182775  0.53603603]]\n",
      "64000 번째 학습중입니다.\n",
      "Accuracy :  0.9466666666666667\n",
      "Loss :      0.41491364256695146\n",
      "[[ 0.25923821  0.10535835 -0.36472621]\n",
      " [ 0.68384352 -0.24292464 -0.44126106]\n",
      " [-0.99531526  0.20401551  0.79171608]\n",
      " [-0.45709975 -0.0843166   0.54156104]]\n",
      "65000 번째 학습중입니다.\n",
      "Accuracy :  0.9533333333333334\n",
      "Loss :      0.4129073020368467\n",
      "[[ 0.26111172  0.10745805 -0.36869943]\n",
      " [ 0.68857847 -0.24410116 -0.4448195 ]\n",
      " [-1.00189529  0.20384408  0.79846754]\n",
      " [-0.46010101 -0.08680675  0.54705244]]\n",
      "66000 번째 학습중입니다.\n",
      "Accuracy :  0.96\n",
      "Loss :      0.41093321700772006\n",
      "[[ 0.26296922  0.1095514  -0.37265027]\n",
      " [ 0.69326449 -0.24525367 -0.44835301]\n",
      " [-1.00840048  0.20364859  0.80516822]\n",
      " [-0.46306841 -0.08929779  0.55251089]]\n",
      "67000 번째 학습중입니다.\n",
      "Accuracy :  0.96\n",
      "Loss :      0.40899028580282104\n",
      "[[ 0.26481115  0.11163828 -0.37657908]\n",
      " [ 0.69790299 -0.24638285 -0.45186231]\n",
      " [-1.014833    0.20343001  0.81181932]\n",
      " [-0.46600296 -0.09178936  0.55793701]]\n",
      "68000 번째 학습중입니다.\n",
      "Accuracy :  0.96\n",
      "Loss :      0.40707746495184094\n",
      "[[ 0.26663798  0.11371858 -0.38048621]\n",
      " [ 0.7024953  -0.24748936 -0.45534812]\n",
      " [-1.02119495  0.20318927  0.81842201]\n",
      " [-0.4689056  -0.0942811   0.56333138]]\n",
      "69000 번째 학습중입니다.\n",
      "Accuracy :  0.96\n",
      "Loss :      0.4051937652658183\n",
      "[[ 0.26845013  0.1157922  -0.38437199]\n",
      " [ 0.70704271 -0.24857382 -0.45881107]\n",
      " [-1.0274883   0.20292725  0.82497738]\n",
      " [-0.47177723 -0.09677268  0.56869459]]\n",
      "70000 번째 학습중입니다.\n",
      "Accuracy :  0.96\n",
      "Loss :      0.4033382482257318\n",
      "[[ 0.27024801  0.11785906 -0.38823672]\n",
      " [ 0.71154647 -0.24963683 -0.46225181]\n",
      " [-1.03371496  0.20264479  0.83148651]\n",
      " [-0.47461873 -0.09926377  0.57402719]]\n",
      "71000 번째 학습중입니다.\n",
      "Accuracy :  0.96\n",
      "Loss :      0.40151002265599567\n",
      "[[ 0.272032    0.11991906 -0.39208071]\n",
      " [ 0.71600773 -0.25067898 -0.46567093]\n",
      " [-1.03987677  0.20234271  0.83795039]\n",
      " [-0.47743094 -0.10175408  0.5793297 ]]\n",
      "72000 번째 학습중입니다.\n",
      "Accuracy :  0.96\n",
      "Loss :      0.3997082416570614\n",
      "[[ 0.27380247  0.12197214 -0.39590426]\n",
      " [ 0.72042763 -0.25170081 -0.46906901]\n",
      " [-1.04597547  0.20202179  0.84437002]\n",
      " [-0.48021464 -0.10424332  0.58460264]]\n",
      "73000 번째 학습중입니다.\n",
      "Accuracy :  0.96\n",
      "Loss :      0.3979320997739515\n",
      "[[ 0.27555978  0.12401821 -0.39970764]\n",
      " [ 0.72480725 -0.25270285 -0.47244658]\n",
      " [-1.05201276  0.20168276  0.85074633]\n",
      " [-0.48297061 -0.10673121  0.58984651]]\n",
      "74000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.39618083037987756\n",
      "[[ 0.27730425  0.12605721 -0.40349112]\n",
      " [ 0.72914762 -0.25368563 -0.47580418]\n",
      " [-1.05799023  0.20132635  0.85708021]\n",
      " [-0.48569958 -0.1092175   0.59506177]]\n",
      "75000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3944537032561726\n",
      "[[ 0.27903622  0.12808909 -0.40725497]\n",
      " [ 0.73344975 -0.25464962 -0.4791423 ]\n",
      " [-1.06390945  0.20095324  0.86337255]\n",
      " [-0.48840226 -0.11170194  0.60024889]]\n",
      "76000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.39275002235161516\n",
      "[[ 0.28075599  0.1301138  -0.41099944]\n",
      " [ 0.73771457 -0.25559532 -0.48246142]\n",
      " [-1.0697719   0.20056408  0.86962416]\n",
      " [-0.49107933 -0.1141843   0.60540831]]\n",
      "77000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3910691237058588\n",
      "[[ 0.28246385  0.13213127 -0.41472477]\n",
      " [ 0.741943   -0.25652318 -0.48576201]\n",
      " [-1.07557902  0.2001595   0.87583586]\n",
      " [-0.49373143 -0.11666435  0.61054047]]\n",
      "78000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3894103735231516\n",
      "[[ 0.28416008  0.13414147 -0.4184312 ]\n",
      " [ 0.74613593 -0.25743363 -0.48904449]\n",
      " [-1.08133218  0.19974011  0.8820084 ]\n",
      " [-0.49635919 -0.11914188  0.61564576]]\n",
      "79000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3877731663838374\n",
      "[[ 0.28584495  0.13614435 -0.42211895]\n",
      " [ 0.7502942  -0.2583271  -0.49230928]\n",
      " [-1.08703271  0.19930649  0.88814255]\n",
      " [-0.49896322 -0.1216167   0.62072461]]\n",
      "80000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.38615692358231096\n",
      "[[ 0.28751872  0.13813989 -0.42578826]\n",
      " [ 0.75441863 -0.25920401 -0.49555679]\n",
      " [-1.09268188  0.1988592   0.89423901]\n",
      " [-0.50154409 -0.1240886   0.62577738]]\n",
      "81000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.38456109158113816\n",
      "[[ 0.28918163  0.14012804 -0.42943933]\n",
      " [ 0.75850998 -0.26006475 -0.49878741]\n",
      " [-1.09828092  0.19839878  0.90029848]\n",
      " [-0.50410237 -0.12655742  0.63080447]]\n",
      "82000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.38298514057200433\n",
      "[[ 0.29083393  0.14210878 -0.43307237]\n",
      " [ 0.76256903 -0.2609097  -0.5020015 ]\n",
      " [-1.10383101  0.19792573  0.90632162]\n",
      " [-0.50663858 -0.12902297  0.63580623]]\n",
      "83000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.38142856313499895\n",
      "[[ 0.29247583  0.14408209 -0.43668758]\n",
      " [ 0.76659648 -0.26173924 -0.50519942]\n",
      " [-1.1093333   0.19744056  0.91230908]\n",
      " [-0.50915325 -0.13148509  0.64078302]]\n",
      "84000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3798908729884994\n",
      "[[ 0.29410756  0.14604795 -0.44028516]\n",
      " [ 0.77059304 -0.26255371 -0.50838151]\n",
      " [-1.11478888  0.19694374  0.91826147]\n",
      " [-0.51164687 -0.13394362  0.64573518]]\n",
      "85000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.37837160382261253\n",
      "[[ 0.29572933  0.14800633 -0.44386531]\n",
      " [ 0.77455938 -0.26335347 -0.51154809]\n",
      " [-1.12019881  0.19643573  0.92417941]\n",
      " [-0.51411992 -0.13639843  0.65066304]]\n",
      "86000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.37687030820974465\n",
      "[[ 0.29734133  0.14995722 -0.4474282 ]\n",
      " [ 0.77849615 -0.26413884 -0.51469949]\n",
      " [-1.12556411  0.19591697  0.93006347]\n",
      " [-0.51657288 -0.13884935  0.65556692]]\n",
      "87000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.375386556586426\n",
      "[[ 0.29894376  0.15190061 -0.45097402]\n",
      " [ 0.78240397 -0.26491015 -0.517836  ]\n",
      " [-1.13088578  0.1953879   0.93591421]\n",
      " [-0.51900618 -0.14129628  0.66044714]]\n",
      "88000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3739199363010298\n",
      "[[ 0.30053681  0.15383648 -0.45450294]\n",
      " [ 0.78628345 -0.26566772 -0.52095791]\n",
      " [-1.13616475  0.19484891  0.94173218]\n",
      " [-0.52142025 -0.14373906  0.665304  ]]\n",
      "89000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.37247005072246847\n",
      "[[ 0.30212066  0.15576483 -0.45801514]\n",
      " [ 0.79013517 -0.26641184 -0.52406551]\n",
      " [-1.14140197  0.1943004   0.9475179 ]\n",
      " [-0.52381552 -0.14617759  0.6701378 ]]\n",
      "90000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3710365184053753\n",
      "[[ 0.30369547  0.15768566 -0.46151078]\n",
      " [ 0.79395969 -0.26714282 -0.52715905]\n",
      " [-1.1465983   0.19374276  0.95327188]\n",
      " [-0.52619239 -0.14861175  0.67494883]]\n",
      "91000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3696189723076469\n",
      "[[ 0.30526142  0.15959896 -0.46499003]\n",
      " [ 0.79775756 -0.26786092 -0.53023882]\n",
      " [-1.15175462  0.19317634  0.95899461]\n",
      " [-0.52855124 -0.15104144  0.67973736]]\n",
      "92000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.36821705905655816\n",
      "[[ 0.30681866  0.16150472 -0.46845304]\n",
      " [ 0.80152929 -0.26856643 -0.53330504]\n",
      " [-1.15687175  0.19260151  0.96468658]\n",
      " [-0.53089245 -0.15346654  0.68450368]]\n",
      "93000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3668304382599832\n",
      "[[ 0.30836735  0.16340296 -0.47189996]\n",
      " [ 0.80527541 -0.26925962 -0.53635797]\n",
      " [-1.1619505   0.1920186   0.97034824]\n",
      " [-0.53321639 -0.15588695  0.68924803]]\n",
      "94000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3654587818595206\n",
      "[[ 0.30990765  0.16529367 -0.47533097]\n",
      " [ 0.80899639 -0.26994075 -0.53939783]\n",
      " [-1.16699165  0.19142794  0.97598005]\n",
      " [-0.53552341 -0.1583026   0.6939707 ]]\n",
      "95000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3641017735225886\n",
      "[[ 0.31143968  0.16717685 -0.47874619]\n",
      " [ 0.81269272 -0.27061005 -0.54242485]\n",
      " [-1.17199594  0.19082984  0.98158243]\n",
      " [-0.53781384 -0.16071339  0.69867191]]\n",
      "96000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3627591080707793\n",
      "[[ 0.3129636   0.16905252 -0.48214577]\n",
      " [ 0.81636485 -0.27126779 -0.54543924]\n",
      " [-1.17696411  0.19022462  0.98715582]\n",
      " [-0.54008802 -0.16311923  0.70335193]]\n",
      "97000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3614304909419825\n",
      "[[ 0.31447953  0.17092068 -0.48552987]\n",
      " [ 0.82001323 -0.27191419 -0.54844122]\n",
      " [-1.18189686  0.18961257  0.99270063]\n",
      " [-0.54234627 -0.16552004  0.70801099]]\n",
      "98000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.36011563768397487\n",
      "[[ 0.31598762  0.17278133 -0.48889861]\n",
      " [ 0.82363829 -0.27254949 -0.55143098]\n",
      " [-1.18679488  0.18899397  0.99821725]\n",
      " [-0.54458888 -0.16791576  0.71264933]]\n",
      "99000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3588142734773507\n",
      "[[ 0.31748797  0.1746345  -0.49225213]\n",
      " [ 0.82724044 -0.2731739  -0.55440872]\n",
      " [-1.19165883  0.18836909  1.00370607]\n",
      " [-0.54681618 -0.17030631  0.71726718]]\n",
      "100000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.35752613268583633\n",
      "[[ 0.31898072  0.17648019 -0.49559057]\n",
      " [ 0.8308201  -0.27378765 -0.55737463]\n",
      " [-1.19648935  0.18773821  1.00916747]\n",
      " [-0.54902843 -0.17269163  0.72186475]]\n",
      "101000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.35625095843217\n",
      "[[ 0.32046599  0.17831841 -0.49891405]\n",
      " [ 0.83437766 -0.27439095 -0.56032889]\n",
      " [-1.20128706  0.18710158  1.01460181]\n",
      " [-0.55122593 -0.17507164  0.72644227]]\n",
      "102000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3549885021978689\n",
      "[[ 0.32194388  0.18014918 -0.50222271]\n",
      " [ 0.83791348 -0.27498399 -0.56327167]\n",
      " [-1.20605256  0.18645944  1.02000946]\n",
      " [-0.55340895 -0.1774463   0.73099994]]\n",
      "103000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3537385234453319\n",
      "[[ 0.32341451  0.18197251 -0.50551668]\n",
      " [ 0.84142796 -0.27556699 -0.56620315]\n",
      " [-1.21078646  0.18581203  1.02539076]\n",
      " [-0.55557775 -0.17981555  0.73553799]]\n",
      "104000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3525007892608369\n",
      "[[ 0.32487798  0.18378843 -0.50879606]\n",
      " [ 0.84492143 -0.27614013 -0.56912348]\n",
      " [-1.2154893   0.18515959  1.03074604]\n",
      " [-0.55773259 -0.18217933  0.74005661]]\n",
      "105000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.35127507401709884\n",
      "[[ 0.32633441  0.18559694 -0.512061  ]\n",
      " [ 0.84839426 -0.2767036  -0.57203284]\n",
      " [-1.22016164  0.18450233  1.03607564]\n",
      " [-0.55987372 -0.18453759  0.744556  ]]\n",
      "106000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3500611590541449\n",
      "[[ 0.32778388  0.18739806 -0.5153116 ]\n",
      " [ 0.85184677 -0.27725759 -0.57493136]\n",
      " [-1.22480403  0.18384048  1.04137988]\n",
      " [-0.56200137 -0.18689029  0.74903635]]\n",
      "107000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.34885883237736315\n",
      "[[ 0.3292265   0.18919182 -0.51854798]\n",
      " [ 0.8552793  -0.27780227 -0.57781921]\n",
      " [-1.22941697  0.18317424  1.04665906]\n",
      " [-0.56411579 -0.18923738  0.75349786]]\n",
      "108000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3476678883716513\n",
      "[[ 0.33066237  0.19097823 -0.52177025]\n",
      " [ 0.85869216 -0.27833782 -0.58069653]\n",
      " [-1.23400098  0.18250382  1.0519135 ]\n",
      " [-0.5662172  -0.19157883  0.75794072]]\n",
      "109000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.34648812753067376\n",
      "[[ 0.33209157  0.19275732 -0.52497854]\n",
      " [ 0.86208567 -0.2788644  -0.58356345]\n",
      " [-1.23855655  0.1818294   1.05714348]\n",
      " [-0.56830583 -0.19391459  0.76236511]]\n",
      "110000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.34531935620029997\n",
      "[[ 0.3335142   0.1945291  -0.52817295]\n",
      " [ 0.86546012 -0.27938219 -0.58642011]\n",
      " [-1.24308415  0.18115117  1.06234931]\n",
      " [-0.57038188 -0.19624463  0.7667712 ]]\n",
      "111000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3441613863353668\n",
      "[[ 0.33493034  0.1962936  -0.53135359]\n",
      " [ 0.86881582 -0.27989134 -0.58926666]\n",
      " [-1.24758425  0.18046932  1.06753126]\n",
      " [-0.57244557 -0.19856892  0.77115917]]\n",
      "112000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3430140352689604\n",
      "[[ 0.33634008  0.19805084 -0.53452057]\n",
      " [ 0.87215303 -0.28039201 -0.5921032 ]\n",
      " [-1.2520573   0.17978403  1.0726896 ]\n",
      " [-0.5744971  -0.20088742  0.7755292 ]]\n",
      "113000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.34187712549347393\n",
      "[[ 0.3377435   0.19980084 -0.537674  ]\n",
      " [ 0.87547205 -0.28088435 -0.59492988]\n",
      " [-1.25650374  0.17909546  1.07782461]\n",
      " [-0.57653668 -0.2032001   0.77988146]]\n",
      "114000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3407504844527358\n",
      "[[ 0.33914069  0.20154363 -0.54081397]\n",
      " [ 0.87877314 -0.28136851 -0.59774681]\n",
      " [-1.260924    0.17840378  1.08293655]\n",
      " [-0.57856448 -0.20550694  0.78421611]]\n",
      "115000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.33963394434456906\n",
      "[[ 0.34053171  0.20327924 -0.5439406 ]\n",
      " [ 0.88205656 -0.28184464 -0.6005541 ]\n",
      " [-1.26531849  0.17770914  1.08802568]\n",
      " [-0.5805807  -0.20780792  0.78853331]]\n",
      "116000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3385273419331684\n",
      "[[ 0.34191665  0.20500768 -0.54705398]\n",
      " [ 0.88532257 -0.28231287 -0.60335188]\n",
      " [-1.26968761  0.1770117   1.09309224]\n",
      " [-0.58258552 -0.21010301  0.79283322]]\n",
      "117000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.33743051837072296\n",
      "[[ 0.34329558  0.20672899 -0.55015422]\n",
      " [ 0.88857142 -0.28277335 -0.60614025]\n",
      " [-1.27403177  0.17631162  1.09813649]\n",
      " [-0.58457913 -0.21239219  0.797116  ]]\n",
      "118000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3363433190277669\n",
      "[[ 0.34466857  0.20844318 -0.5532414 ]\n",
      " [ 0.89180335 -0.28322621 -0.60891932]\n",
      " [-1.27835135  0.17560903  1.10315866]\n",
      " [-0.58656168 -0.21467544  0.80138181]]\n",
      "119000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3352655933317484\n",
      "[[ 0.34603569  0.21015029 -0.55631564]\n",
      " [ 0.8950186  -0.28367158 -0.6116892 ]\n",
      " [-1.28264672  0.17490407  1.10815898]\n",
      " [-0.58853335 -0.21695275  0.80563079]]\n",
      "120000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3341971946133612\n",
      "[[ 0.34739702  0.21185034 -0.55937702]\n",
      " [ 0.89821739 -0.28410959 -0.61444998]\n",
      " [-1.28691824  0.17419688  1.11313769]\n",
      " [-0.59049431 -0.2192241   0.8098631 ]]\n",
      "121000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3331379799602027\n",
      "[[ 0.34875262  0.21354336 -0.56242563]\n",
      " [ 0.90139996 -0.28454037 -0.61720178]\n",
      " [-1.29116627  0.17348759  1.11809502]\n",
      " [-0.59244472 -0.22148948  0.81407888]]\n",
      "122000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3320878100773462\n",
      "[[ 0.35010256  0.21522938 -0.56546159]\n",
      " [ 0.90456653 -0.28496403 -0.61994468]\n",
      " [-1.29539116  0.17277633  1.12303117]\n",
      " [-0.59438472 -0.22374886  0.81827827]]\n",
      "123000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.33104654915445364\n",
      "[[ 0.35144689  0.21690842 -0.56848496]\n",
      " [ 0.9077173  -0.28538069 -0.62267878]\n",
      " [-1.29959324  0.17206321  1.12794636]\n",
      " [-0.59631447 -0.22600226  0.82246141]]\n",
      "124000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.33001406473906364\n",
      "[[ 0.35278568  0.21858051 -0.57149585]\n",
      " [ 0.91085248 -0.28579048 -0.62540418]\n",
      " [-1.30377285  0.17134837  1.13284082]\n",
      " [-0.59823413 -0.22824964  0.82662845]]\n",
      "125000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3289902276157244\n",
      "[[ 0.354119    0.22024569 -0.57449435]\n",
      " [ 0.91397229 -0.28619351 -0.62812096]\n",
      " [-1.3079303   0.1706319   1.13771474]\n",
      " [-0.60014382 -0.23049101  0.83077952]]\n",
      "126000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.327974911690653\n",
      "[[ 0.35544691  0.22190397 -0.57748053]\n",
      " [ 0.91707691 -0.28658988 -0.63082921]\n",
      " [-1.31206591  0.16991392  1.14256832]\n",
      " [-0.60204371 -0.23272636  0.83491475]]\n",
      "127000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.32696799388162584\n",
      "[[ 0.35676945  0.2235554  -0.5804545 ]\n",
      " [ 0.92016655 -0.28697972 -0.63352901]\n",
      " [-1.31617998  0.16919455  1.14740176]\n",
      " [-0.60393391 -0.23495568  0.83903428]]\n",
      "128000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.32596935401282356\n",
      "[[ 0.35808669  0.22519999 -0.58341634]\n",
      " [ 0.92324138 -0.28736311 -0.63622046]\n",
      " [-1.32027281  0.16847388  1.15221527]\n",
      " [-0.60581458 -0.23717898  0.84313824]]\n",
      "129000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.32497887471436654\n",
      "[[ 0.35939869  0.22683778 -0.58636613]\n",
      " [ 0.92630161 -0.28774017 -0.63890362]\n",
      " [-1.3243447   0.16775201  1.15700902]\n",
      " [-0.60768583 -0.23939623  0.84722675]]\n",
      "130000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3239964413262982\n",
      "[[ 0.3607055   0.2284688  -0.58930395]\n",
      " [ 0.92934741 -0.288111   -0.64157859]\n",
      " [-1.32839592  0.16702905  1.1617832 ]\n",
      " [-0.60954779 -0.24160746  0.85129994]]\n",
      "131000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3230219418067811\n",
      "[[ 0.36200717  0.23009307 -0.5922299 ]\n",
      " [ 0.93237895 -0.2884757  -0.64424543]\n",
      " [-1.33242676  0.16630508  1.16653801]\n",
      " [-0.6114006  -0.24381265  0.85535793]]\n",
      "132000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.32205526664429224\n",
      "[[ 0.36330375  0.23171064 -0.59514404]\n",
      " [ 0.93539641 -0.28883436 -0.64690423]\n",
      " [-1.33643748  0.1655802   1.17127361]\n",
      " [-0.61324437 -0.2460118   0.85940085]]\n",
      "133000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.32109630877360884\n",
      "[[ 0.3645953   0.23332152 -0.59804647]\n",
      " [ 0.93839996 -0.28918709 -0.64955506]\n",
      " [-1.34042836  0.1648545   1.17599019]\n",
      " [-0.61507922 -0.24820491  0.86342882]]\n",
      "134000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3201449634953943\n",
      "[[ 0.36588187  0.23492574 -0.60093726]\n",
      " [ 0.94138977 -0.28953396 -0.65219799]\n",
      " [-1.34439965  0.16412806  1.18068792]\n",
      " [-0.61690527 -0.250392    0.86744195]]\n",
      "135000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.31920112839920134\n",
      "[[ 0.3671635   0.23652334 -0.6038165 ]\n",
      " [ 0.94436599 -0.28987508 -0.65483309]\n",
      " [-1.3483516   0.16340097  1.18536696]\n",
      " [-0.61872263 -0.25257305  0.87144037]]\n",
      "136000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.31826470328971945\n",
      "[[ 0.36844025  0.23811436 -0.60668426]\n",
      " [ 0.94732879 -0.29021054 -0.65746043]\n",
      " [-1.35228446  0.1626733   1.1900275 ]\n",
      " [-0.62053141 -0.25474808  0.87542418]]\n",
      "137000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.31733559011610685\n",
      "[[ 0.36971216  0.23969881 -0.60954062]\n",
      " [ 0.95027832 -0.29054041 -0.66008009]\n",
      " [-1.35619848  0.16194514  1.19466968]\n",
      " [-0.62233173 -0.25691709  0.8793935 ]]\n",
      "138000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3164136929042544\n",
      "[[ 0.37097927  0.24127673 -0.61238565]\n",
      " [ 0.95321472 -0.29086479 -0.66269212]\n",
      " [-1.36009389  0.16121655  1.19929367]\n",
      " [-0.62412368 -0.25908008  0.88334845]]\n",
      "139000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.31549891769183397\n",
      "[[ 0.37224164  0.24284815 -0.61521944]\n",
      " [ 0.95613816 -0.29118376 -0.66529659]\n",
      " [-1.36397092  0.16048762  1.20389963]\n",
      " [-0.62590738 -0.26123706  0.88728912]]\n",
      "140000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3145911724660008\n",
      "[[ 0.37349931  0.2444131  -0.61804206]\n",
      " [ 0.95904878 -0.2914974  -0.66789356]\n",
      " [-1.3678298   0.15975841  1.20848772]\n",
      " [-0.62768292 -0.26338804  0.89121565]]\n",
      "141000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3136903671036152\n",
      "[[ 0.37475232  0.24597161 -0.62085358]\n",
      " [ 0.96194671 -0.29180579 -0.6704831 ]\n",
      " [-1.37167075  0.15902899  1.21305809]\n",
      " [-0.6294504  -0.26553303  0.89512811]]\n",
      "142000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3127964133138657\n",
      "[[ 0.37600071  0.24752371 -0.62365408]\n",
      " [ 0.9648321  -0.29210901 -0.67306528]\n",
      " [-1.37549398  0.15829942  1.21761089]\n",
      " [-0.63120993 -0.26767203  0.89902664]]\n",
      "143000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.31190922458317955\n",
      "[[ 0.37724453  0.24906944 -0.62644362]\n",
      " [ 0.96770509 -0.29240713 -0.67564014]\n",
      " [-1.37929972  0.15756978  1.22214627]\n",
      " [-0.63296159 -0.26980505  0.90291132]]\n",
      "144000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.311028716122308\n",
      "[[ 0.37848381  0.25060883 -0.62922229]\n",
      " [ 0.9705658  -0.29270024 -0.67820775]\n",
      " [-1.38308816  0.15684012  1.22666437]\n",
      " [-0.63470548 -0.27193211  0.90678227]]\n",
      "145000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.31015480481548785\n",
      "[[ 0.37971861  0.25214189 -0.63199015]\n",
      " [ 0.97341438 -0.2929884  -0.68076816]\n",
      " [-1.38685951  0.15611051  1.23116534]\n",
      " [-0.63644169 -0.27405321  0.91063958]]\n",
      "146000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3092874091715791\n",
      "[[ 0.38094895  0.25366868 -0.63474728]\n",
      " [ 0.97625094 -0.29327169 -0.68332143]\n",
      " [-1.39061398  0.155381    1.23564931]\n",
      " [-0.63817031 -0.27616836  0.91448335]]\n",
      "147000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3084264492770877\n",
      "[[ 0.38217488  0.25518921 -0.63749374]\n",
      " [ 0.97907562 -0.29355018 -0.68586763]\n",
      " [-1.39435174  0.15465164  1.24011644]\n",
      " [-0.63989143 -0.27827758  0.91831369]]\n",
      "148000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.30757184675098687\n",
      "[[ 0.38339643  0.25670352 -0.64022961]\n",
      " [ 0.98188854 -0.29382393 -0.68840679]\n",
      " [-1.39807301  0.1539225   1.24456685]\n",
      " [-0.64160513 -0.28038088  0.92213069]]\n",
      "149000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.30672352470125264\n",
      "[[ 0.38461365  0.25821164 -0.64295495]\n",
      " [ 0.98468982 -0.29409302 -0.69093898]\n",
      " [-1.40177796  0.15319362  1.24900067]\n",
      " [-0.6433115  -0.28247827  0.92593445]]\n",
      "150000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.30588140768303673\n",
      "[[ 0.38582657  0.2597136  -0.64566983]\n",
      " [ 0.98747958 -0.29435751 -0.69346425]\n",
      " [-1.40546677  0.15246506  1.25341805]\n",
      " [-0.64501062 -0.28456976  0.92972506]]\n",
      "151000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.30504542165840254\n",
      "[[ 0.38703523  0.26120944 -0.64837432]\n",
      " [ 0.99025794 -0.29461747 -0.69598265]\n",
      " [-1.40913964  0.15173686  1.25781911]\n",
      " [-0.64670257 -0.28665537  0.93350262]]\n",
      "152000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.30421549395755176\n",
      "[[ 0.38823966  0.26269917 -0.65106849]\n",
      " [ 0.993025   -0.29487296 -0.69849423]\n",
      " [-1.41279672  0.15100908  1.26220398]\n",
      " [-0.64838743 -0.28873511  0.93726722]]\n",
      "153000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.30339155324147865\n",
      "[[ 0.3894399   0.26418284 -0.65375239]\n",
      " [ 0.9957809  -0.29512404 -0.70099903]\n",
      " [-1.41643821  0.15028175  1.26657279]\n",
      " [-0.65006528 -0.29080899  0.94101896]]\n",
      "154000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3025735294659839\n",
      "[[ 0.39063599  0.26566047 -0.65642611]\n",
      " [ 0.99852572 -0.29537078 -0.70349712]\n",
      " [-1.42006426  0.14955494  1.27092566]\n",
      " [-0.6517362  -0.29287703  0.94475791]]\n",
      "155000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.30176135384699354\n",
      "[[ 0.39182795  0.26713209 -0.6590897 ]\n",
      " [ 1.00125959 -0.29561324 -0.70598854]\n",
      " [-1.42367504  0.14882867  1.27526271]\n",
      " [-0.65340025 -0.29493925  0.94848418]]\n",
      "156000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.30095495882711876\n",
      "[[ 0.39301582  0.26859774 -0.66174322]\n",
      " [ 1.00398261 -0.29585147 -0.70847332]\n",
      " [-1.42727072  0.14810298  1.27958407]\n",
      " [-0.65505751 -0.29699565  0.95219785]]\n",
      "157000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.3001542780434095\n",
      "[[ 0.39419964  0.27005745 -0.66438674]\n",
      " [ 1.00669489 -0.29608553 -0.71095153]\n",
      " [-1.43085145  0.14737793  1.28388986]\n",
      " [-0.65670806 -0.29904627  0.95589901]]\n",
      "158000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.2993592462962456\n",
      "[[ 0.39537944  0.27151124 -0.66702033]\n",
      " [ 1.00939652 -0.29631549 -0.71342321]\n",
      " [-1.4344174   0.14665355  1.28818018]\n",
      " [-0.65835196 -0.3010911   0.95958775]]\n",
      "159000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.29856979951931767\n",
      "[[ 0.39655524  0.27295915 -0.66964405]\n",
      " [ 1.01208761 -0.29654139 -0.7158884 ]\n",
      " [-1.43796872  0.14592988  1.29245517]\n",
      " [-0.65998929 -0.30313018  0.96326415]]\n",
      "160000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.29778587475065216\n",
      "[[ 0.39772709  0.27440121 -0.67225795]\n",
      " [ 1.01476825 -0.2967633  -0.71834714]\n",
      " [-1.44150555  0.14520695  1.29671494]\n",
      " [-0.6616201  -0.3051635   0.96692829]]\n",
      "161000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.2970074101046343\n",
      "[[ 0.398895    0.27583745 -0.67486211]\n",
      " [ 1.01743856 -0.29698125 -0.72079948]\n",
      " [-1.44502805  0.14448479  1.30095959]\n",
      " [-0.66324448 -0.3071911   0.97058027]]\n",
      "162000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.2962343447449887\n",
      "[[ 0.40005903  0.27726789 -0.67745657]\n",
      " [ 1.02009861 -0.29719532 -0.72324547]\n",
      " [-1.44853636  0.14376346  1.30518924]\n",
      " [-0.66486248 -0.30921299  0.97422016]]\n",
      "163000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.2954666188586774\n",
      "[[ 0.40121918  0.27869258 -0.68004141]\n",
      " [ 1.02274851 -0.29740555 -0.72568514]\n",
      " [-1.45203063  0.14304297  1.309404  ]\n",
      " [-0.66647416 -0.31122919  0.97784804]]\n",
      "164000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.29470417363067514\n",
      "[[ 0.4023755   0.28011153 -0.68261668]\n",
      " [ 1.02538835 -0.29761199 -0.72811854]\n",
      " [-1.45551099  0.14232335  1.31360397]\n",
      " [-0.6680796  -0.31323971  0.98146399]]\n",
      "165000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.2939469512195874\n",
      "[[ 0.40352801  0.28152478 -0.68518244]\n",
      " [ 1.02801821 -0.29781469 -0.7305457 ]\n",
      " [-1.45897759  0.14160465  1.31778927]\n",
      " [-0.66967884 -0.31524458  0.98506811]]\n",
      "166000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.2931948947340762\n",
      "[[ 0.40467674  0.28293236 -0.68773875]\n",
      " [ 1.0306382  -0.29801371 -0.73296667]\n",
      " [-1.46243056  0.14088689  1.32196001]\n",
      " [-0.67127196 -0.3172438   0.98866045]]\n",
      "167000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.2924479482100606\n",
      "[[ 0.40582172  0.2843343  -0.69028567]\n",
      " [ 1.03324839 -0.29820908 -0.73538149]\n",
      " [-1.46587003  0.14017009  1.32611627]\n",
      " [-0.67285902 -0.31923741  0.99224111]]\n",
      "168000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.2917060565886608\n",
      "[[ 0.40696298  0.28573062 -0.69282326]\n",
      " [ 1.03584888 -0.29840086 -0.7377902 ]\n",
      " [-1.46929614  0.1394543   1.33025818]\n",
      " [-0.67444006 -0.32122541  0.99581016]]\n",
      "169000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.2909691656948548\n",
      "[[ 0.40810055  0.28712137 -0.69535157]\n",
      " [ 1.03843974 -0.29858909 -0.74019283]\n",
      " [-1.47270901  0.13873952  1.33438582]\n",
      " [-0.67601516 -0.32320783  0.99936767]]\n",
      "170000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.2902372222168193\n",
      "[[ 0.40923445  0.28850656 -0.69787066]\n",
      " [ 1.04102107 -0.29877382 -0.74258943]\n",
      " [-1.47610876  0.13802579  1.3384993 ]\n",
      " [-0.67758436 -0.32518469  1.00291373]]\n",
      "171000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.2895101736859302\n",
      "[[ 0.41036471  0.28988623 -0.70038059]\n",
      " [ 1.04359294 -0.2989551  -0.74498002]\n",
      " [-1.47949553  0.13731314  1.34259872]\n",
      " [-0.67914772 -0.327156    1.00644841]]\n",
      "172000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.2887879684573919\n",
      "[[ 0.41149136  0.2912604  -0.70288141]\n",
      " [ 1.04615544 -0.29913296 -0.74736466]\n",
      " [-1.48286944  0.13660159  1.34668418]\n",
      " [-0.6807053  -0.32912179  1.00997177]]\n",
      "173000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.2880705556914754\n",
      "[[ 0.41261441  0.29262911 -0.70537318]\n",
      " [ 1.04870865 -0.29930746 -0.74974337]\n",
      " [-1.4862306   0.13589116  1.35075578]\n",
      " [-0.68225715 -0.33108207  1.0134839 ]]\n",
      "174000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.2873578853353385\n",
      "[[ 0.41373391  0.29399239 -0.70785595]\n",
      " [ 1.05125264 -0.29947863 -0.75211619]\n",
      " [-1.48957913  0.13518187  1.3548136 ]\n",
      " [-0.68380332 -0.33303687  1.01698487]]\n",
      "175000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.2866499081054064\n",
      "[[ 0.41484988  0.29535026 -0.71032979]\n",
      " [ 1.05378749 -0.29964651 -0.75448316]\n",
      " [-1.49291516  0.13447375  1.35885774]\n",
      " [-0.68534387 -0.3349862   1.02047475]]\n",
      "176000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.28594657547029184\n",
      "[[ 0.41596233  0.29670275 -0.71279473]\n",
      " [ 1.05631329 -0.29981116 -0.75684431]\n",
      " [-1.49623879  0.13376681  1.36288831]\n",
      " [-0.68687884 -0.33693008  1.02395361]]\n",
      "177000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.28524783963423184\n",
      "[[ 0.4170713   0.29804989 -0.71525084]\n",
      " [ 1.0588301  -0.2999726  -0.75919968]\n",
      " [-1.49955013  0.13306109  1.36690538]\n",
      " [-0.68840829 -0.33886854  1.02742152]]\n",
      "178000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.28455365352102563\n",
      "[[ 0.4181768   0.29939171 -0.71769817]\n",
      " [ 1.06133799 -0.30013088 -0.7615493 ]\n",
      " [-1.5028493   0.13235659  1.37090905]\n",
      " [-0.68993227 -0.34080159  1.03087854]]\n",
      "179000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.28386397075844944\n",
      "[[ 0.41927887  0.30072824 -0.72013677]\n",
      " [ 1.06383705 -0.30028604 -0.7638932 ]\n",
      " [-1.50613641  0.13165333  1.37489942]\n",
      " [-0.69145082 -0.34272926  1.03432476]]\n",
      "180000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.2831787456631354\n",
      "[[ 0.42037753  0.30205951 -0.7225667 ]\n",
      " [ 1.06632735 -0.30043811 -0.76623142]\n",
      " [-1.50941156  0.13095134  1.37887656]\n",
      " [-0.692964   -0.34465156  1.03776024]]\n",
      "181000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.2824979332258931\n",
      "[[ 0.4214728   0.30338554 -0.724988  ]\n",
      " [ 1.06880895 -0.30058713 -0.76856399]\n",
      " [-1.51267486  0.13025062  1.38284057]\n",
      " [-0.69447184 -0.34656851  1.04118504]]\n",
      "182000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.2818214890974612\n",
      "[[ 0.4225647   0.30470637 -0.72740073]\n",
      " [ 1.07128192 -0.30073315 -0.77089095]\n",
      " [-1.51592641  0.12955121  1.38679153]\n",
      " [-0.69597441 -0.34848014  1.04459924]]\n",
      "183000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.28114936957466835\n",
      "[[ 0.42365327  0.30602202 -0.72980494]\n",
      " [ 1.07374633 -0.3008762  -0.77321232]\n",
      " [-1.51916631  0.12885311  1.39072954]\n",
      " [-0.69747173 -0.35038647  1.04800289]]\n",
      "184000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.2804815315869958\n",
      "[[ 0.42473851  0.30733251 -0.73220068]\n",
      " [ 1.07620226 -0.3010163  -0.77552814]\n",
      " [-1.52239467  0.12815634  1.39465467]\n",
      " [-0.69896387 -0.35228751  1.05139607]]\n",
      "185000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.2798179326835185\n",
      "[[ 0.42582045  0.30863789 -0.73458799]\n",
      " [ 1.07864977 -0.30115351 -0.77783844]\n",
      " [-1.52561158  0.12746091  1.39856701]\n",
      " [-0.70045085 -0.3541833   1.05477884]]\n",
      "186000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.2791585310202179\n",
      "[[ 0.42689912  0.30993817 -0.73696694]\n",
      " [ 1.08108892 -0.30128785 -0.78014325]\n",
      " [-1.52881714  0.12676684  1.40246664]\n",
      " [-0.70193274 -0.35607384  1.05815126]]\n",
      "187000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.2785032853476493\n",
      "[[ 0.42797454  0.31123338 -0.73933757]\n",
      " [ 1.08351977 -0.30141936 -0.7824426 ]\n",
      " [-1.53201145  0.12607414  1.40635365]\n",
      " [-0.70340956 -0.35795915  1.0615134 ]]\n",
      "188000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.2778521549989537\n",
      "[[ 0.42904672  0.31252355 -0.74169992]\n",
      " [ 1.0859424  -0.30154806 -0.78473652]\n",
      " [-1.5351946   0.12538282  1.41022811]\n",
      " [-0.70488136 -0.35983927  1.06486532]]\n",
      "189000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.2772050998781987\n",
      "[[ 0.4301157   0.31380871 -0.74405406]\n",
      " [ 1.08835687 -0.30167401 -0.78702504]\n",
      " [-1.53836668  0.1246929   1.41409011]\n",
      " [-0.70634818 -0.36171421  1.06820708]]\n",
      "190000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.2765620804490408\n",
      "[[ 0.43118148  0.31508888 -0.74640002]\n",
      " [ 1.09076324 -0.30179722 -0.7893082 ]\n",
      " [-1.54152779  0.1240044   1.41793973]\n",
      " [-0.70781007 -0.36358399  1.07153875]]\n",
      "191000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.27592305772369563\n",
      "[[ 0.4322441   0.31636409 -0.74873785]\n",
      " [ 1.09316156 -0.30191773 -0.79158601]\n",
      " [-1.54467802  0.12331731  1.42177704]\n",
      " [-0.70926707 -0.36544863  1.07486039]]\n",
      "192000 번째 학습중입니다.\n",
      "Accuracy :  0.9666666666666667\n",
      "Loss :      0.2752879932522039\n",
      "[[ 0.43330358  0.31763437 -0.7510676 ]\n",
      " [ 1.09555191 -0.30203557 -0.79385852]\n",
      " [-1.54781745  0.12263165  1.42560213]\n",
      " [-0.7107192  -0.36730816  1.07817205]]\n",
      "193000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.27465684911198734\n",
      "[[ 0.43435992  0.31889974 -0.75338932]\n",
      " [ 1.09793433 -0.30215078 -0.79612574]\n",
      " [-1.55094617  0.12194744  1.42941506]\n",
      " [-0.71216653 -0.36916259  1.0814738 ]]\n",
      "194000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.27402958789768034\n",
      "[[ 0.43541316  0.32016023 -0.75570305]\n",
      " [ 1.1003089  -0.30226337 -0.79838771]\n",
      " [-1.55406427  0.12126468  1.43321592]\n",
      " [-0.71360907 -0.37101195  1.0847657 ]]\n",
      "195000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.2734061727112303\n",
      "[[ 0.43646332  0.32141588 -0.75800885]\n",
      " [ 1.10267566 -0.30237339 -0.80064445]\n",
      " [-1.55717183  0.12058338  1.43700479]\n",
      " [-0.71504687 -0.37285625  1.08804781]]\n",
      "196000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.27278656715225735\n",
      "[[ 0.43751041  0.32266669 -0.76030675]\n",
      " [ 1.10503468 -0.30248087 -0.802896  ]\n",
      " [-1.56026895  0.11990355  1.44078173]\n",
      " [-0.71647998 -0.37469552  1.09132018]]\n",
      "197000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.2721707353086639\n",
      "[[ 0.43855445  0.32391271 -0.76259681]\n",
      " [ 1.10738601 -0.30258582 -0.80514237]\n",
      " [-1.56335569  0.11922521  1.44454682]\n",
      " [-0.71790842 -0.37652978  1.09458288]]\n",
      "198000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.27155864174748634\n",
      "[[ 0.43959546  0.32515395 -0.76487906]\n",
      " [ 1.10972971 -0.30268829 -0.8073836 ]\n",
      " [-1.56643215  0.11854835  1.44830013]\n",
      " [-0.71933223 -0.37835905  1.09783596]]\n",
      "199000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.27095025150598134\n",
      "[[ 0.44063347  0.32639044 -0.76715356]\n",
      " [ 1.11206583 -0.30278829 -0.80961972]\n",
      " [-1.5694984   0.11787299  1.45204174]\n",
      " [-0.72075144 -0.38018334  1.10107947]]\n",
      "200000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.27034553008293666\n",
      "[[ 0.44166848  0.32762221 -0.76942035]\n",
      " [ 1.11439443 -0.30288586 -0.81185075]\n",
      " [-1.57255453  0.11719914  1.45577172]\n",
      " [-0.7221661  -0.38200269  1.10431348]]\n",
      "201000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.26974444343020426\n",
      "[[ 0.44270053  0.32884928 -0.77167946]\n",
      " [ 1.11671556 -0.30298103 -0.81407671]\n",
      " [-1.5756006   0.11652679  1.45949014]\n",
      " [-0.72357624 -0.38381711  1.10753805]]\n",
      "202000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.26914695794444177\n",
      "[[ 0.44372962  0.33007168 -0.77393096]\n",
      " [ 1.11902928 -0.30307382 -0.81629764]\n",
      " [-1.5786367   0.11585596  1.46319707]\n",
      " [-0.7249819  -0.38562663  1.11075321]]\n",
      "203000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.268553040459061\n",
      "[[ 0.44475578  0.33128944 -0.77617487]\n",
      " [ 1.12133563 -0.30316425 -0.81851356]\n",
      " [-1.58166291  0.11518666  1.46689258]\n",
      " [-0.7263831  -0.38743126  1.11395904]]\n",
      "204000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.26796265823637366\n",
      "[[ 0.44577902  0.33250257 -0.77841125]\n",
      " [ 1.12363468 -0.30325237 -0.82072449]\n",
      " [-1.58467929  0.11451889  1.47057673]\n",
      " [-0.72777988 -0.38923102  1.11715559]]\n",
      "205000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.26737577895993137\n",
      "[[ 0.44679937  0.33371111 -0.78064014]\n",
      " [ 1.12592646 -0.30333818 -0.82293047]\n",
      " [-1.58768593  0.11385266  1.4742496 ]\n",
      " [-0.72917228 -0.39102594  1.1203429 ]]\n",
      "206000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.2667923707270491\n",
      "[[ 0.44781684  0.33491508 -0.78286157]\n",
      " [ 1.12821104 -0.30342171 -0.8251315 ]\n",
      " [-1.5906829   0.11318797  1.47791126]\n",
      " [-0.73056032 -0.39281604  1.12352104]]\n",
      "207000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.2662124020415108\n",
      "[[ 0.44883144  0.3361145  -0.78507559]\n",
      " [ 1.13048845 -0.303503   -0.82732763]\n",
      " [-1.59367026  0.11252483  1.48156177]\n",
      " [-0.73194404 -0.39460133  1.12669006]]\n",
      "208000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.2656358418064486\n",
      "[[ 0.4498432   0.33730939 -0.78728225]\n",
      " [ 1.13275876 -0.30358206 -0.82951888]\n",
      " [-1.59664809  0.11186324  1.48520119]\n",
      " [-0.73332347 -0.39638184  1.12985   ]]\n",
      "209000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.26506265931739154\n",
      "[[ 0.45085213  0.3384998  -0.78948158]\n",
      " [ 1.135022   -0.30365893 -0.83170526]\n",
      " [-1.59961647  0.11120321  1.4888296 ]\n",
      " [-0.73469865 -0.39815759  1.13300093]]\n",
      "210000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.2644928242554796\n",
      "[[ 0.45185825  0.33968572 -0.79167363]\n",
      " [ 1.13727824 -0.30373361 -0.8338868 ]\n",
      " [-1.60257545  0.11054473  1.49244705]\n",
      " [-0.7360696  -0.3999286   1.13614289]]\n",
      "211000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.2639263066808332\n",
      "[[ 0.45286158  0.3408672  -0.79385844]\n",
      " [ 1.1395275  -0.30380615 -0.83606354]\n",
      " [-1.60552511  0.10988783  1.49605362]\n",
      " [-0.73743635 -0.40169489  1.13927593]]\n",
      "212000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.26336307702608214\n",
      "[[ 0.45386213  0.34204426 -0.79603604]\n",
      " [ 1.14176985 -0.30387655 -0.83823548]\n",
      " [-1.60846552  0.10923249  1.49964936]\n",
      " [-0.73879894 -0.40345649  1.14240012]]\n",
      "213000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.26280310609003854\n",
      "[[ 0.45485992  0.34321691 -0.79820648]\n",
      " [ 1.14400533 -0.30394485 -0.84040266]\n",
      " [-1.61139674  0.10857872  1.50323435]\n",
      " [-0.7401574  -0.4052134   1.14551548]]\n",
      "214000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.26224636503151977\n",
      "[[ 0.45585496  0.34438519 -0.80036981]\n",
      " [ 1.14623399 -0.30401107 -0.8425651 ]\n",
      " [-1.61431883  0.10792653  1.50680863]\n",
      " [-0.74151175 -0.40696565  1.14862208]]\n",
      "215000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.26169282536330807\n",
      "[[ 0.45684728  0.34554911 -0.80252605]\n",
      " [ 1.14845586 -0.30407522 -0.84472282]\n",
      " [-1.61723187  0.10727592  1.51037228]\n",
      " [-0.74286202 -0.40871327  1.15171997]]\n",
      "216000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.26114245894625016\n",
      "[[ 0.45783689  0.3467087  -0.80467524]\n",
      " [ 1.150671   -0.30413734 -0.84687584]\n",
      " [-1.62013592  0.10662689  1.51392536]\n",
      " [-0.74420824 -0.41045627  1.15480919]]\n",
      "217000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.26059523798348644\n",
      "[[ 0.45882379  0.34786399 -0.80681744]\n",
      " [ 1.15287945 -0.30419743 -0.84902419]\n",
      " [-1.62303103  0.10597945  1.51746792]\n",
      " [-0.74555044 -0.41219467  1.1578898 ]]\n",
      "218000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.260051135014812\n",
      "[[ 0.45980802  0.34901499 -0.80895267]\n",
      " [ 1.15508125 -0.30425554 -0.85116789]\n",
      " [-1.62591728  0.10533359  1.52100003]\n",
      " [-0.74688865 -0.4139285   1.16096184]]\n",
      "219000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.25951012291115944\n",
      "[[ 0.46078959  0.35016174 -0.81108098]\n",
      " [ 1.15727645 -0.30431166 -0.85330696]\n",
      " [-1.62879473  0.10468931  1.52452174]\n",
      " [-0.7482229  -0.41565777  1.16402536]]\n",
      "220000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.25897217486920543\n",
      "[[ 0.4617685   0.35130424 -0.8132024 ]\n",
      " [ 1.15946508 -0.30436583 -0.85544143]\n",
      " [-1.63166343  0.10404663  1.52803313]\n",
      " [-0.74955321 -0.4173825   1.1670804 ]]\n",
      "221000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.25843726440609455\n",
      "[[ 0.46274478  0.35244253 -0.81531697]\n",
      " [ 1.1616472  -0.30441807 -0.85757131]\n",
      " [-1.63452344  0.10340554  1.53153424]\n",
      " [-0.75087962 -0.41910272  1.17012702]]\n",
      "222000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.2579053653542766\n",
      "[[ 0.46371844  0.35357663 -0.81742473]\n",
      " [ 1.16382285 -0.3044684  -0.85969663]\n",
      " [-1.63737484  0.10276604  1.53502513]\n",
      " [-0.75220213 -0.42081844  1.17316526]]\n",
      "223000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.25737645185645797\n",
      "[[ 0.4646895   0.35470657 -0.81952572]\n",
      " [ 1.16599206 -0.30451683 -0.86181741]\n",
      " [-1.64021766  0.10212814  1.53850586]\n",
      " [-0.7535208  -0.42252969  1.17619517]]\n",
      "224000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.25685049836065793\n",
      "[[ 0.46565796  0.35583235 -0.82161997]\n",
      " [ 1.16815487 -0.30456339 -0.86393366]\n",
      " [-1.64305198  0.10149182  1.54197649]\n",
      " [-0.75483563 -0.42423648  1.1792168 ]]\n",
      "225000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.2563274796153724\n",
      "[[ 0.46662386  0.35695401 -0.82370752]\n",
      " [ 1.17031134 -0.30460809 -0.86604542]\n",
      " [-1.64587786  0.10085711  1.54543708]\n",
      " [-0.75614666 -0.42593883  1.18223018]]\n",
      "226000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.2558073706648388\n",
      "[[ 0.46758719  0.35807157 -0.82578841]\n",
      " [ 1.17246149 -0.30465096 -0.8681527 ]\n",
      " [-1.64869534  0.10022399  1.54888768]\n",
      " [-0.75745391 -0.42763677  1.18523536]]\n",
      "227000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.2552901468444022\n",
      "[[ 0.46854798  0.35918504 -0.82786267]\n",
      " [ 1.17460536 -0.30469201 -0.87025553]\n",
      " [-1.65150448  0.09959247  1.55232835]\n",
      " [-0.7587574  -0.42933031  1.1882324 ]]\n",
      "228000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.2547757837759758\n",
      "[[ 0.46950623  0.36029446 -0.82993035]\n",
      " [ 1.17674301 -0.30473127 -0.87235392]\n",
      " [-1.65430534  0.09896254  1.55575914]\n",
      " [-0.76005717 -0.43101947  1.19122133]]\n",
      "229000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.2542642573635971\n",
      "[[ 0.47046197  0.36139984 -0.83199147]\n",
      " [ 1.17887445 -0.30476874 -0.87444789]\n",
      " [-1.65709798  0.09833421  1.5591801 ]\n",
      " [-0.76135323 -0.43270428  1.1942022 ]]\n",
      "230000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.2537555437890754\n",
      "[[ 0.47141521  0.36250121 -0.83404607]\n",
      " [ 1.18099975 -0.30480446 -0.87653747]\n",
      " [-1.65988244  0.09770747  1.5625913 ]\n",
      " [-0.76264562 -0.43438475  1.19717505]]\n",
      "231000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.25324961950772856\n",
      "[[ 0.47236595  0.36359859 -0.83609419]\n",
      " [ 1.18311892 -0.30483843 -0.87862267]\n",
      " [-1.66265879  0.09708234  1.56599278]\n",
      " [-0.76393434 -0.4360609   1.20013992]]\n",
      "232000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.25274646124420613\n",
      "[[ 0.47331422  0.36469199 -0.83813587]\n",
      " [ 1.18523201 -0.30487067 -0.88070352]\n",
      " [-1.66542707  0.0964588   1.56938461]\n",
      " [-0.76521944 -0.43773275  1.20309687]]\n",
      "233000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.2522460459883971\n",
      "[[ 0.47426003  0.36578144 -0.84017113]\n",
      " [ 1.18733906 -0.30490121 -0.88278004]\n",
      " [-1.66818734  0.09583685  1.57276682]\n",
      " [-0.76650092 -0.43940032  1.20604592]]\n",
      "234000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.25174835099142046\n",
      "[[ 0.4752034   0.36686696 -0.84220001]\n",
      " [ 1.18944011 -0.30493005 -0.88485224]\n",
      " [-1.67093964  0.0952165   1.57613948]\n",
      " [-0.76777882 -0.44106363  1.20898713]]\n",
      "235000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.25125335376169505\n",
      "[[ 0.47614432  0.36794857 -0.84422255]\n",
      " [ 1.19153518 -0.30495722 -0.88692014]\n",
      " [-1.67368404  0.09459774  1.57950263]\n",
      " [-0.76905316 -0.44272269  1.21192054]]\n",
      "236000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.25076103206108885\n",
      "[[ 0.47708283  0.36902629 -0.84623878]\n",
      " [ 1.19362432 -0.30498273 -0.88898377]\n",
      " [-1.67642058  0.09398057  1.58285634]\n",
      " [-0.77032396 -0.44437754  1.21484618]]\n",
      "237000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.25027136390114213\n",
      "[[ 0.47801892  0.37010015 -0.84824873]\n",
      " [ 1.19570756 -0.3050066  -0.89104314]\n",
      " [-1.67914931  0.093365    1.58620064]\n",
      " [-0.77159124 -0.44602818  1.2177641 ]]\n",
      "238000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.2497843275393667\n",
      "[[ 0.47895262  0.37117016 -0.85025244]\n",
      " [ 1.19778494 -0.30502885 -0.89309827]\n",
      " [-1.68187028  0.09275102  1.5895356 ]\n",
      " [-0.77285502 -0.44767464  1.22067434]]\n",
      "239000 번째 학습중입니다.\n",
      "Accuracy :  0.9733333333333334\n",
      "Loss :      0.24929990147561634\n",
      "[[ 0.47988394  0.37223634 -0.85224994]\n",
      " [ 1.19985649 -0.30504949 -0.89514918]\n",
      " [-1.68458354  0.09213862  1.59286125]\n",
      " [-0.77411533 -0.44931693  1.22357695]]\n",
      "240000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2488180644485279\n",
      "[[ 0.48081289  0.37329872 -0.85424127]\n",
      " [ 1.20192225 -0.30506853 -0.89719589]\n",
      " [-1.68728914  0.09152782  1.59617765]\n",
      " [-0.77537219 -0.45095507  1.22647195]]\n",
      "241000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.24833879543203183\n",
      "[[ 0.48173948  0.37435731 -0.85622645]\n",
      " [ 1.20398225 -0.305086   -0.89923842]\n",
      " [-1.68998712  0.0909186   1.59948486]\n",
      " [-0.77662562 -0.45258909  1.2293594 ]]\n",
      "242000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.24786207363192644\n",
      "[[ 0.48266373  0.37541214 -0.85820553]\n",
      " [ 1.20603652 -0.30510191 -0.90127679]\n",
      " [-1.69267754  0.09031096  1.60278291]\n",
      " [-0.77787564 -0.454219    1.23223932]]\n",
      "243000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.24738787848252278\n",
      "[[ 0.48358565  0.37646322 -0.86017852]\n",
      " [ 1.2080851  -0.30511627 -0.90331102]\n",
      " [-1.69536044  0.08970491  1.60607186]\n",
      " [-0.77912227 -0.45584481  1.23511177]]\n",
      "244000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.24691618964334747\n",
      "[[ 0.48450525  0.37751057 -0.86214547]\n",
      " [ 1.21012803 -0.3051291  -0.90534111]\n",
      " [-1.69803586  0.08910044  1.60935176]\n",
      " [-0.78036554 -0.45746656  1.23797678]]\n",
      "245000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.24644698699591194\n",
      "[[ 0.48542254  0.37855422 -0.86410641]\n",
      " [ 1.21216533 -0.30514041 -0.9073671 ]\n",
      " [-1.70070386  0.08849754  1.61262265]\n",
      " [-0.78160546 -0.45908424  1.24083439]]\n",
      "246000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.24598025064054013\n",
      "[[ 0.48633753  0.37959418 -0.86606137]\n",
      " [ 1.21419704 -0.30515022 -0.909389  ]\n",
      " [-1.70336448  0.08789623  1.61588459]\n",
      " [-0.78284205 -0.4606979   1.24368463]]\n",
      "247000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.245515960893255\n",
      "[[ 0.48725024  0.38063048 -0.86801038]\n",
      " [ 1.21622319 -0.30515854 -0.91140682]\n",
      " [-1.70601776  0.08729648  1.61913761]\n",
      " [-0.78407534 -0.46230753  1.24652755]]\n",
      "248000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.24505409828272415\n",
      "[[ 0.48816069  0.38166312 -0.86995346]\n",
      " [ 1.21824381 -0.30516539 -0.9134206 ]\n",
      " [-1.70866375  0.08669831  1.62238177]\n",
      " [-0.78530534 -0.46391316  1.24936319]]\n",
      "249000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2445946435472609\n",
      "[[ 0.48906887  0.38269214 -0.87189067]\n",
      " [ 1.22025893 -0.30517078 -0.91543033]\n",
      " [-1.71130249  0.08610171  1.62561711]\n",
      " [-0.78653207 -0.46551481  1.25219157]]\n",
      "250000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2441375776318796\n",
      "[[ 0.4899748   0.38371755 -0.87382201]\n",
      " [ 1.22226859 -0.30517473 -0.91743604]\n",
      " [-1.71393402  0.08550667  1.62884368]\n",
      " [-0.78775556 -0.4671125   1.25501275]]\n",
      "251000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.24368288168540658\n",
      "[[ 0.4908785   0.38473937 -0.87574753]\n",
      " [ 1.22427282 -0.30517725 -0.91943776]\n",
      " [-1.71655839  0.0849132   1.63206152]\n",
      " [-0.78897582 -0.46870625  1.25782675]]\n",
      "252000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.24323053705764153\n",
      "[[ 0.49177998  0.38575761 -0.87766725]\n",
      " [ 1.22627165 -0.30517835 -0.92143548]\n",
      " [-1.71917565  0.0843213   1.63527068]\n",
      " [-0.79019287 -0.47029606  1.26063362]]\n",
      "253000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.24278052529657126\n",
      "[[ 0.49267924  0.38677231 -0.87958121]\n",
      " [ 1.2282651  -0.30517804 -0.92342924]\n",
      " [-1.72178583  0.08373095  1.63847121]\n",
      " [-0.79140673 -0.47188196  1.26343338]]\n",
      "254000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.24233282814563248\n",
      "[[ 0.49357631  0.38778347 -0.88148943]\n",
      " [ 1.23025321 -0.30517635 -0.92541905]\n",
      " [-1.72438897  0.08314216  1.64166315]\n",
      " [-0.79261743 -0.47346397  1.26622608]]\n",
      "255000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.24188742754102507\n",
      "[[ 0.49447118  0.38879111 -0.88339194]\n",
      " [ 1.23223601 -0.30517327 -0.92740492]\n",
      " [-1.72698512  0.08255492  1.64484654]\n",
      " [-0.79382497 -0.47504211  1.26901176]]\n",
      "256000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2414443056090704\n",
      "[[ 0.49536387  0.38979525 -0.88528878]\n",
      " [ 1.23421353 -0.30516884 -0.92938688]\n",
      " [-1.72957432  0.08196923  1.64802142]\n",
      " [-0.79502937 -0.47661638  1.27179044]]\n",
      "257000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.24100344466361923\n",
      "[[ 0.4962544   0.39079592 -0.88717998]\n",
      " [ 1.2361858  -0.30516305 -0.93136493]\n",
      " [-1.7321566   0.08138509  1.65118785]\n",
      " [-0.79623066 -0.47818682  1.27456217]]\n",
      "258000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2405648272035025\n",
      "[[ 0.49714277  0.39179313 -0.88906555]\n",
      " [ 1.23815284 -0.30515592 -0.9333391 ]\n",
      " [-1.73473202  0.08080249  1.65434586]\n",
      " [-0.79742886 -0.47975343  1.27732697]]\n",
      "259000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.24012843591002905\n",
      "[[ 0.498029    0.39278689 -0.89094554]\n",
      " [ 1.24011469 -0.30514747 -0.9353094 ]\n",
      " [-1.7373006   0.08022144  1.6574955 ]\n",
      " [-0.79862397 -0.48131624  1.28008489]]\n",
      "260000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.23969425364452596\n",
      "[[ 0.49891309  0.39377723 -0.89281997]\n",
      " [ 1.24207137 -0.3051377  -0.93727585]\n",
      " [-1.73986239  0.07964192  1.66063681]\n",
      " [-0.79981602 -0.48287526  1.28283596]]\n",
      "261000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.23926226344591964\n",
      "[[ 0.49979505  0.39476415 -0.89468886]\n",
      " [ 1.24402292 -0.30512663 -0.93923847]\n",
      " [-1.74241743  0.07906394  1.66376983]\n",
      " [-0.80100503 -0.4844305   1.28558021]]\n",
      "262000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2388324485283619\n",
      "[[ 0.50067491  0.3957477  -0.89655225]\n",
      " [ 1.24596935 -0.30511427 -0.94119726]\n",
      " [-1.74496575  0.07848749  1.6668946 ]\n",
      " [-0.80219101 -0.48598199  1.28831768]]\n",
      "263000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.23840479227889394\n",
      "[[ 0.50155266  0.39672786 -0.89841017]\n",
      " [ 1.24791071 -0.30510064 -0.94315225]\n",
      " [-1.7475074   0.07791256  1.67001117]\n",
      " [-0.80337398 -0.48752974  1.2910484 ]]\n",
      "264000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.23797927825515178\n",
      "[[ 0.50242831  0.39770468 -0.90026265]\n",
      " [ 1.24984701 -0.30508573 -0.94510345]\n",
      " [-1.75004241  0.07733917  1.67311958]\n",
      " [-0.80455395 -0.48907377  1.29377241]]\n",
      "265000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.23755589018310977\n",
      "[[ 0.50330189  0.39867815 -0.9021097 ]\n",
      " [ 1.25177828 -0.30506958 -0.94705089]\n",
      " [-1.75257082  0.07676729  1.67621986]\n",
      " [-0.80573095 -0.4906141   1.29648973]]\n",
      "266000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.237134611954863\n",
      "[[ 0.5041734   0.39964831 -0.90395136]\n",
      " [ 1.25370456 -0.30505218 -0.94899456]\n",
      " [-1.75509266  0.07619693  1.67931206]\n",
      " [-0.80690499 -0.49215073  1.29920041]]\n",
      "267000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.23671542762644635\n",
      "[[ 0.50504284  0.40061516 -0.90578766]\n",
      " [ 1.25562586 -0.30503355 -0.95093449]\n",
      " [-1.75760798  0.07562809  1.68239622]\n",
      " [-0.80807609 -0.4936837   1.30190447]]\n",
      "268000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.23629832141569002\n",
      "[[ 0.50591023  0.40157873 -0.90761862]\n",
      " [ 1.25754222 -0.3050137  -0.9528707 ]\n",
      " [-1.7601168   0.07506075  1.68547238]\n",
      " [-0.80924426 -0.49521301  1.30460195]]\n",
      "269000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.23588327770011105\n",
      "[[ 0.50677558  0.40253903 -0.90944427]\n",
      " [ 1.25945365 -0.30499264 -0.9548032 ]\n",
      " [-1.76261918  0.07449493  1.68854058]\n",
      " [-0.81040952 -0.49673868  1.30729289]]\n",
      "270000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.23547028101484008\n",
      "[[ 0.50763891  0.40349608 -0.91126464]\n",
      " [ 1.2613602  -0.30497038 -0.956732  ]\n",
      " [-1.76511513  0.0739306   1.69160086]\n",
      " [-0.81157189 -0.49826073  1.3099773 ]]\n",
      "271000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.23505931605058134\n",
      "[[ 0.50850021  0.40444989 -0.91307975]\n",
      " [ 1.26326188 -0.30494694 -0.95865712]\n",
      " [-1.7676047   0.07336778  1.69465326]\n",
      " [-0.81273137 -0.49977917  1.31265523]]\n",
      "272000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2346503676516071\n",
      "[[ 0.5093595   0.40540048 -0.91488963]\n",
      " [ 1.26515871 -0.30492232 -0.96057858]\n",
      " [-1.77008793  0.07280645  1.69769781]\n",
      " [-0.813888   -0.50129402  1.3153267 ]]\n",
      "273000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2342434208137852\n",
      "[[ 0.51021678  0.40634788 -0.91669431]\n",
      " [ 1.26705074 -0.30489653 -0.96249639]\n",
      " [-1.77256484  0.07224661  1.70073456]\n",
      " [-0.81504177 -0.5028053   1.31799176]]\n",
      "274000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.23383846068263697\n",
      "[[ 0.51107208  0.40729208 -0.91849382]\n",
      " [ 1.26893797 -0.30486959 -0.96441056]\n",
      " [-1.77503547  0.07168827  1.70376354]\n",
      " [-0.81619272 -0.50431302  1.32065042]]\n",
      "275000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.23343547255142927\n",
      "[[ 0.51192539  0.40823312 -0.92028817]\n",
      " [ 1.27082043 -0.3048415  -0.96632111]\n",
      " [-1.77749986  0.0711314   1.70678479]\n",
      " [-0.81734084 -0.50581719  1.32330272]]\n",
      "276000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2330344418592933\n",
      "[[ 0.51277674  0.409171   -0.92207739]\n",
      " [ 1.27269816 -0.30481228 -0.96822805]\n",
      " [-1.77995804  0.07057602  1.70979835]\n",
      " [-0.81848617 -0.50731784  1.3259487 ]]\n",
      "277000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.23263535418937947\n",
      "[[ 0.51362612  0.41010575 -0.92386152]\n",
      " [ 1.27457116 -0.30478194 -0.97013141]\n",
      " [-1.78241004  0.07002211  1.71280426]\n",
      " [-0.81962871 -0.50881498  1.32858837]]\n",
      "278000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.23223819526703618\n",
      "[[ 0.51447354  0.41103737 -0.92564057]\n",
      " [ 1.27643948 -0.30475048 -0.97203118]\n",
      " [-1.78485589  0.06946967  1.71580256]\n",
      " [-0.82076848 -0.51030862  1.33122179]]\n",
      "279000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.23184295095802004\n",
      "[[ 0.51531902  0.41196589 -0.92741457]\n",
      " [ 1.27830313 -0.30471792 -0.9739274 ]\n",
      " [-1.78729564  0.0689187   1.71879327]\n",
      " [-0.82190549 -0.51179878  1.33384896]]\n",
      "280000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.23144960726673564\n",
      "[[ 0.51616257  0.41289132 -0.92918355]\n",
      " [ 1.28016214 -0.30468426 -0.97582006]\n",
      " [-1.78972931  0.0683692   1.72177644]\n",
      " [-0.82303976 -0.51328548  1.33646993]]\n",
      "281000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.23105815033450008\n",
      "[[ 0.51700419  0.41381368 -0.93094752]\n",
      " [ 1.28201653 -0.30464952 -0.97770919]\n",
      " [-1.79215693  0.06782116  1.72475211]\n",
      " [-0.8241713  -0.51476873  1.33908472]]\n",
      "282000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.23066856643783812\n",
      "[[ 0.5178439   0.41473297 -0.93270653]\n",
      " [ 1.28386632 -0.3046137  -0.9795948 ]\n",
      " [-1.79457855  0.06727457  1.72772031]\n",
      " [-0.82530013 -0.51624854  1.34169336]]\n",
      "283000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.23028084198680218\n",
      "[[ 0.5186817   0.41564923 -0.93446058]\n",
      " [ 1.28571154 -0.30457682 -0.9814769 ]\n",
      " [-1.79699417  0.06672944  1.73068107]\n",
      " [-0.82642626 -0.51772494  1.34429589]]\n",
      "284000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.22989496352331837\n",
      "[[ 0.5195176   0.41656245 -0.9362097 ]\n",
      " [ 1.28755221 -0.30453888 -0.98335551]\n",
      " [-1.79940385  0.06618575  1.73363444]\n",
      " [-0.82754971 -0.51919793  1.34689233]]\n",
      "285000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.22951091771955864\n",
      "[[ 0.52035161  0.41747267 -0.93795393]\n",
      " [ 1.28938836 -0.30449989 -0.98523065]\n",
      " [-1.80180761  0.0656435   1.73658044]\n",
      " [-0.82867048 -0.52066753  1.3494827 ]]\n",
      "286000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.22912869137633876\n",
      "[[ 0.52118373  0.41837989 -0.93969328]\n",
      " [ 1.29122    -0.30445987 -0.98710231]\n",
      " [-1.80420549  0.0651027   1.73951912]\n",
      " [-0.8297886  -0.52213376  1.35206705]]\n",
      "287000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2287482714215397\n",
      "[[ 0.52201399  0.41928412 -0.94142777]\n",
      " [ 1.29304717 -0.30441882 -0.98897053]\n",
      " [-1.8065975   0.06456333  1.74245051]\n",
      " [-0.83090408 -0.52359663  1.3546454 ]]\n",
      "288000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.22836964490855527\n",
      "[[ 0.52284239  0.42018539 -0.94315744]\n",
      " [ 1.29486987 -0.30437675 -0.99083531]\n",
      " [-1.80898369  0.06402539  1.74537463]\n",
      " [-0.83201692 -0.52505616  1.35721777]]\n",
      "289000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.22799279901476016\n",
      "[[ 0.52366893  0.42108371 -0.94488229]\n",
      " [ 1.29668814 -0.30433366 -0.99269666]\n",
      " [-1.81136408  0.06348888  1.74829154]\n",
      " [-0.83312715 -0.52651236  1.3597842 ]]\n",
      "290000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.22761772104000608\n",
      "[[ 0.52449362  0.42197909 -0.94660237]\n",
      " [ 1.298502   -0.30428958 -0.9945546 ]\n",
      " [-1.81373871  0.06295379  1.75120125]\n",
      " [-0.83423478 -0.52796524  1.36234471]]\n",
      "291000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2272443984051354\n",
      "[[ 0.52531648  0.42287155 -0.94831768]\n",
      " [ 1.30031147 -0.3042445  -0.99640914]\n",
      " [-1.8161076   0.06242012  1.75410381]\n",
      " [-0.83533982 -0.52941482  1.36489933]]\n",
      "292000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2268728186505217\n",
      "[[ 0.52613751  0.4237611  -0.95002826]\n",
      " [ 1.30211656 -0.30419844 -0.9982603 ]\n",
      " [-1.81847078  0.06188786  1.75699925]\n",
      " [-0.83644228 -0.53086112  1.36744808]]\n",
      "293000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.22650296943462933\n",
      "[[ 0.52695672  0.42464776 -0.95173413]\n",
      " [ 1.30391731 -0.3041514  -1.00010809]\n",
      " [-1.82082828  0.06135701  1.7598876 ]\n",
      " [-0.83754218 -0.53230415  1.36999101]]\n",
      "294000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.22613483853259608\n",
      "[[ 0.52777411  0.42553154 -0.95343531]\n",
      " [ 1.30571374 -0.3041034  -1.00195252]\n",
      " [-1.82318014  0.06082757  1.7627689 ]\n",
      " [-0.83863952 -0.53374392  1.37252813]]\n",
      "295000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2257684138348372\n",
      "[[ 0.52858971  0.42641245 -0.95513181]\n",
      " [ 1.30750586 -0.30405443 -1.0037936 ]\n",
      " [-1.82552637  0.06029953  1.76564318]\n",
      " [-0.83973433 -0.53518044  1.37505946]]\n",
      "296000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.22540368334566913\n",
      "[[ 0.5294035   0.42729052 -0.95682367]\n",
      " [ 1.30929369 -0.30400452 -1.00563136]\n",
      " [-1.82786701  0.05977288  1.76851046]\n",
      " [-0.84082662 -0.53661374  1.37758505]]\n",
      "297000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.22504063518195408\n",
      "[[ 0.53021552  0.42816574 -0.95851091]\n",
      " [ 1.31107726 -0.30395366 -1.00746579]\n",
      " [-1.83020209  0.05924763  1.77137079]\n",
      " [-0.8419164  -0.53804382  1.38010491]]\n",
      "298000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.22467925757176516\n",
      "[[ 0.53102575  0.42903815 -0.96019355]\n",
      " [ 1.3128566  -0.30390186 -1.00929691]\n",
      " [-1.83253163  0.05872376  1.7742242 ]\n",
      " [-0.84300367 -0.53947071  1.38261907]]\n",
      "299000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.22431953885307063\n",
      "[[ 0.53183421  0.42990775 -0.96187161]\n",
      " [ 1.3146317  -0.30384914 -1.01112474]\n",
      " [-1.83485567  0.05820128  1.77707072]\n",
      " [-0.84408846 -0.5408944   1.38512755]]\n",
      "300000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2239614674724378\n",
      "[[ 0.53264091  0.43077455 -0.96354511]\n",
      " [ 1.31640261 -0.30379551 -1.01294929]\n",
      " [-1.83717422  0.05768018  1.77991037]\n",
      " [-0.84517078 -0.54231493  1.38763039]]\n",
      "301000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2236050319837555\n",
      "[[ 0.53344585  0.43163857 -0.96521408]\n",
      " [ 1.31816934 -0.30374096 -1.01477057]\n",
      " [-1.83948732  0.05716045  1.7827432 ]\n",
      " [-0.84625063 -0.54373229  1.39012761]]\n",
      "302000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2232502210469752\n",
      "[[ 0.53424905  0.43249983 -0.96687853]\n",
      " [ 1.31993191 -0.3036855  -1.01658859]\n",
      " [-1.84179499  0.0566421   1.78556923]\n",
      " [-0.84732803 -0.54514651  1.39261923]]\n",
      "303000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.22289702342687093\n",
      "[[ 0.53505051  0.43335834 -0.9685385 ]\n",
      " [ 1.32169034 -0.30362915 -1.01840336]\n",
      " [-1.84409727  0.05612511  1.7883885 ]\n",
      " [-0.84840299 -0.5465576   1.39510528]]\n",
      "304000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.22254542799181687\n",
      "[[ 0.53585023  0.4342141  -0.97019399]\n",
      " [ 1.32344465 -0.30357192 -1.02021491]\n",
      " [-1.84639417  0.05560948  1.79120103]\n",
      " [-0.84947553 -0.54796557  1.39758579]]\n",
      "305000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.22219542371258208\n",
      "[[ 0.53664823  0.43506714 -0.97184503]\n",
      " [ 1.32519485 -0.3035138  -1.02202323]\n",
      " [-1.84868573  0.0550952   1.79400686]\n",
      " [-0.85054566 -0.54937044  1.40006078]]\n",
      "306000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.22184699966114313\n",
      "[[ 0.53744452  0.43591747 -0.97349164]\n",
      " [ 1.32694098 -0.30345481 -1.02382835]\n",
      " [-1.85097196  0.05458228  1.79680601]\n",
      " [-0.85161338 -0.55077222  1.40253028]]\n",
      "307000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2215001450095139\n",
      "[[ 0.5382391   0.43676509 -0.97513385]\n",
      " [ 1.32868304 -0.30339496 -1.02563027]\n",
      " [-1.85325291  0.05407071  1.79959853]\n",
      " [-0.85267871 -0.55217091  1.40499431]]\n",
      "308000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.22115484902859128\n",
      "[[ 0.53903198  0.43761004 -0.97677167]\n",
      " [ 1.33042106 -0.30333424 -1.027429  ]\n",
      " [-1.85552858  0.05356049  1.80238443]\n",
      " [-0.85374166 -0.55356655  1.40745289]]\n",
      "309000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.22081110108701812\n",
      "[[ 0.53982316  0.4384523  -0.97840512]\n",
      " [ 1.33215506 -0.30327268 -1.02922457]\n",
      " [-1.85779901  0.0530516   1.80516375]\n",
      " [-0.85480224 -0.55495913  1.40990606]]\n",
      "310000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2204688906500615\n",
      "[[ 0.54061266  0.43929191 -0.98003423]\n",
      " [ 1.33388506 -0.30321027 -1.03101697]\n",
      " [-1.86006422  0.05254405  1.80793651]\n",
      " [-0.85586047 -0.55634867  1.41235383]]\n",
      "311000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.22012820727850776\n",
      "[[ 0.54140048  0.44012888 -0.98165901]\n",
      " [ 1.33561107 -0.30314702 -1.03280622]\n",
      " [-1.86232425  0.05203782  1.81070276]\n",
      " [-0.85691635 -0.55773519  1.41479623]]\n",
      "312000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2197890406275727\n",
      "[[ 0.54218663  0.4409632  -0.98327949]\n",
      " [ 1.33733311 -0.30308295 -1.03459234]\n",
      " [-1.8645791   0.05153293  1.81346251]\n",
      " [-0.8579699  -0.5591187   1.41723328]]\n",
      "313000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2194513804458264\n",
      "[[ 0.54297112  0.44179491 -0.98489568]\n",
      " [ 1.3390512  -0.30301805 -1.03637533]\n",
      " [-1.86682881  0.05102936  1.81621579]\n",
      " [-0.85902112 -0.56049921  1.41966501]]\n",
      "314000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2191152165741346\n",
      "[[ 0.54375395  0.44262401 -0.98650761]\n",
      " [ 1.34076537 -0.30295234 -1.03815521]\n",
      " [-1.86907341  0.0505271   1.81896264]\n",
      " [-0.86007003 -0.56187673  1.42209145]]\n",
      "315000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.21878053894461316\n",
      "[[ 0.54453513  0.44345051 -0.9881153 ]\n",
      " [ 1.34247562 -0.30288581 -1.03993199]\n",
      " [-1.87131291  0.05002616  1.82170309]\n",
      " [-0.86111664 -0.56325128  1.42451261]]\n",
      "316000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.21844733757959833\n",
      "[[ 0.54531467  0.44427443 -0.98971876]\n",
      " [ 1.34418198 -0.30281849 -1.04170567]\n",
      " [-1.87354734  0.04952652  1.82443716]\n",
      " [-0.86216097 -0.56462286  1.42692852]]\n",
      "317000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.21811560259063054\n",
      "[[ 0.54609258  0.44509578 -0.99131801]\n",
      " [ 1.34588446 -0.30275037 -1.04347628]\n",
      " [-1.87577673  0.04902819  1.82716488]\n",
      " [-0.86320301 -0.5659915   1.4293392 ]]\n",
      "318000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.21778532417745292\n",
      "[[ 0.54686886  0.44591457 -0.99291308]\n",
      " [ 1.34758309 -0.30268146 -1.04524382]\n",
      " [-1.8780011   0.04853116  1.82988627]\n",
      " [-0.86424278 -0.56735721  1.43174467]]\n",
      "319000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2174564926270227\n",
      "[[ 0.54764351  0.44673082 -0.99450398]\n",
      " [ 1.34927788 -0.30261176 -1.0470083 ]\n",
      " [-1.88022047  0.04803543  1.83260138]\n",
      " [-0.8652803  -0.56871999  1.43414497]]\n",
      "320000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.21712909831253674\n",
      "[[ 0.54841656  0.44754453 -0.99609074]\n",
      " [ 1.35096884 -0.30254129 -1.04876973]\n",
      " [-1.88243487  0.04754098  1.83531022]\n",
      " [-0.86631556 -0.57007986  1.4365401 ]]\n",
      "321000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.21680313169247103\n",
      "[[ 0.54918799  0.44835572 -0.99767336]\n",
      " [ 1.35265601 -0.30247005 -1.05052813]\n",
      " [-1.88464431  0.04704782  1.83801282]\n",
      " [-0.86734859 -0.57143683  1.43893011]]\n",
      "322000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.21647858330963213\n",
      "[[ 0.54995783  0.4491644  -0.99925188]\n",
      " [ 1.35433938 -0.30239805 -1.05228351]\n",
      " [-1.88684883  0.04655595  1.84070922]\n",
      " [-0.8683794  -0.57279091  1.44131499]]\n",
      "323000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.21615544379022186\n",
      "[[ 0.55072608  0.44997058 -1.00082631]\n",
      " [ 1.35601899 -0.30232529 -1.05403588]\n",
      " [-1.88904845  0.04606535  1.84339943]\n",
      " [-0.86940799 -0.57414212  1.44369479]]\n",
      "324000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.21583370384291495\n",
      "[[ 0.55149274  0.45077428 -1.00239667]\n",
      " [ 1.35769484 -0.30225178 -1.05578524]\n",
      " [-1.89124318  0.04557603  1.84608349]\n",
      " [-0.87043437 -0.57549047  1.44606952]]\n",
      "325000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.21551335425794918\n",
      "[[ 0.55225782  0.4515755  -1.00396297]\n",
      " [ 1.35936695 -0.30217752 -1.05753161]\n",
      " [-1.89343305  0.04508797  1.84876141]\n",
      " [-0.87145855 -0.57683597  1.44843921]]\n",
      "326000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.21519438590622778\n",
      "[[ 0.55302132  0.45237426 -1.00552524]\n",
      " [ 1.36103535 -0.30210253 -1.059275  ]\n",
      " [-1.89561809  0.04460118  1.85143324]\n",
      " [-0.87248055 -0.57817863  1.45080387]]\n",
      "327000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2148767897384339\n",
      "[[ 0.55378326  0.45317057 -1.00708349]\n",
      " [ 1.36270005 -0.3020268  -1.06101543]\n",
      " [-1.89779831  0.04411565  1.854099  ]\n",
      " [-0.87350038 -0.57951846  1.45316353]]\n",
      "328000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.21456055678415634\n",
      "[[ 0.55454365  0.45396445 -1.00863775]\n",
      " [ 1.36436106 -0.30195035 -1.06275289]\n",
      " [-1.89997374  0.04363137  1.8567587 ]\n",
      " [-0.87451804 -0.58085548  1.4555182 ]]\n",
      "329000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.21424567815102752\n",
      "[[ 0.55530248  0.45475589 -1.01018803]\n",
      " [ 1.3660184  -0.30187317 -1.06448741]\n",
      " [-1.9021444   0.04314835  1.85941239]\n",
      " [-0.87553354 -0.5821897   1.45786792]]\n",
      "330000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.21393214502387317\n",
      "[[ 0.55605976  0.45554493 -1.01173434]\n",
      " [ 1.36767209 -0.30179528 -1.06621899]\n",
      " [-1.90431032  0.04266657  1.86206007]\n",
      " [-0.87654689 -0.58352113  1.46021271]]\n",
      "331000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.21361994866387335\n",
      "[[ 0.5568155   0.45633155 -1.01327671]\n",
      " [ 1.36932215 -0.30171669 -1.06794764]\n",
      " [-1.9064715   0.04218604  1.86470179]\n",
      " [-0.87755811 -0.58484978  1.46255258]]\n",
      "332000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.21330908040773378\n",
      "[[ 0.55756972  0.45711579 -1.01481516]\n",
      " [ 1.37096858 -0.30163739 -1.06967338]\n",
      " [-1.90862798  0.04170675  1.86733757]\n",
      " [-0.8785672  -0.58617566  1.46488755]]\n",
      "333000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.21299953166686833\n",
      "[[ 0.5583224   0.45789764 -1.0163497 ]\n",
      " [ 1.37261141 -0.30155739 -1.0713962 ]\n",
      " [-1.91077978  0.04122869  1.86996743]\n",
      " [-0.87957418 -0.58749879  1.46721765]]\n",
      "334000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.21269129392659353\n",
      "[[ 0.55907356  0.45867713 -1.01788035]\n",
      " [ 1.37425065 -0.3014767  -1.07311614]\n",
      " [-1.91292691  0.04075185  1.87259139]\n",
      " [-0.88057904 -0.58881917  1.4695429 ]]\n",
      "335000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.21238435874533199\n",
      "[[ 0.55982321  0.45945425 -1.01940712]\n",
      " [ 1.37588633 -0.30139532 -1.07483319]\n",
      " [-1.91506941  0.04027625  1.87520949]\n",
      " [-0.88158181 -0.59013682  1.47186331]]\n",
      "336000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.21207871775382742\n",
      "[[ 0.56057136  0.46022903 -1.02093004]\n",
      " [ 1.37751844 -0.30131326 -1.07654736]\n",
      " [-1.91720728  0.03980186  1.87782175]\n",
      " [-0.88258249 -0.59145175  1.47417892]]\n",
      "337000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.21177436265436894\n",
      "[[ 0.561318    0.46100147 -1.02244913]\n",
      " [ 1.37914702 -0.30123053 -1.07825867]\n",
      " [-1.91934055  0.0393287   1.88042819]\n",
      " [-0.88358108 -0.59276397  1.47648974]]\n",
      "338000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.21147128522002645\n",
      "[[ 0.56206315  0.46177159 -1.02396439]\n",
      " [ 1.38077207 -0.30114713 -1.07996712]\n",
      " [-1.92146924  0.03885674  1.88302883]\n",
      " [-0.88457761 -0.59407349  1.47879578]]\n",
      "339000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.21116947729389599\n",
      "[[ 0.5628068   0.46253939 -1.02547585]\n",
      " [ 1.38239361 -0.30106306 -1.08167273]\n",
      " [-1.92359338  0.038386    1.88562371]\n",
      " [-0.88557208 -0.59538032  1.48109708]]\n",
      "340000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.21086893078835325\n",
      "[[ 0.56354898  0.46330489 -1.02698352]\n",
      " [ 1.38401165 -0.30097833 -1.0833755 ]\n",
      " [-1.92571297  0.03791645  1.88821285]\n",
      " [-0.88656449 -0.59668447  1.48339365]]\n",
      "341000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2105696376843191\n",
      "[[ 0.56428967  0.46406809 -1.02848742]\n",
      " [ 1.38562622 -0.30089296 -1.08507545]\n",
      " [-1.92782805  0.03744811  1.89079627]\n",
      " [-0.88755486 -0.59798596  1.48568551]]\n",
      "342000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.21027159003053267\n",
      "[[ 0.5650289   0.46482902 -1.02998757]\n",
      " [ 1.38723733 -0.30080693 -1.08677258]\n",
      " [-1.92993862  0.03698096  1.893374  ]\n",
      " [-0.88854319 -0.5992848   1.48797267]]\n",
      "343000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2099747799428346\n",
      "[[ 0.56576666  0.46558767 -1.03148398]\n",
      " [ 1.38884498 -0.30072026 -1.08846691]\n",
      " [-1.93204472  0.03651501  1.89594605]\n",
      " [-0.8895295  -0.60058099  1.49025517]]\n",
      "344000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.20967919960345965\n",
      "[[ 0.56650297  0.46634405 -1.03297668]\n",
      " [ 1.3904492  -0.30063295 -1.09015844]\n",
      " [-1.93414636  0.03605024  1.89851246]\n",
      " [-0.89051379 -0.60187455  1.49253303]]\n",
      "345000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.209384841260338\n",
      "[[ 0.56723782  0.46709819 -1.03446567]\n",
      " [ 1.39205001 -0.30054501 -1.09184718]\n",
      " [-1.93624356  0.03558665  1.90107325]\n",
      " [-0.89149608 -0.60316548  1.49480625]]\n",
      "346000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.20909169722640533\n",
      "[[ 0.56797122  0.46785009 -1.03595097]\n",
      " [ 1.39364741 -0.30045644 -1.09353315]\n",
      " [-1.93833634  0.03512424  1.90362843]\n",
      " [-0.89247636 -0.60445381  1.49707486]]\n",
      "347000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2087997598789224\n",
      "[[ 0.56870319  0.46859976 -1.0374326 ]\n",
      " [ 1.39524142 -0.30036724 -1.09521635]\n",
      " [-1.94042472  0.03466301  1.90617805]\n",
      " [-0.89345466 -0.60573953  1.49933887]]\n",
      "348000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2085090216588027\n",
      "[[ 0.56943372  0.46934721 -1.03891057]\n",
      " [ 1.39683205 -0.30027743 -1.0968968 ]\n",
      " [-1.94250872  0.03420295  1.90872211]\n",
      " [-0.89443097 -0.60702267  1.50159832]]\n",
      "349000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.20821947506994815\n",
      "[[ 0.57016281  0.47009244 -1.04038491]\n",
      " [ 1.39841933 -0.30018701 -1.0985745 ]\n",
      " [-1.94458836  0.03374405  1.91126064]\n",
      " [-0.89540531 -0.60830322  1.50385321]]\n",
      "350000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.20793111267859393\n",
      "[[ 0.57089049  0.47083548 -1.04185563]\n",
      " [ 1.40000325 -0.30009598 -1.10024946]\n",
      " [-1.94666365  0.03328631  1.91379367]\n",
      " [-0.89637768 -0.60958121  1.50610357]]\n",
      "351000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.20764392711266225\n",
      "[[ 0.57161675  0.47157633 -1.04332274]\n",
      " [ 1.40158385 -0.30000434 -1.10192169]\n",
      " [-1.94873462  0.03282974  1.91632122]\n",
      " [-0.8973481  -0.61085663  1.50834942]]\n",
      "352000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.20735791106112245\n",
      "[[ 0.57234159  0.47231501 -1.04478625]\n",
      " [ 1.40316113 -0.29991211 -1.1035912 ]\n",
      " [-1.95080128  0.03237431  1.9188433 ]\n",
      " [-0.89831657 -0.61212951  1.51059077]]\n",
      "353000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2070730572733598\n",
      "[[ 0.57306503  0.47305151 -1.0462462 ]\n",
      " [ 1.4047351  -0.29981928 -1.105258  ]\n",
      " [-1.95286365  0.03192004  1.92135995]\n",
      " [-0.89928309 -0.61339986  1.51282764]]\n",
      "354000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.20678935855855382\n",
      "[[ 0.57378707  0.47378585 -1.04770258]\n",
      " [ 1.40630579 -0.29972587 -1.1069221 ]\n",
      " [-1.95492176  0.03146691  1.92387118]\n",
      " [-0.90024769 -0.61466767  1.51506005]]\n",
      "355000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.20650680778506142\n",
      "[[ 0.57450772  0.47451805 -1.04915542]\n",
      " [ 1.40787319 -0.29963187 -1.10858351]\n",
      " [-1.95697561  0.03101492  1.92637703]\n",
      " [-0.90121036 -0.61593297  1.51728802]]\n",
      "356000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.20622539787980984\n",
      "[[ 0.57522697  0.4752481  -1.05060472]\n",
      " [ 1.40943734 -0.29953729 -1.11024223]\n",
      " [-1.95902523  0.03056407  1.9288775 ]\n",
      " [-0.90217112 -0.61719576  1.51951156]]\n",
      "357000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2059451218276971\n",
      "[[ 0.57594484  0.47597603 -1.05205052]\n",
      " [ 1.41099824 -0.29944213 -1.11189829]\n",
      " [-1.96107064  0.03011435  1.93137262]\n",
      " [-0.90312997 -0.61845605  1.52173071]]\n",
      "358000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.20566597267099795\n",
      "[[ 0.57666133  0.47670183 -1.05349282]\n",
      " [ 1.4125559  -0.29934641 -1.11355168]\n",
      " [-1.96311185  0.02966576  1.93386242]\n",
      " [-0.90408692 -0.61971386  1.52394547]]\n",
      "359000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.20538794350878053\n",
      "[[ 0.57737645  0.47742553 -1.05493163]\n",
      " [ 1.41411034 -0.29925011 -1.11520241]\n",
      " [-1.96514888  0.02921829  1.93634692]\n",
      " [-0.90504198 -0.62096919  1.52615585]]\n",
      "360000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2051110274963263\n",
      "[[ 0.5780902   0.47814712 -1.05636697]\n",
      " [ 1.41566158 -0.29915326 -1.1168505 ]\n",
      " [-1.96718175  0.02877195  1.93882613]\n",
      " [-0.90599516 -0.62222205  1.52836189]]\n",
      "361000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.20483521784456016\n",
      "[[ 0.57880259  0.47886662 -1.05779887]\n",
      " [ 1.41720962 -0.29905585 -1.11849595]\n",
      " [-1.96921047  0.02832672  1.94130008]\n",
      " [-0.90694646 -0.62347245  1.5305636 ]]\n",
      "362000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.20456050781948554\n",
      "[[ 0.57951362  0.47958405 -1.05922732]\n",
      " [ 1.41875448 -0.29895789 -1.12013877]\n",
      " [-1.97123507  0.02788261  1.9437688 ]\n",
      " [-0.90789589 -0.62472041  1.53276099]]\n",
      "363000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.20428689074162834\n",
      "[[ 0.5802233   0.4802994  -1.06065235]\n",
      " [ 1.42029617 -0.29885938 -1.12177897]\n",
      " [-1.97325556  0.0274396   1.94623229]\n",
      " [-0.90884346 -0.62596593  1.53495408]]\n",
      "364000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.20401435998548592\n",
      "[[ 0.58093163  0.48101268 -1.06207397]\n",
      " [ 1.4218347  -0.29876032 -1.12341656]\n",
      " [-1.97527196  0.0269977   1.94869059]\n",
      " [-0.90978918 -0.62720902  1.53714289]]\n",
      "365000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.20374290897898328\n",
      "[[ 0.58163862  0.48172391 -1.06349219]\n",
      " [ 1.42337009 -0.29866073 -1.12505155]\n",
      " [-1.97728428  0.0265569   1.95114372]\n",
      " [-0.91073306 -0.6284497   1.53932744]]\n",
      "366000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2034725312029365\n",
      "[[ 0.58234428  0.4824331  -1.06490704]\n",
      " [ 1.42490236 -0.2985606  -1.12668394]\n",
      " [-1.97929255  0.0261172   1.95359169]\n",
      " [-0.9116751  -0.62968796  1.54150775]]\n",
      "367000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.20320322019052203\n",
      "[[ 0.5830486   0.48314026 -1.06631852]\n",
      " [ 1.42643151 -0.29845993 -1.12831375]\n",
      " [-1.98129677  0.02567858  1.95603452]\n",
      " [-0.91261531 -0.63092383  1.54368382]]\n",
      "368000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2029349695267527\n",
      "[[ 0.5837516   0.48384538 -1.06772664]\n",
      " [ 1.42795755 -0.29835874 -1.12994099]\n",
      " [-1.98329697  0.02524106  1.95847225]\n",
      " [-0.9135537  -0.63215731  1.54585569]]\n",
      "369000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.20266777284795953\n",
      "[[ 0.58445328  0.48454849 -1.06913143]\n",
      " [ 1.42948051 -0.29825703 -1.13156565]\n",
      " [-1.98529317  0.02480462  1.96090488]\n",
      " [-0.91449027 -0.6333884   1.54802336]]\n",
      "370000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.20240162384128055\n",
      "[[ 0.58515365  0.4852496  -1.0705329 ]\n",
      " [ 1.43100038 -0.2981548  -1.13318776]\n",
      " [-1.98728537  0.02436927  1.96333243]\n",
      " [-0.91542503 -0.63461713  1.55018685]]\n",
      "371000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2021365162441554\n",
      "[[ 0.5858527   0.4859487  -1.07193106]\n",
      " [ 1.43251719 -0.29805205 -1.13480732]\n",
      " [-1.9892736   0.02393499  1.96575494]\n",
      " [-0.916358   -0.6358435   1.55234618]]\n",
      "372000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.20187244384382597\n",
      "[[ 0.58655045  0.48664581 -1.07332592]\n",
      " [ 1.43403095 -0.2979488  -1.13642433]\n",
      " [-1.99125787  0.02350178  1.96817242]\n",
      " [-0.91728917 -0.63706751  1.55450137]]\n",
      "373000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.20160940047684253\n",
      "[[ 0.5872469   0.48734095 -1.0747175 ]\n",
      " [ 1.43554167 -0.29784503 -1.13803881]\n",
      " [-1.99323819  0.02306965  1.97058488]\n",
      " [-0.91821856 -0.63828918  1.55665243]]\n",
      "374000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.20134738002857724\n",
      "[[ 0.58794205  0.48803411 -1.07610582]\n",
      " [ 1.43704935 -0.29774077 -1.13965077]\n",
      " [-1.99521459  0.02263857  1.97299235]\n",
      " [-0.91914617 -0.63950852  1.55879938]]\n",
      "375000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.20108637643274108\n",
      "[[ 0.58863592  0.4887253  -1.07749088]\n",
      " [ 1.43855403 -0.297636   -1.14126021]\n",
      " [-1.99718709  0.02220856  1.97539486]\n",
      " [-0.92007201 -0.64072553  1.56094223]]\n",
      "376000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.20082638367090902\n",
      "[[ 0.5893285   0.48941455 -1.0788727 ]\n",
      " [ 1.44005569 -0.29753074 -1.14286713]\n",
      " [-1.99915568  0.02177961  1.97779241]\n",
      " [-0.92099609 -0.64194023  1.563081  ]]\n",
      "377000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.2005673957720492\n",
      "[[ 0.5900198   0.49010184 -1.08025129]\n",
      " [ 1.44155437 -0.29742499 -1.14447156]\n",
      " [-2.0011204   0.02135171  1.98018502]\n",
      " [-0.92191841 -0.64315262  1.56521572]]\n",
      "378000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.20030940681205808\n",
      "[[ 0.59070982  0.4907872  -1.08162667]\n",
      " [ 1.44305007 -0.29731875 -1.1460735 ]\n",
      " [-2.00308126  0.02092486  1.98257273]\n",
      " [-0.92283898 -0.64436272  1.56734638]]\n",
      "379000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.20005241091330184\n",
      "[[ 0.59139857  0.49147063 -1.08299886]\n",
      " [ 1.44454279 -0.29721202 -1.14767295]\n",
      " [-2.00503827  0.02049906  1.98495554]\n",
      " [-0.92375781 -0.64557052  1.56947302]]\n",
      "380000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1997964022441611\n",
      "[[ 0.59208606  0.49215214 -1.08436785]\n",
      " [ 1.44603256 -0.29710482 -1.14926992]\n",
      " [-2.00699145  0.0200743   1.98733348]\n",
      " [-0.9246749  -0.64677605  1.57159564]]\n",
      "381000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.19954137501858352\n",
      "[[ 0.59277228  0.49283174 -1.08573367]\n",
      " [ 1.44751939 -0.29699714 -1.15086443]\n",
      " [-2.00894081  0.01965058  1.98970657]\n",
      " [-0.92559026 -0.64797931  1.57371426]]\n",
      "382000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1992873234956402\n",
      "[[ 0.59345725  0.49350943 -1.08709634]\n",
      " [ 1.44900329 -0.29688899 -1.15245647]\n",
      " [-2.01088638  0.01922789  1.99207482]\n",
      " [-0.92650391 -0.6491803   1.57582889]]\n",
      "383000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.19903424197908778\n",
      "[[ 0.59414097  0.49418523 -1.08845585]\n",
      " [ 1.45048426 -0.29678037 -1.15404607]\n",
      " [-2.01282815  0.01880624  1.99443825]\n",
      " [-0.92741583 -0.65037904  1.57793956]]\n",
      "384000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1987821248169344\n",
      "[[ 0.59482344  0.49485914 -1.08981224]\n",
      " [ 1.45196232 -0.29667129 -1.15563322]\n",
      " [-2.01476616  0.01838561  1.99679688]\n",
      " [-0.92832605 -0.65157554  1.58004628]]\n",
      "385000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.19853096640101323\n",
      "[[ 0.59550467  0.49553117 -1.0911655 ]\n",
      " [ 1.45343749 -0.29656174 -1.15721793]\n",
      " [-2.01670041  0.01796601  1.99915074]\n",
      " [-0.92923457 -0.6527698   1.58214906]]\n",
      "386000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.19828076116655818\n",
      "[[ 0.59618467  0.49620133 -1.09251565]\n",
      " [ 1.45490977 -0.29645173 -1.15880021]\n",
      " [-2.01863093  0.01754742  2.00149984]\n",
      " [-0.93014139 -0.65396184  1.58424792]]\n",
      "387000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.19803150359178667\n",
      "[[ 0.59686343  0.49686963 -1.09386271]\n",
      " [ 1.45637917 -0.29634127 -1.16038008]\n",
      " [-2.02055771  0.01712986  2.00384419]\n",
      " [-0.93104653 -0.65515166  1.58634287]]\n",
      "388000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.19778318819748575\n",
      "[[ 0.59754096  0.49753608 -1.09520669]\n",
      " [ 1.45784571 -0.29623036 -1.16195753]\n",
      " [-2.02248079  0.0167133   2.00618382]\n",
      " [-0.93194998 -0.65633926  1.58843393]]\n",
      "389000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1975358095466042\n",
      "[[ 0.59821726  0.49820067 -1.09654759]\n",
      " [ 1.4593094  -0.29611901 -1.16353257]\n",
      " [-2.02440017  0.01629776  2.00851875]\n",
      " [-0.93285176 -0.65752467  1.59052112]]\n",
      "390000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.19728936224384852\n",
      "[[ 0.59889235  0.49886344 -1.09788544]\n",
      " [ 1.46077024 -0.29600721 -1.16510522]\n",
      " [-2.02631587  0.01588321  2.01084899]\n",
      " [-0.93375187 -0.65870788  1.59260444]]\n",
      "391000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.19704384093528277\n",
      "[[ 0.59956623  0.49952437 -1.09922025]\n",
      " [ 1.46222826 -0.29589496 -1.16667547]\n",
      " [-2.0282279   0.01546968  2.01317456]\n",
      " [-0.93465032 -0.65988891  1.59468392]]\n",
      "392000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.19679924030793627\n",
      "[[ 0.60023889  0.50018348 -1.10055202]\n",
      " [ 1.46368345 -0.29578229 -1.16824335]\n",
      " [-2.03013628  0.01505713  2.01549548]\n",
      " [-0.93554711 -0.66106776  1.59675957]]\n",
      "393000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.19655555508941117\n",
      "[[ 0.60091035  0.50084077 -1.10188077]\n",
      " [ 1.46513584 -0.29566917 -1.16980885]\n",
      " [-2.03204102  0.01464559  2.01781177]\n",
      " [-0.93644226 -0.66224445  1.59883139]]\n",
      "394000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.19631278004749866\n",
      "[[ 0.60158061  0.50149626 -1.10320652]\n",
      " [ 1.46658543 -0.29555563 -1.17137198]\n",
      " [-2.03394214  0.01423503  2.02012344]\n",
      " [-0.93733576 -0.66341898  1.60089942]]\n",
      "395000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.19607090998979668\n",
      "[[ 0.60224967  0.50214995 -1.10452927]\n",
      " [ 1.46803223 -0.29544166 -1.17293275]\n",
      " [-2.03583964  0.01382546  2.02243052]\n",
      " [-0.93822763 -0.66459135  1.60296366]]\n",
      "396000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.19582993976333382\n",
      "[[ 0.60291753  0.50280185 -1.10584904]\n",
      " [ 1.46947626 -0.29532727 -1.17449117]\n",
      " [-2.03773356  0.01341688  2.02473301]\n",
      " [-0.93911786 -0.66576158  1.60502413]]\n",
      "397000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.19558986425419547\n",
      "[[ 0.60358422  0.50345196 -1.10716583]\n",
      " [ 1.47091752 -0.29521245 -1.17604724]\n",
      " [-2.03962389  0.01300927  2.02703095]\n",
      " [-0.94000648 -0.66692968  1.60708084]]\n",
      "398000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1953506783871579\n",
      "[[ 0.60424971  0.5041003  -1.10847967]\n",
      " [ 1.47235602 -0.29509722 -1.17760098]\n",
      " [-2.04151065  0.01260265  2.02932434]\n",
      " [-0.94089347 -0.66809565  1.6091338 ]]\n",
      "399000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.19511237712532087\n",
      "[[ 0.60491403  0.50474687 -1.10979056]\n",
      " [ 1.47379178 -0.29498158 -1.17915239]\n",
      " [-2.04339386  0.01219699  2.0316132 ]\n",
      " [-0.94177885 -0.6692595   1.61118303]]\n",
      "400000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.19487495546974998\n",
      "[[ 0.60557717  0.50539169 -1.11109851]\n",
      " [ 1.47522481 -0.29486552 -1.18070147]\n",
      " [-2.04527352  0.01179231  2.03389755]\n",
      " [-0.94266263 -0.67042123  1.61322855]]\n",
      "401000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1946384084591199\n",
      "[[ 0.60623914  0.50603474 -1.11240354]\n",
      " [ 1.47665512 -0.29474906 -1.18224824]\n",
      " [-2.04714966  0.01138859  2.03617741]\n",
      " [-0.94354481 -0.67158087  1.61527037]]\n",
      "402000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.19440273116936263\n",
      "[[ 0.60689995  0.50667606 -1.11370566]\n",
      " [ 1.47808271 -0.29463219 -1.1837927 ]\n",
      " [-2.04902229  0.01098583  2.03845279]\n",
      " [-0.9444254  -0.67273841  1.6173085 ]]\n",
      "403000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.19416791871331862\n",
      "[[ 0.60755959  0.50731563 -1.11500488]\n",
      " [ 1.4795076  -0.29451492 -1.18533486]\n",
      " [-2.05089142  0.01058403  2.04072372]\n",
      " [-0.9453044  -0.67389387  1.61934295]]\n",
      "404000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.19393396624039272\n",
      "[[ 0.60821808  0.50795348 -1.11630121]\n",
      " [ 1.4809298  -0.29439725 -1.18687472]\n",
      " [-2.05275706  0.01018319  2.0429902 ]\n",
      " [-0.94618182 -0.67504724  1.62137374]]\n",
      "405000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.19370086893621544\n",
      "[[ 0.60887541  0.5085896  -1.11759467]\n",
      " [ 1.48234932 -0.29427919 -1.1884123 ]\n",
      " [-2.05461923  0.0097833   2.04525226]\n",
      " [-0.94705766 -0.67619854  1.62340089]]\n",
      "406000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1934686220223038\n",
      "[[ 0.60953159  0.50922401 -1.11888526]\n",
      " [ 1.48376616 -0.29416074 -1.1899476 ]\n",
      " [-2.05647794  0.00938436  2.04750991]\n",
      " [-0.94793194 -0.67734778  1.6254244 ]]\n",
      "407000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.193237220755731\n",
      "[[ 0.61018663  0.50985671 -1.12017299]\n",
      " [ 1.48518034 -0.29404189 -1.19148063]\n",
      " [-2.0583332   0.00898637  2.04976317]\n",
      " [-0.94880465 -0.67849496  1.6274443 ]]\n",
      "408000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1930066604287959\n",
      "[[ 0.61084053  0.5104877  -1.12145788]\n",
      " [ 1.48659187 -0.29392266 -1.19301139]\n",
      " [-2.06018503  0.00858931  2.05201205]\n",
      " [-0.9496758  -0.6796401   1.62946059]]\n",
      "409000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1927769363686979\n",
      "[[ 0.61149328  0.511117   -1.12273994]\n",
      " [ 1.48800076 -0.29380305 -1.19453989]\n",
      " [-2.06203344  0.0081932   2.05425657]\n",
      " [-0.95054541 -0.68078319  1.63147328]]\n",
      "410000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.19254804393721525\n",
      "[[ 0.61214491  0.51174462 -1.12401918]\n",
      " [ 1.48940702 -0.29368306 -1.19606614]\n",
      " [-2.06387844  0.00779802  2.05649675]\n",
      " [-0.95141346 -0.68192425  1.6334824 ]]\n",
      "411000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1923199785303865\n",
      "[[ 0.6127954   0.51237056 -1.12529561]\n",
      " [ 1.49081066 -0.29356269 -1.19759015]\n",
      " [-2.06572004  0.00740377  2.0587326 ]\n",
      " [-0.95227998 -0.68306329  1.63548795]]\n",
      "412000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.19209273557819606\n",
      "[[ 0.61344478  0.51299482 -1.12656925]\n",
      " [ 1.49221168 -0.29344194 -1.19911192]\n",
      " [-2.06755826  0.00701045  2.06096415]\n",
      " [-0.95314497 -0.6842003   1.63748995]]\n",
      "413000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.19186631054426273\n",
      "[[ 0.61409302  0.51361742 -1.1278401 ]\n",
      " [ 1.4936101  -0.29332083 -1.20063145]\n",
      " [-2.06939312  0.00661806  2.06319139]\n",
      " [-0.95400842 -0.68533531  1.63948842]]\n",
      "414000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1916406989255316\n",
      "[[ 0.61474016  0.51423835 -1.12910817]\n",
      " [ 1.49500593 -0.29319934 -1.20214877]\n",
      " [-2.07122462  0.00622659  2.06541436]\n",
      " [-0.95487035 -0.68646831  1.64148335]]\n",
      "415000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1914158962519699\n",
      "[[ 0.61538618  0.51485764 -1.13037347]\n",
      " [ 1.49639917 -0.29307749 -1.20366386]\n",
      " [-2.07305277  0.00583603  2.06763307]\n",
      " [-0.95573077 -0.68759932  1.64347477]]\n",
      "416000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.19119189808626522\n",
      "[[ 0.61603109  0.51547528 -1.13163602]\n",
      " [ 1.49778985 -0.29295528 -1.20517675]\n",
      " [-2.07487759  0.0054464   2.06984753]\n",
      " [-0.95658967 -0.68872833  1.64546269]]\n",
      "417000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.19096870002352864\n",
      "[[ 0.61667489  0.51609129 -1.13289583]\n",
      " [ 1.49917796 -0.29283271 -1.20668743]\n",
      " [-2.07669909  0.00505767  2.07205776]\n",
      " [-0.95744707 -0.68985537  1.64744713]]\n",
      "418000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.19074629769099888\n",
      "[[ 0.61731759  0.51670566 -1.13415291]\n",
      " [ 1.50056351 -0.29270977 -1.20819592]\n",
      " [-2.07851729  0.00466985  2.07426377]\n",
      " [-0.95830297 -0.69098043  1.64942809]]\n",
      "419000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.19052468674775155\n",
      "[[ 0.6179592   0.51731841 -1.13540726]\n",
      " [ 1.50194652 -0.29258649 -1.20970221]\n",
      " [-2.08033219  0.00428294  2.07646558]\n",
      " [-0.95915737 -0.69210353  1.65140559]]\n",
      "420000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1903038628844105\n",
      "[[ 0.61859971  0.51792954 -1.13665891]\n",
      " [ 1.50332699 -0.29246285 -1.21120632]\n",
      " [-2.08214381  0.00389693  2.07866321]\n",
      " [-0.96001029 -0.69322466  1.65337964]]\n",
      "421000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.19008382182286299\n",
      "[[ 0.61923913  0.51853906 -1.13790785]\n",
      " [ 1.50470494 -0.29233886 -1.21270826]\n",
      " [-2.08395215  0.00351182  2.08085667]\n",
      " [-0.96086172 -0.69434385  1.65535025]]\n",
      "422000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18986455931597762\n",
      "[[ 0.61987747  0.51914698 -1.1391541 ]\n",
      " [ 1.50608037 -0.29221453 -1.21420802]\n",
      " [-2.08575724  0.0031276   2.08304597]\n",
      " [-0.96171167 -0.69546108  1.65731744]]\n",
      "423000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18964607114732512\n",
      "[[ 0.62051472  0.51975329 -1.14039767]\n",
      " [ 1.50745329 -0.29208985 -1.21570562]\n",
      " [-2.08755909  0.00274428  2.08523114]\n",
      " [-0.96256015 -0.69657638  1.65928122]]\n",
      "424000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18942835313090178\n",
      "[[ 0.6211509   0.52035802 -1.14163858]\n",
      " [ 1.50882372 -0.29196484 -1.21720106]\n",
      " [-2.0893577   0.00236185  2.08741218]\n",
      " [-0.96340716 -0.69768975  1.6612416 ]]\n",
      "425000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18921140111085752\n",
      "[[ 6.21786001e-01  5.20961165e-01 -1.14287682e+00]\n",
      " [ 1.51019165e+00 -2.91839479e-01 -1.21869436e+00]\n",
      " [-2.09115308e+00  1.98030339e-03  2.08958911e+00]\n",
      " [-9.64252705e-01 -6.98801197e-01  1.66319859e+00]]\n",
      "426000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1889952109612251\n",
      "[[ 6.22420031e-01  5.21562731e-01 -1.14411242e+00]\n",
      " [ 1.51155711e+00 -2.91713787e-01 -1.22018550e+00]\n",
      " [-2.09294526e+00  1.59963999e-03  2.09176195e+00]\n",
      " [-9.65096796e-01 -6.99910724e-01  1.66515221e+00]]\n",
      "427000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18877977858565279\n",
      "[[ 6.23052994e-01  5.22162725e-01 -1.14534537e+00]\n",
      " [ 1.51292009e+00 -2.91587760e-01 -1.22167451e+00]\n",
      " [-2.09473423e+00  1.21985656e-03  2.09393071e+00]\n",
      " [-9.65939434e-01 -7.01018340e-01  1.66710246e+00]]\n",
      "428000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18856509991713985\n",
      "[[ 6.23684893e-01  5.22761154e-01 -1.14657570e+00]\n",
      " [ 1.51428061e+00 -2.91461403e-01 -1.22316139e+00]\n",
      " [-2.09652002e+00  8.40949962e-04  2.09609541e+00]\n",
      " [-9.66780626e-01 -7.02124053e-01  1.66904937e+00]]\n",
      "429000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1883511709177755\n",
      "[[ 6.24315732e-01  5.23358025e-01 -1.14780341e+00]\n",
      " [ 1.51563868e+00 -2.91334718e-01 -1.22464614e+00]\n",
      " [-2.09830264e+00  4.62917078e-04  2.09825605e+00]\n",
      " [-9.67620376e-01 -7.03227870e-01  1.67099293e+00]]\n",
      "430000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18813798757848016\n",
      "[[ 6.24945515e-01  5.23953344e-01 -1.14902851e+00]\n",
      " [ 1.51699431e+00 -2.91207707e-01 -1.22612878e+00]\n",
      " [-2.10008209e+00  8.57548059e-05  2.10041266e+00]\n",
      " [-9.68458690e-01 -7.04329797e-01  1.67293317e+00]]\n",
      "431000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18792554591874888\n",
      "[[ 6.25574246e-01  5.24547117e-01 -1.15025102e+00]\n",
      " [ 1.51834749e+00 -2.91080373e-01 -1.22760930e+00]\n",
      " [-2.10185838e+00 -2.90539945e-04  2.10256526e+00]\n",
      " [-9.69295573e-01 -7.05429840e-01  1.67487010e+00]]\n",
      "432000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1877138419863987\n",
      "[[ 6.26201927e-01  5.25139351e-01 -1.15147093e+00]\n",
      " [ 1.51969825e+00 -2.90952718e-01 -1.22908772e+00]\n",
      " [-2.10363154e+00 -6.65970253e-04  2.10471384e+00]\n",
      " [-9.70131030e-01 -7.06528008e-01  1.67680372e+00]]\n",
      "433000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18750287185731743\n",
      "[[ 6.26828564e-01  5.25730051e-01 -1.15268827e+00]\n",
      " [ 1.52104660e+00 -2.90824744e-01 -1.23056403e+00]\n",
      " [-2.10540156e+00 -1.04053918e-03  2.10685843e+00]\n",
      " [-9.70965065e-01 -7.07624306e-01  1.67873406e+00]]\n",
      "434000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1872926316352153\n",
      "[[ 6.27454158e-01  5.26319225e-01 -1.15390304e+00]\n",
      " [ 1.52239253e+00 -2.90696455e-01 -1.23203825e+00]\n",
      " [-2.10716847e+00 -1.41424978e-03  2.10899905e+00]\n",
      " [-9.71797685e-01 -7.08718742e-01  1.68066111e+00]]\n",
      "435000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18708311745138104\n",
      "[[ 6.28078714e-01  5.26906879e-01 -1.15511525e+00]\n",
      " [ 1.52373606e+00 -2.90567853e-01 -1.23351039e+00]\n",
      " [-2.10893227e+00 -1.78710510e-03  2.11113571e+00]\n",
      " [-9.72628893e-01 -7.09811321e-01  1.68258490e+00]]\n",
      "436000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18687432546443816\n",
      "[[ 0.62870224  0.52749302 -1.15632491]\n",
      " [ 1.5250772  -0.29043894 -1.23498044]\n",
      " [-2.11069297 -0.00215911  2.11326841]\n",
      " [-0.9734587  -0.71090205  1.68450543]]\n",
      "437000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18666625186010477\n",
      "[[ 0.62932473  0.52807765 -1.15753203]\n",
      " [ 1.52641596 -0.29030972 -1.23644842]\n",
      " [-2.11245059 -0.00253026  2.11539718]\n",
      " [-0.9742871  -0.71199094  1.68642272]]\n",
      "438000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18645889285095602\n",
      "[[ 0.62994619  0.52866078 -1.15873662]\n",
      " [ 1.52775234 -0.29018019 -1.23791433]\n",
      " [-2.11420513 -0.00290057  2.11752203]\n",
      " [-0.9751141  -0.71307799  1.68833678]]\n",
      "439000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18625224467618923\n",
      "[[ 0.63056663  0.52924241 -1.15993869]\n",
      " [ 1.52908635 -0.29005036 -1.23937817]\n",
      " [-2.11595661 -0.00327003  2.11964298]\n",
      " [-0.97593972 -0.71416321  1.69024761]]\n",
      "440000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18604630360139032\n",
      "[[ 0.63118605  0.52982255 -1.16113825]\n",
      " [ 1.53041801 -0.28992022 -1.24083996]\n",
      " [-2.11770503 -0.00363866  2.12176003]\n",
      " [-0.97676395 -0.71524661  1.69215524]]\n",
      "441000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1858410659183043\n",
      "[[ 0.63180445  0.53040121 -1.16233531]\n",
      " [ 1.53174731 -0.28978979 -1.2422997 ]\n",
      " [-2.11945042 -0.00400644  2.1238732 ]\n",
      " [-0.97758679 -0.71632819  1.69405967]]\n",
      "442000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1856365279446071\n",
      "[[ 0.63242183  0.53097839 -1.16352988]\n",
      " [ 1.53307428 -0.28965906 -1.2437574 ]\n",
      " [-2.12119277 -0.0043734   2.1259825 ]\n",
      " [-0.97840826 -0.71740796  1.69596091]]\n",
      "443000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18543268602367988\n",
      "[[ 0.63303821  0.5315541  -1.16472196]\n",
      " [ 1.53439891 -0.28952804 -1.24521305]\n",
      " [-2.12293211 -0.00473952  2.12808796]\n",
      " [-0.97922836 -0.71848592  1.69785897]]\n",
      "444000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18522953652438603\n",
      "[[ 0.63365358  0.53212834 -1.16591158]\n",
      " [ 1.53572121 -0.28939672 -1.24666667]\n",
      " [-2.12466843 -0.00510481  2.13018958]\n",
      " [-0.9800471  -0.71956209  1.69975387]]\n",
      "445000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18502707584085043\n",
      "[[ 0.63426795  0.53270112 -1.16709872]\n",
      " [ 1.5370412  -0.28926511 -1.24811827]\n",
      " [-2.12640176 -0.00546928  2.13228737]\n",
      " [-0.98086447 -0.72063647  1.70164562]]\n",
      "446000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18482530039224063\n",
      "[[ 0.63488131  0.53327245 -1.16828342]\n",
      " [ 1.53835888 -0.28913322 -1.24956784]\n",
      " [-2.1281321  -0.00583292  2.13438135]\n",
      " [-0.98168048 -0.72170906  1.70353422]]\n",
      "447000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18462420662255039\n",
      "[[ 0.63549368  0.53384233 -1.16946567]\n",
      " [ 1.53967426 -0.28900104 -1.2510154 ]\n",
      " [-2.12985946 -0.00619575  2.13647154]\n",
      " [-0.98249514 -0.72277987  1.70541969]]\n",
      "448000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18442379100038628\n",
      "[[ 0.63610506  0.53441077 -1.17064548]\n",
      " [ 1.54098734 -0.28886858 -1.25246095]\n",
      " [-2.13158385 -0.00655775  2.13855794]\n",
      " [-0.98330845 -0.72384891  1.70730204]]\n",
      "449000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18422405001875475\n",
      "[[ 0.63671544  0.53497777 -1.17182286]\n",
      " [ 1.54229814 -0.28873583 -1.25390449]\n",
      " [-2.13330528 -0.00691895  2.14064056]\n",
      " [-0.98412042 -0.72491618  1.70918129]]\n",
      "450000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1840249801948538\n",
      "[[ 0.63732484  0.53554334 -1.17299783]\n",
      " [ 1.54360667 -0.28860281 -1.25534604]\n",
      " [-2.13502377 -0.00727933  2.14271944]\n",
      " [-0.98493105 -0.7259817   1.71105743]]\n",
      "451000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18382657806986386\n",
      "[[ 0.63793325  0.53610748 -1.17417039]\n",
      " [ 1.54491292 -0.28846951 -1.25678559]\n",
      " [-2.13673933 -0.0076389   2.14479456]\n",
      " [-0.98574034 -0.72704546  1.71293048]]\n",
      "452000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18362884020874362\n",
      "[[ 0.63854069  0.5366702  -1.17534054]\n",
      " [ 1.54621692 -0.28833593 -1.25822316]\n",
      " [-2.13845195 -0.00799767  2.14686596]\n",
      " [-0.98654831 -0.72810747  1.71480046]]\n",
      "453000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18343176320002616\n",
      "[[ 0.63914715  0.53723151 -1.17650831]\n",
      " [ 1.54751866 -0.28820209 -1.25965875]\n",
      " [-2.14016166 -0.00835563  2.14893363]\n",
      " [-0.98735495 -0.72916773  1.71666737]]\n",
      "454000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18323534365561733\n",
      "[[ 0.63975263  0.53779141 -1.17767369]\n",
      " [ 1.54881815 -0.28806797 -1.26109236]\n",
      " [-2.14186847 -0.0087128   2.1509976 ]\n",
      " [-0.98816027 -0.73022627  1.71853122]]\n",
      "455000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18303957821059744\n",
      "[[ 0.64035714  0.53834991 -1.1788367 ]\n",
      " [ 1.55011541 -0.28793358 -1.26252401]\n",
      " [-2.14357238 -0.00906917  2.15305788]\n",
      " [-0.98896428 -0.73128307  1.72039203]]\n",
      "456000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18284446352302366\n",
      "[[ 0.64096069  0.53890701 -1.17999735]\n",
      " [ 1.55141044 -0.28779893 -1.26395369]\n",
      " [-2.1452734  -0.00942474  2.15511448]\n",
      " [-0.98976697 -0.73233815  1.7222498 ]]\n",
      "457000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18264999627373465\n",
      "[[ 0.64156327  0.53946271 -1.18115564]\n",
      " [ 1.55270325 -0.28766401 -1.26538141]\n",
      " [-2.14697155 -0.00977952  2.15716741]\n",
      " [-0.99056836 -0.73339151  1.72410455]]\n",
      "458000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18245617316615798\n",
      "[[ 0.64216489  0.54001703 -1.18231158]\n",
      " [ 1.55399384 -0.28752884 -1.26680718]\n",
      " [-2.14866683 -0.01013352  2.15921668]\n",
      " [-0.99136844 -0.73444316  1.72595628]]\n",
      "459000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18226299092611783\n",
      "[[ 0.64276555  0.54056997 -1.18346518]\n",
      " [ 1.55528222 -0.2873934  -1.26823101]\n",
      " [-2.15035926 -0.01048672  2.16126231]\n",
      " [-0.99216723 -0.7354931   1.72780501]]\n",
      "460000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.182070446301647\n",
      "[[ 0.64336526  0.54112154 -1.18461645]\n",
      " [ 1.55656841 -0.2872577  -1.26965289]\n",
      " [-2.15204883 -0.01083915  2.16330432]\n",
      " [-0.99296472 -0.73654134  1.72965075]]\n",
      "461000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1818785360627983\n",
      "[[ 0.64396401  0.54167173 -1.1857654 ]\n",
      " [ 1.5578524  -0.28712175 -1.27107284]\n",
      " [-2.15373558 -0.01119079  2.1653427 ]\n",
      " [-0.99376092 -0.73758789  1.7314935 ]]\n",
      "462000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18168725700146027\n",
      "[[ 0.64456182  0.54222056 -1.18691203]\n",
      " [ 1.55913421 -0.28698554 -1.27249085]\n",
      " [-2.15541949 -0.01154166  2.16737748]\n",
      " [-0.99455584 -0.73863275  1.73333327]]\n",
      "463000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18149660593117248\n",
      "[[ 0.64515868  0.54276803 -1.18805636]\n",
      " [ 1.56041385 -0.28684908 -1.27390694]\n",
      " [-2.15710059 -0.01189174  2.16940867]\n",
      " [-0.99534948 -0.73967592  1.73517009]]\n",
      "464000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18130657968694416\n",
      "[[ 0.6457546   0.54331414 -1.1891984 ]\n",
      " [ 1.56169131 -0.28671237 -1.27532111]\n",
      " [-2.15877888 -0.01224106  2.17143628]\n",
      " [-0.99614184 -0.74071742  1.73700395]]\n",
      "465000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18111717512507455\n",
      "[[ 0.64634958  0.54385891 -1.19033814]\n",
      " [ 1.56296661 -0.28657542 -1.27673337]\n",
      " [-2.16045438 -0.01258961  2.17346032]\n",
      " [-0.99693293 -0.74175725  1.73883486]]\n",
      "466000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18092838912297438\n",
      "[[ 0.64694362  0.54440233 -1.19147561]\n",
      " [ 1.56423976 -0.28643821 -1.27814372]\n",
      " [-2.16212708 -0.01293739  2.1754808 ]\n",
      " [-0.99772275 -0.74279541  1.74066285]]\n",
      "467000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18074021857898928\n",
      "[[ 0.64753673  0.54494442 -1.1926108 ]\n",
      " [ 1.56551076 -0.28630077 -1.27955217]\n",
      " [-2.163797   -0.0132844   2.17749774]\n",
      " [-0.99851131 -0.74383191  1.7424879 ]]\n",
      "468000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18055266041222562\n",
      "[[ 0.64812891  0.54548517 -1.19374373]\n",
      " [ 1.56677961 -0.28616308 -1.28095872]\n",
      " [-2.16546416 -0.01363066  2.17951115]\n",
      " [-0.9992986  -0.74486676  1.74431005]]\n",
      "469000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18036571156237768\n",
      "[[ 0.64872016  0.54602459 -1.19487441]\n",
      " [ 1.56804634 -0.28602515 -1.28236337]\n",
      " [-2.16712855 -0.01397615  2.18152104]\n",
      " [-1.00008465 -0.74589996  1.74612929]]\n",
      "470000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.18017936898955567\n",
      "[[ 0.64931049  0.54656269 -1.19600284]\n",
      " [ 1.56931094 -0.28588698 -1.28376614]\n",
      " [-2.1687902  -0.01432089  2.18352742]\n",
      " [-1.00086944 -0.74693151  1.74794564]]\n",
      "471000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17999362967411736\n",
      "[[ 0.6498999   0.54709947 -1.19712903]\n",
      " [ 1.57057342 -0.28574857 -1.28516703]\n",
      " [-2.1704491  -0.01466487  2.1855303 ]\n",
      " [-1.00165299 -0.74796143  1.7497591 ]]\n",
      "472000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17980849061649973\n",
      "[[ 0.65048839  0.54763494 -1.19825298]\n",
      " [ 1.57183379 -0.28560993 -1.28656604]\n",
      " [-2.17210527 -0.0150081   2.1875297 ]\n",
      " [-1.00243529 -0.74898971  1.75156969]]\n",
      "473000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1796239488370524\n",
      "[[ 0.65107596  0.5481691  -1.19937472]\n",
      " [ 1.57309206 -0.28547106 -1.28796318]\n",
      " [-2.17375871 -0.01535058  2.18952563]\n",
      " [-1.00321635 -0.75001637  1.75337741]]\n",
      "474000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17944000137587385\n",
      "[[ 0.65166262  0.54870196 -1.20049424]\n",
      " [ 1.57434822 -0.28533195 -1.28935845]\n",
      " [-2.17540945 -0.01569232  2.1915181 ]\n",
      " [-1.00399618 -0.7510414   1.75518227]]\n",
      "475000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17925664529264881\n",
      "[[ 0.65224837  0.54923352 -1.20161155]\n",
      " [ 1.5756023  -0.28519262 -1.29075186]\n",
      " [-2.17705747 -0.01603331  2.19350712]\n",
      " [-1.00477478 -0.75206483  1.75698429]]\n",
      "476000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17907387766648594\n",
      "[[ 0.65283322  0.54976379 -1.20272666]\n",
      " [ 1.5768543  -0.28505306 -1.29214342]\n",
      " [-2.1787028  -0.01637356  2.1954927 ]\n",
      " [-1.00555216 -0.75308663  1.75878348]]\n",
      "477000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17889169559575918\n",
      "[[ 0.65341716  0.55029277 -1.20383959]\n",
      " [ 1.57810421 -0.28491327 -1.29353312]\n",
      " [-2.18034544 -0.01671307  2.19747485]\n",
      " [-1.00632831 -0.75410684  1.76057983]]\n",
      "478000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17871009619794848\n",
      "[[ 0.6540002   0.55082047 -1.20495032]\n",
      " [ 1.57935206 -0.28477326 -1.29492098]\n",
      " [-2.18198541 -0.01705185  2.19945359]\n",
      " [-1.00710324 -0.75512544  1.76237337]]\n",
      "479000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1785290766094848\n",
      "[[ 0.65458234  0.55134689 -1.20605889]\n",
      " [ 1.58059785 -0.28463303 -1.296307  ]\n",
      " [-2.1836227  -0.01738989  2.20142893]\n",
      " [-1.00787696 -0.75614245  1.7641641 ]]\n",
      "480000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17834863398559364\n",
      "[[ 0.65516358  0.55187204 -1.20716528]\n",
      " [ 1.58184158 -0.28449257 -1.29769118]\n",
      " [-2.18525733 -0.0177272   2.20340087]\n",
      " [-1.00864947 -0.75715788  1.76595203]]\n",
      "481000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1781687655001423\n",
      "[[ 0.65574394  0.55239592 -1.20826951]\n",
      " [ 1.58308326 -0.2843519  -1.29907354]\n",
      " [-2.18688932 -0.01806378  2.20536943]\n",
      " [-1.00942077 -0.75817171  1.76773717]]\n",
      "482000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17798946834548787\n",
      "[[ 0.6563234   0.55291854 -1.20937159]\n",
      " [ 1.58432289 -0.28421101 -1.30045406]\n",
      " [-2.18851865 -0.01839964  2.20733463]\n",
      " [-1.01019087 -0.75918397  1.76951952]]\n",
      "483000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17781073973232592\n",
      "[[ 0.65690198  0.5534399  -1.21047153]\n",
      " [ 1.5855605  -0.28406991 -1.30183277]\n",
      " [-2.19014536 -0.01873477  2.20929646]\n",
      " [-1.01095977 -0.76019466  1.77129911]]\n",
      "484000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17763257688954287\n",
      "[[ 0.65747967  0.55396    -1.21156933]\n",
      " [ 1.58679607 -0.28392859 -1.30320966]\n",
      " [-2.19176944 -0.01906918  2.21125495]\n",
      " [-1.01172747 -0.76120378  1.77307593]]\n",
      "485000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17745497706406665\n",
      "[[ 0.65805649  0.55447886 -1.212665  ]\n",
      " [ 1.58802962 -0.28378706 -1.30458474]\n",
      " [-2.1933909  -0.01940287  2.2132101 ]\n",
      " [-1.01249399 -0.76221133  1.77485   ]]\n",
      "486000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17727793752072163\n",
      "[[ 0.65863242  0.55499647 -1.21375854]\n",
      " [ 1.58926116 -0.28364532 -1.30595802]\n",
      " [-2.19500975 -0.01973585  2.21516193]\n",
      " [-1.01325932 -0.76321733  1.77662133]]\n",
      "487000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.177101455542084\n",
      "[[ 0.65920748  0.55551284 -1.21484997]\n",
      " [ 1.59049068 -0.28350337 -1.3073295 ]\n",
      " [-2.196626   -0.02006811  2.21711044]\n",
      " [-1.01402346 -0.76422177  1.77838992]]\n",
      "488000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17692552842833734\n",
      "[[ 0.65978167  0.55602798 -1.2159393 ]\n",
      " [ 1.59171821 -0.28336121 -1.30869918]\n",
      " [-2.19823966 -0.02039966  2.21905565]\n",
      " [-1.01478643 -0.76522467  1.78015578]]\n",
      "489000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17675015349713152\n",
      "[[ 0.66035498  0.55654188 -1.21702652]\n",
      " [ 1.59294374 -0.28321885 -1.31006706]\n",
      " [-2.19985074 -0.0207305   2.22099757]\n",
      " [-1.01554822 -0.76622602  1.78191893]]\n",
      "490000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17657532808344156\n",
      "[[ 0.66092743  0.55705457 -1.21811165]\n",
      " [ 1.59416728 -0.28307629 -1.31143317]\n",
      " [-2.20145924 -0.02106063  2.2229362 ]\n",
      " [-1.01630884 -0.76722584  1.78367936]]\n",
      "491000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17640104953942878\n",
      "[[ 0.66149901  0.55756603 -1.21919469]\n",
      " [ 1.59538883 -0.28293352 -1.31279749]\n",
      " [-2.20306518 -0.02139006  2.22487157]\n",
      " [-1.01706829 -0.76822412  1.7854371 ]]\n",
      "492000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17622731523430213\n",
      "[[ 0.66206973  0.55807627 -1.22027566]\n",
      " [ 1.59660841 -0.28279056 -1.31416004]\n",
      " [-2.20466855 -0.02171878  2.22680367]\n",
      " [-1.01782657 -0.76922088  1.78719214]]\n",
      "493000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17605412255418296\n",
      "[[ 0.66263959  0.55858531 -1.22135455]\n",
      " [ 1.59782602 -0.28264739 -1.31552081]\n",
      " [-2.20626938 -0.02204681  2.22873253]\n",
      " [-1.0185837  -0.77021612  1.7889445 ]]\n",
      "494000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17588146890196757\n",
      "[[ 0.6632086   0.55909313 -1.22243139]\n",
      " [ 1.59904167 -0.28250403 -1.31687982]\n",
      " [-2.20786767 -0.02237414  2.23065814]\n",
      " [-1.01933967 -0.77120983  1.79069419]]\n",
      "495000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17570935169719495\n",
      "[[ 0.66377675  0.55959976 -1.22350616]\n",
      " [ 1.60025536 -0.28236047 -1.31823707]\n",
      " [-2.20946342 -0.02270077  2.23258053]\n",
      " [-1.02009448 -0.77220204  1.79244121]]\n",
      "496000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17553776837591398\n",
      "[[ 0.66434405  0.56010518 -1.22457888]\n",
      " [ 1.60146709 -0.28221672 -1.31959255]\n",
      " [-2.21105665 -0.02302672  2.2344997 ]\n",
      " [-1.02084815 -0.77319274  1.79418557]]\n",
      "497000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1753667163905505\n",
      "[[ 0.6649105   0.56060941 -1.22564957]\n",
      " [ 1.60267689 -0.28207278 -1.32094629]\n",
      " [-2.21264736 -0.02335197  2.23641566]\n",
      " [-1.02160067 -0.77418193  1.79592729]]\n",
      "498000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17519619320977853\n",
      "[[ 0.6654761   0.56111246 -1.22671821]\n",
      " [ 1.60388474 -0.28192864 -1.32229828]\n",
      " [-2.21423556 -0.02367653  2.23832843]\n",
      " [-1.02235205 -0.77516963  1.79766636]]\n",
      "499000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17502619631839053\n",
      "[[ 0.66604086  0.56161432 -1.22778483]\n",
      " [ 1.60509066 -0.28178432 -1.32364853]\n",
      " [-2.21582126 -0.02400041  2.240238  ]\n",
      " [-1.02310229 -0.77615583  1.7994028 ]]\n",
      "500000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17485672321717008\n",
      "[[ 0.66660478  0.56211499 -1.22884943]\n",
      " [ 1.60629466 -0.28163981 -1.32499703]\n",
      " [-2.21740447 -0.0243236   2.2421444 ]\n",
      " [-1.02385139 -0.77714055  1.80113662]]\n",
      "501000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17468777142276495\n",
      "[[ 0.66716786  0.5626145  -1.22991201]\n",
      " [ 1.60749674 -0.28149511 -1.32634381]\n",
      " [-2.21898519 -0.02464611  2.24404764]\n",
      " [-1.02459937 -0.77812378  1.80286783]]\n",
      "502000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17451933846756193\n",
      "[[ 0.66773011  0.56311283 -1.23097259]\n",
      " [ 1.6086969  -0.28135023 -1.32768885]\n",
      " [-2.22056344 -0.02496795  2.24594772]\n",
      " [-1.02534621 -0.77910553  1.80459643]]\n",
      "503000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17435142189956185\n",
      "[[ 0.66829152  0.56360999 -1.23203116]\n",
      " [ 1.60989515 -0.28120516 -1.32903217]\n",
      " [-2.22213921 -0.0252891   2.24784465]\n",
      " [-1.02609193 -0.78008581  1.80632243]]\n",
      "504000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17418401928225835\n",
      "[[ 0.6688521   0.56410599 -1.23308774]\n",
      " [ 1.61109151 -0.28105991 -1.33037377]\n",
      " [-2.22371253 -0.02560959  2.24973845]\n",
      " [-1.02683653 -0.78106462  1.80804584]]\n",
      "505000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17401712819451412\n",
      "[[ 0.66941185  0.56460083 -1.23414234]\n",
      " [ 1.61228596 -0.28091448 -1.33171366]\n",
      " [-2.22528339 -0.0259294   2.25162912]\n",
      " [-1.02758001 -0.78204197  1.80976667]]\n",
      "506000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17385074623044108\n",
      "[[ 0.66997078  0.56509452 -1.23519495]\n",
      " [ 1.61347853 -0.28076888 -1.33305183]\n",
      " [-2.22685181 -0.02624854  2.25351668]\n",
      " [-1.02832238 -0.78301786  1.81148493]]\n",
      "507000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17368487099928118\n",
      "[[ 0.67052888  0.56558706 -1.23624559]\n",
      " [ 1.61466922 -0.28062309 -1.3343883 ]\n",
      " [-2.22841778 -0.02656701  2.25540113]\n",
      " [-1.02906364 -0.78399229  1.81320062]]\n",
      "508000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1735195001252868\n",
      "[[ 0.67108616  0.56607845 -1.23729426]\n",
      " [ 1.61585802 -0.28047713 -1.33572307]\n",
      " [-2.22998133 -0.02688482  2.25728248]\n",
      " [-1.0298038  -0.78496527  1.81491375]]\n",
      "509000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17335463124760447\n",
      "[[ 0.67164263  0.5665687  -1.23834098]\n",
      " [ 1.61704496 -0.280331   -1.33705614]\n",
      " [-2.23154245 -0.02720196  2.25916075]\n",
      " [-1.03054284 -0.78593681  1.81662434]]\n",
      "510000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1731902620201575\n",
      "[[ 0.67219827  0.56705781 -1.23938574]\n",
      " [ 1.61823003 -0.28018469 -1.33838752]\n",
      " [-2.23310116 -0.02751844  2.26103594]\n",
      " [-1.03128079 -0.7869069   1.81833238]]\n",
      "511000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17302639011153242\n",
      "[[ 0.67275311  0.56754579 -1.24042855]\n",
      " [ 1.61941324 -0.28003821 -1.3397172 ]\n",
      " [-2.23465747 -0.02783427  2.26290807]\n",
      " [-1.03201764 -0.78787556  1.82003789]]\n",
      "512000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17286301320486344\n",
      "[[ 0.67330713  0.56803264 -1.24146943]\n",
      " [ 1.62059459 -0.27989157 -1.34104521]\n",
      " [-2.23621137 -0.02814943  2.26477714]\n",
      " [-1.0327534  -0.78884278  1.82174087]]\n",
      "513000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17270012899771964\n",
      "[[ 0.67386035  0.56851836 -1.24250837]\n",
      " [ 1.6217741  -0.27974475 -1.34237153]\n",
      " [-2.23776288 -0.02846395  2.26664316]\n",
      " [-1.03348807 -0.78980858  1.82344134]]\n",
      "514000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17253773520199311\n",
      "[[ 0.67441276  0.56900297 -1.24354538]\n",
      " [ 1.62295177 -0.27959776 -1.34369618]\n",
      " [-2.239312   -0.02877781  2.26850614]\n",
      " [-1.03422166 -0.79077296  1.8251393 ]]\n",
      "515000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1723758295437887\n",
      "[[ 0.67496436  0.56948646 -1.24458047]\n",
      " [ 1.62412759 -0.27945061 -1.34501916]\n",
      " [-2.24085875 -0.02909102  2.2703661 ]\n",
      " [-1.03495415 -0.79173591  1.82683475]]\n",
      "516000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1722144097633127\n",
      "[[ 0.67551517  0.56996883 -1.24561365]\n",
      " [ 1.62530159 -0.2793033  -1.34634048]\n",
      " [-2.24240312 -0.02940358  2.27222304]\n",
      " [-1.03568557 -0.79269746  1.82852772]]\n",
      "517000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17205347361476508\n",
      "[[ 0.67606517  0.5704501  -1.24664492]\n",
      " [ 1.62647377 -0.27915582 -1.34766013]\n",
      " [-2.24394514 -0.02971549  2.27407697]\n",
      " [-1.03641592 -0.79365759  1.83021819]]\n",
      "518000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.171893018866231\n",
      "[[ 0.67661438  0.57093026 -1.24767429]\n",
      " [ 1.62764412 -0.27900818 -1.34897812]\n",
      " [-2.2454848  -0.03002677  2.2759279 ]\n",
      " [-1.03714519 -0.79461632  1.83190619]]\n",
      "519000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1717330432995741\n",
      "[[ 0.6771628   0.57140932 -1.24870177]\n",
      " [ 1.62881266 -0.27886037 -1.35029446]\n",
      " [-2.24702211 -0.0303374   2.27777584]\n",
      " [-1.03787339 -0.79557364  1.83359172]]\n",
      "520000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17157354471033048\n",
      "[[ 0.67771042  0.57188728 -1.24972736]\n",
      " [ 1.62997939 -0.27871241 -1.35160916]\n",
      " [-2.24855708 -0.03064739  2.2796208 ]\n",
      " [-1.03860052 -0.79652957  1.83527478]]\n",
      "521000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17141452090760315\n",
      "[[ 0.67825725  0.57236415 -1.25075106]\n",
      " [ 1.63114432 -0.27856429 -1.3529222 ]\n",
      " [-2.25008971 -0.03095674  2.28146278]\n",
      " [-1.03932659 -0.79748411  1.83695539]]\n",
      "522000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17125596971395946\n",
      "[[ 0.6788033   0.57283994 -1.25177289]\n",
      " [ 1.63230745 -0.27841602 -1.35423361]\n",
      " [-2.25162002 -0.03126546  2.28330181]\n",
      " [-1.0400516  -0.79843726  1.83863355]]\n",
      "523000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17109788896532657\n",
      "[[ 0.67934856  0.57331463 -1.25279285]\n",
      " [ 1.63346879 -0.27826759 -1.35554338]\n",
      " [-2.25314801 -0.03157354  2.28513788]\n",
      " [-1.04077556 -0.79938903  1.84030927]]\n",
      "524000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17094027651089025\n",
      "[[ 0.67989304  0.57378825 -1.25381095]\n",
      " [ 1.63462834 -0.27811901 -1.35685152]\n",
      " [-2.25467369 -0.03188099  2.28697101]\n",
      " [-1.04149846 -0.80033942  1.84198256]]\n",
      "525000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1707831302129932\n",
      "[[ 0.68043674  0.57426079 -1.25482719]\n",
      " [ 1.63578612 -0.27797027 -1.35815803]\n",
      " [-2.25619706 -0.03218781  2.28880121]\n",
      " [-1.04222031 -0.80128843  1.84365343]]\n",
      "526000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17062644794703474\n",
      "[[ 0.68097966  0.57473226 -1.25584158]\n",
      " [ 1.63694212 -0.27782138 -1.35946292]\n",
      " [-2.25771814 -0.03249401  2.29062848]\n",
      " [-1.04294111 -0.80223608  1.84532187]]\n",
      "527000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17047022760137215\n",
      "[[ 0.68152181  0.57520265 -1.25685412]\n",
      " [ 1.63809634 -0.27767234 -1.36076618]\n",
      " [-2.25923692 -0.03279958  2.29245284]\n",
      " [-1.04366087 -0.80318236  1.84698791]]\n",
      "528000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17031446707722148\n",
      "[[ 0.68206318  0.57567199 -1.25786482]\n",
      " [ 1.63924881 -0.27752315 -1.36206784]\n",
      " [-2.26075342 -0.03310453  2.29427428]\n",
      " [-1.04437958 -0.80412727  1.84865154]]\n",
      "529000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17015916428855996\n",
      "[[ 0.68260379  0.57614026 -1.2588737 ]\n",
      " [ 1.64039952 -0.27737382 -1.36336788]\n",
      " [-2.26226764 -0.03340885  2.29609283]\n",
      " [-1.04509726 -0.80507083  1.85031277]]\n",
      "530000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.17000431716203032\n",
      "[[ 0.68314362  0.57660747 -1.25988074]\n",
      " [ 1.64154847 -0.27722434 -1.36466631]\n",
      " [-2.2637796  -0.03371256  2.29790849]\n",
      " [-1.04581391 -0.80601303  1.85197162]]\n",
      "531000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16984992363684362\n",
      "[[ 0.68368269  0.57707363 -1.26088597]\n",
      " [ 1.64269568 -0.27707471 -1.36596314]\n",
      " [-2.26528929 -0.03401565  2.29972127]\n",
      " [-1.04652952 -0.80695389  1.85362809]]\n",
      "532000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16969598166468544\n",
      "[[ 0.68422099  0.57753873 -1.26188938]\n",
      " [ 1.64384114 -0.27692494 -1.36725838]\n",
      " [-2.26679672 -0.03431812  2.30153118]\n",
      " [-1.0472441  -0.8078934   1.85528218]]\n",
      "533000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1695424892096212\n",
      "[[ 0.68475853  0.57800279 -1.26289098]\n",
      " [ 1.64498486 -0.27677503 -1.36855202]\n",
      " [-2.26830191 -0.03461999  2.30333823]\n",
      " [-1.04795766 -0.80883156  1.85693391]]\n",
      "534000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16938944424800279\n",
      "[[ 0.68529531  0.57846581 -1.26389078]\n",
      " [ 1.64612686 -0.27662498 -1.36984406]\n",
      " [-2.26980485 -0.03492124  2.30514242]\n",
      " [-1.0486702  -0.80976839  1.85858328]]\n",
      "535000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16923684476837683\n",
      "[[ 0.68583133  0.57892779 -1.26488878]\n",
      " [ 1.64726712 -0.27647478 -1.37113452]\n",
      " [-2.27130555 -0.03522188  2.30694377]\n",
      " [-1.04938171 -0.81070389  1.86023029]]\n",
      "536000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16908468877139246\n",
      "[[ 0.6863666   0.57938874 -1.26588499]\n",
      " [ 1.64840567 -0.27632445 -1.3724234 ]\n",
      " [-2.27280403 -0.03552191  2.30874228]\n",
      " [-1.05009221 -0.81163806  1.86187496]]\n",
      "537000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16893297426971132\n",
      "[[ 0.68690112  0.57984865 -1.26687942]\n",
      " [ 1.6495425  -0.27617398 -1.3737107 ]\n",
      " [-2.27430029 -0.03582134  2.31053796]\n",
      " [-1.0508017  -0.81257091  1.86351729]]\n",
      "538000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16878169928791664\n",
      "[[ 0.68743488  0.58030753 -1.26787206]\n",
      " [ 1.65067762 -0.27602337 -1.37499643]\n",
      " [-2.27579433 -0.03612016  2.31233082]\n",
      " [-1.05151018 -0.81350243  1.86515729]]\n",
      "539000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16863086186242474\n",
      "[[ 0.68796789  0.58076539 -1.26886294]\n",
      " [ 1.65181103 -0.27587263 -1.37628058]\n",
      " [-2.27728616 -0.03641839  2.31412088]\n",
      " [-1.05221765 -0.81443264  1.86679497]]\n",
      "540000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16848046004139672\n",
      "[[ 0.68850016  0.58122223 -1.26985204]\n",
      " [ 1.65294274 -0.27572175 -1.37756317]\n",
      " [-2.27877578 -0.03671601  2.31590813]\n",
      " [-1.05292411 -0.81536153  1.86843033]]\n",
      "541000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1683304918846512\n",
      "[[ 0.68903169  0.58167805 -1.27083939]\n",
      " [ 1.65407276 -0.27557074 -1.3788442 ]\n",
      " [-2.28026322 -0.03701304  2.31769259]\n",
      " [-1.05362958 -0.81628911  1.87006338]]\n",
      "542000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16818095546357612\n",
      "[[ 0.68956247  0.58213286 -1.27182498]\n",
      " [ 1.65520108 -0.2754196  -1.38012367]\n",
      " [-2.28174846 -0.03730947  2.31947426]\n",
      " [-1.05433404 -0.8172154   1.87169412]]\n",
      "543000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16803184886104494\n",
      "[[ 0.69009251  0.58258665 -1.27280882]\n",
      " [ 1.65632772 -0.27526832 -1.38140158]\n",
      " [-2.28323152 -0.0376053   2.32125316]\n",
      " [-1.05503751 -0.81814037  1.87332257]]\n",
      "544000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16788317017132906\n",
      "[[ 0.69062181  0.58303944 -1.27379091]\n",
      " [ 1.65745268 -0.27511692 -1.38267794]\n",
      " [-2.2847124  -0.03790055  2.32302929]\n",
      " [-1.05573999 -0.81906406  1.87494873]]\n",
      "545000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16773491750001554\n",
      "[[ 0.69115038  0.58349123 -1.27477126]\n",
      " [ 1.65857596 -0.27496539 -1.38395275]\n",
      " [-2.28619112 -0.0381952   2.32480266]\n",
      " [-1.05644148 -0.81998645  1.87657261]]\n",
      "546000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16758708896392202\n",
      "[[ 0.69167821  0.58394202 -1.27574988]\n",
      " [ 1.65969758 -0.27481373 -1.38522603]\n",
      " [-2.28766767 -0.03848927  2.32657327]\n",
      " [-1.05714198 -0.82090755  1.87819421]]\n",
      "547000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1674396826910137\n",
      "[[ 0.69220531  0.58439181 -1.27672678]\n",
      " [ 1.66081752 -0.27466195 -1.38649776]\n",
      " [-2.28914206 -0.03878275  2.32834115]\n",
      " [-1.05784149 -0.82182736  1.87981354]]\n",
      "548000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16729269682032155\n",
      "[[ 0.69273168  0.58484061 -1.27770195]\n",
      " [ 1.66193581 -0.27451004 -1.38776796]\n",
      " [-2.29061431 -0.03907565  2.33010629]\n",
      " [-1.05854003 -0.8227459   1.88143061]]\n",
      "549000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1671461295018613\n",
      "[[ 0.69325733  0.58528842 -1.2786754 ]\n",
      " [ 1.66305244 -0.274358   -1.38903662]\n",
      " [-2.29208441 -0.03936796  2.3318687 ]\n",
      " [-1.05923759 -0.82366315  1.88304543]]\n",
      "550000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16699997889655135\n",
      "[[ 0.69378224  0.58573524 -1.27964714]\n",
      " [ 1.66416742 -0.27420585 -1.39030376]\n",
      " [-2.29355237 -0.03965969  2.3336284 ]\n",
      " [-1.05993417 -0.82457914  1.88465799]]\n",
      "551000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1668542431761333\n",
      "[[ 0.69430644  0.58618108 -1.28061718]\n",
      " [ 1.66528076 -0.27405357 -1.39156937]\n",
      " [-2.2950182  -0.03995085  2.33538538]\n",
      " [-1.06062978 -0.82549385  1.88626832]]\n",
      "552000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16670892052309294\n",
      "[[ 0.69482991  0.58662595 -1.28158551]\n",
      " [ 1.66639245 -0.27390117 -1.39283347]\n",
      " [-2.2964819  -0.04024143  2.33713966]\n",
      " [-1.06132442 -0.8264073   1.88787641]]\n",
      "553000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1665640091305807\n",
      "[[ 0.69535267  0.58706983 -1.28255215]\n",
      " [ 1.66750251 -0.27374865 -1.39409604]\n",
      " [-2.29794349 -0.04053143  2.33889125]\n",
      " [-1.0620181  -0.82731948  1.88948226]]\n",
      "554000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1664195072023345\n",
      "[[ 0.6958747   0.58751275 -1.28351711]\n",
      " [ 1.66861094 -0.27359601 -1.39535711]\n",
      " [-2.29940296 -0.04082086  2.34064015]\n",
      " [-1.06271081 -0.82823041  1.8910859 ]]\n",
      "555000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1662754129526017\n",
      "[[ 0.69639602  0.5879547  -1.28448037]\n",
      " [ 1.66971774 -0.27344326 -1.39661666]\n",
      " [-2.30086033 -0.04110971  2.34238638]\n",
      " [-1.06340256 -0.82914008  1.89268732]]\n",
      "556000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16613172460606307\n",
      "[[ 0.69691663  0.58839568 -1.28544196]\n",
      " [ 1.67082292 -0.27329038 -1.39787471]\n",
      " [-2.3023156  -0.041398    2.34412993]\n",
      " [-1.06409335 -0.8300485   1.89428653]]\n",
      "557000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1659884403977557\n",
      "[[ 0.69743653  0.5888357  -1.28640188]\n",
      " [ 1.67192648 -0.2731374  -1.39913126]\n",
      " [-2.30376877 -0.04168572  2.34587082]\n",
      " [-1.06478318 -0.83095567  1.89588354]]\n",
      "558000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16584555857299943\n",
      "[[ 0.69795571  0.58927476 -1.28736012]\n",
      " [ 1.67302843 -0.2729843  -1.40038631]\n",
      " [-2.30521986 -0.04197287  2.34760906]\n",
      " [-1.06547206 -0.8318616   1.89747835]]\n",
      "559000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1657030773873205\n",
      "[[ 0.69847419  0.58971286 -1.28831671]\n",
      " [ 1.67412877 -0.27283108 -1.40163987]\n",
      " [-2.30666886 -0.04225946  2.34934465]\n",
      " [-1.06616    -0.83276629  1.89907097]]\n",
      "560000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1655609951063785\n",
      "[[ 0.69899197  0.59015001 -1.28927163]\n",
      " [ 1.67522751 -0.27267775 -1.40289194]\n",
      " [-2.30811579 -0.04254548  2.3510776 ]\n",
      " [-1.06684698 -0.83366974  1.90066141]]\n",
      "561000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16541931000589222\n",
      "[[ 0.69950904  0.59058622 -1.29022491]\n",
      " [ 1.67632466 -0.27252432 -1.40414252]\n",
      " [-2.30956064 -0.04283095  2.35280793]\n",
      " [-1.06753302 -0.83457196  1.90224967]]\n",
      "562000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16527802037156752\n",
      "[[ 0.70002541  0.59102148 -1.29117654]\n",
      " [ 1.6774202  -0.27237077 -1.40539162]\n",
      " [-2.31100344 -0.04311586  2.35453563]\n",
      " [-1.06821812 -0.83547295  1.90383576]]\n",
      "563000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1651371244990253\n",
      "[[ 0.70054108  0.59145579 -1.29212652]\n",
      " [ 1.67851416 -0.27221711 -1.40663923]\n",
      " [-2.31244417 -0.0434002   2.35626071]\n",
      " [-1.06890228 -0.83637272  1.90541968]]\n",
      "564000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16499662069372942\n",
      "[[ 0.70105605  0.59188917 -1.29307487]\n",
      " [ 1.67960654 -0.27206334 -1.40788538]\n",
      " [-2.31388285 -0.043684    2.35798318]\n",
      " [-1.0695855  -0.83727126  1.90700144]]\n",
      "565000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16485650727091614\n",
      "[[ 0.70157032  0.59232161 -1.29402159]\n",
      " [ 1.68069734 -0.27190947 -1.40913004]\n",
      " [-2.31531949 -0.04396724  2.35970306]\n",
      " [-1.07026779 -0.83816858  1.90858106]]\n",
      "566000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1647167825555238\n",
      "[[ 0.70208391  0.59275312 -1.29496668]\n",
      " [ 1.68178656 -0.27175549 -1.41037325]\n",
      " [-2.31675409 -0.04424992  2.36142034]\n",
      " [-1.07094914 -0.83906469  1.91015852]]\n",
      "567000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1645774448821231\n",
      "[[ 0.7025968   0.59318369 -1.29591015]\n",
      " [ 1.68287421 -0.27160141 -1.41161498]\n",
      " [-2.31818665 -0.04453206  2.36313504]\n",
      " [-1.07162957 -0.83995959  1.91173385]]\n",
      "568000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16443849259484786\n",
      "[[ 0.703109    0.59361335 -1.296852  ]\n",
      " [ 1.68396029 -0.27144722 -1.41285526]\n",
      " [-2.31961719 -0.04481365  2.36484716]\n",
      " [-1.07230907 -0.84085329  1.91330704]]\n",
      "569000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16429992404732716\n",
      "[[ 0.70362051  0.59404207 -1.29779224]\n",
      " [ 1.68504482 -0.27129292 -1.41409407]\n",
      " [-2.3210457  -0.04509469  2.36655672]\n",
      " [-1.07298765 -0.84174577  1.91487811]]\n",
      "570000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16416173760261693\n",
      "[[ 0.70413134  0.59446988 -1.29873088]\n",
      " [ 1.68612778 -0.27113853 -1.41533143]\n",
      " [-2.32247219 -0.04537518  2.36826371]\n",
      " [-1.07366531 -0.84263706  1.91644705]]\n",
      "571000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1640239316331322\n",
      "[[ 0.70464148  0.59489677 -1.29966791]\n",
      " [ 1.6872092  -0.27098403 -1.41656734]\n",
      " [-2.32389668 -0.04565513  2.36996814]\n",
      " [-1.07434205 -0.84352715  1.91801388]]\n",
      "572000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16388650452058096\n",
      "[[ 0.70515094  0.59532275 -1.30060335]\n",
      " [ 1.68828906 -0.27082944 -1.41780181]\n",
      " [-2.32531916 -0.04593454  2.37167003]\n",
      " [-1.07501787 -0.84441604  1.9195786 ]]\n",
      "573000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16374945465589838\n",
      "[[ 0.70565972  0.59574782 -1.3015372 ]\n",
      " [ 1.68936739 -0.27067474 -1.41903483]\n",
      " [-2.32673963 -0.04621341  2.37336938]\n",
      " [-1.07569278 -0.84530375  1.92114122]]\n",
      "574000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16361278043918026\n",
      "[[ 0.70616783  0.59617198 -1.30246946]\n",
      " [ 1.69044417 -0.27051995 -1.42026641]\n",
      " [-2.32815812 -0.04649174  2.37506619]\n",
      " [-1.07636678 -0.84619027  1.92270174]]\n",
      "575000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16347648027961864\n",
      "[[ 0.70667525  0.59659523 -1.30340014]\n",
      " [ 1.69151942 -0.27036505 -1.42149655]\n",
      " [-2.32957462 -0.04676953  2.37676048]\n",
      " [-1.07703988 -0.84707561  1.92426017]]\n",
      "576000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16334055259543676\n",
      "[[ 0.707182    0.59701758 -1.30432924]\n",
      " [ 1.69259314 -0.27021007 -1.42272526]\n",
      " [-2.33098913 -0.04704679  2.37845226]\n",
      " [-1.07771206 -0.84795976  1.92581651]]\n",
      "577000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16320499581382547\n",
      "[[ 0.70768808  0.59743904 -1.30525677]\n",
      " [ 1.69366534 -0.27005498 -1.42395254]\n",
      " [-2.33240167 -0.04732352  2.38014152]\n",
      " [-1.07838335 -0.84884274  1.92737077]]\n",
      "578000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16306980837087953\n",
      "[[ 0.70819348  0.5978596  -1.30618274]\n",
      " [ 1.69473601 -0.2698998  -1.42517839]\n",
      " [-2.33381224 -0.04759971  2.38182828]\n",
      " [-1.07905373 -0.84972455  1.92892296]]\n",
      "579000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16293498871153514\n",
      "[[ 0.70869822  0.59827926 -1.30710714]\n",
      " [ 1.69580516 -0.26974453 -1.42640282]\n",
      " [-2.33522084 -0.04787537  2.38351254]\n",
      " [-1.07972322 -0.85060518  1.93047308]]\n",
      "580000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16280053528950755\n",
      "[[ 0.70920229  0.59869804 -1.30802998]\n",
      " [ 1.69687281 -0.26958916 -1.42762582]\n",
      " [-2.33662748 -0.0481505   2.38519431]\n",
      " [-1.08039181 -0.85148465  1.93202114]]\n",
      "581000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16266644656722884\n",
      "[[ 0.7097057   0.59911593 -1.30895128]\n",
      " [ 1.69793894 -0.2694337  -1.42884742]\n",
      " [-2.33803216 -0.04842511  2.3868736 ]\n",
      " [-1.0810595  -0.85236296  1.93356715]]\n",
      "582000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16253272101578636\n",
      "[[ 0.71020844  0.59953293 -1.30987102]\n",
      " [ 1.69900357 -0.26927815 -1.4300676 ]\n",
      " [-2.3394349  -0.04869919  2.38855042]\n",
      " [-1.08172631 -0.85324011  1.9351111 ]]\n",
      "583000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16239935711486328\n",
      "[[ 0.71071051  0.59994906 -1.31078923]\n",
      " [ 1.7000667  -0.26912251 -1.43128636]\n",
      " [-2.34083569 -0.04897274  2.39022477]\n",
      " [-1.08239223 -0.8541161   1.93665301]]\n",
      "584000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1622663533526764\n",
      "[[ 0.71121193  0.60036431 -1.31170589]\n",
      " [ 1.70112833 -0.26896678 -1.43250373]\n",
      " [-2.34223455 -0.04924578  2.39189666]\n",
      " [-1.08305727 -0.85499093  1.93819289]]\n",
      "585000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16213370822591824\n",
      "[[ 0.71171269  0.60077868 -1.31262102]\n",
      " [ 1.70218847 -0.26881097 -1.43371969]\n",
      " [-2.34363147 -0.04951829  2.3935661 ]\n",
      " [-1.08372142 -0.85586462  1.93973072]]\n",
      "586000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16200142023969652\n",
      "[[ 0.71221279  0.60119218 -1.31353463]\n",
      " [ 1.70324713 -0.26865506 -1.43493425]\n",
      " [-2.34502646 -0.04979029  2.39523308]\n",
      " [-1.08438469 -0.85673716  1.94126654]]\n",
      "587000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1618694879074756\n",
      "[[ 0.71271224  0.60160481 -1.31444671]\n",
      " [ 1.7043043  -0.26849907 -1.43614741]\n",
      " [-2.34641954 -0.05006176  2.39689763]\n",
      " [-1.08504708 -0.85760856  1.94280033]]\n",
      "588000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16173790975101857\n",
      "[[ 0.71321104  0.60201658 -1.31535727]\n",
      " [ 1.70535999 -0.26834299 -1.43735918]\n",
      " [-2.34781069 -0.05033272  2.39855975]\n",
      " [-1.0857086  -0.85847882  1.9443321 ]]\n",
      "589000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16160668430032912\n",
      "[[ 0.71370918  0.60242748 -1.31626631]\n",
      " [ 1.70641421 -0.26818683 -1.43856956]\n",
      " [-2.34919994 -0.05060317  2.40021944]\n",
      " [-1.08636924 -0.85934794  1.94586186]]\n",
      "590000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16147581009359446\n",
      "[[ 0.71420667  0.60283752 -1.31717385]\n",
      " [ 1.70746696 -0.26803058 -1.43977856]\n",
      " [-2.35058728 -0.0508731   2.40187672]\n",
      " [-1.08702901 -0.86021592  1.94738962]]\n",
      "591000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16134528567712803\n",
      "[[ 0.71470352  0.60324671 -1.31807988]\n",
      " [ 1.70851824 -0.26787425 -1.44098617]\n",
      " [-2.35197272 -0.05114253  2.40353158]\n",
      " [-1.08768792 -0.86108278  1.94891538]]\n",
      "592000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16121510960531352\n",
      "[[ 0.71519972  0.60365504 -1.31898441]\n",
      " [ 1.70956806 -0.26771783 -1.4421924 ]\n",
      " [-2.35335626 -0.05141144  2.40518403]\n",
      " [-1.08834596 -0.86194851  1.95043915]]\n",
      "593000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16108528044054893\n",
      "[[ 0.71569527  0.60406251 -1.31988744]\n",
      " [ 1.71061641 -0.26756134 -1.44339726]\n",
      " [-2.35473791 -0.05167984  2.40683409]\n",
      " [-1.08900313 -0.86281312  1.95196093]]\n",
      "594000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16095579675319102\n",
      "[[ 0.71619018  0.60446914 -1.32078898]\n",
      " [ 1.71166332 -0.26740476 -1.44460074]\n",
      " [-2.35611768 -0.05194774  2.40848175]\n",
      " [-1.08965944 -0.8636766   1.95348073]]\n",
      "595000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1608266571215003\n",
      "[[ 0.71668445  0.60487492 -1.32168903]\n",
      " [ 1.71270877 -0.26724811 -1.44580285]\n",
      " [-2.35749557 -0.05221513  2.41012703]\n",
      " [-1.0903149  -0.86453897  1.95499855]]\n",
      "596000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16069786013158657\n",
      "[[ 0.71717809  0.60527986 -1.3225876 ]\n",
      " [ 1.71375278 -0.26709137 -1.44700359]\n",
      " [-2.35887158 -0.05248202  2.41176994]\n",
      " [-1.09096949 -0.86540022  1.9565144 ]]\n",
      "597000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16056940437735479\n",
      "[[ 0.71767108  0.60568396 -1.3234847 ]\n",
      " [ 1.71479535 -0.26693456 -1.44820297]\n",
      " [-2.36024573 -0.05274841  2.41341047]\n",
      " [-1.09162324 -0.86626036  1.95802828]]\n",
      "598000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16044128846045122\n",
      "[[ 0.71816344  0.60608722 -1.32438031]\n",
      " [ 1.71583648 -0.26677767 -1.44940099]\n",
      " [-2.36161801 -0.05301429  2.41504864]\n",
      " [-1.09227613 -0.86711939  1.9595402 ]]\n",
      "599000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16031351099021077\n",
      "[[ 0.71865516  0.60648965 -1.32527446]\n",
      " [ 1.71687617 -0.2666207  -1.45059765]\n",
      " [-2.36298843 -0.05327968  2.41668444]\n",
      " [-1.09292817 -0.86797732  1.96105017]]\n",
      "600000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16018607058360357\n",
      "[[ 0.71914625  0.60689124 -1.32616715]\n",
      " [ 1.71791443 -0.26646365 -1.45179296]\n",
      " [-2.364357   -0.05354457  2.4183179 ]\n",
      " [-1.09357936 -0.86883414  1.96255819]]\n",
      "601000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.16005896586518337\n",
      "[[ 0.71963672  0.607292   -1.32705837]\n",
      " [ 1.71895127 -0.26630654 -1.45298692]\n",
      " [-2.36572372 -0.05380896  2.41994901]\n",
      " [-1.09422971 -0.86968987  1.96406426]]\n",
      "602000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1599321954670351\n",
      "[[ 0.72012655  0.60769194 -1.32794814]\n",
      " [ 1.71998669 -0.26614934 -1.45417952]\n",
      " [-2.3670886  -0.05407286  2.42157779]\n",
      " [-1.09487922 -0.8705445   1.9655684 ]]\n",
      "603000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1598057580287232\n",
      "[[ 0.72061575  0.60809105 -1.32883645]\n",
      " [ 1.72102068 -0.26599207 -1.45537079]\n",
      " [-2.36845163 -0.05433626  2.42320423]\n",
      " [-1.09552788 -0.87139803  1.9670706 ]]\n",
      "604000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15967965219724145\n",
      "[[ 0.72110433  0.60848934 -1.32972332]\n",
      " [ 1.72205326 -0.26583474 -1.45656071]\n",
      " [-2.36981284 -0.05459918  2.42482835]\n",
      " [-1.09617571 -0.87225048  1.96857087]]\n",
      "605000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15955387662696136\n",
      "[[ 0.72159228  0.60888681 -1.33060874]\n",
      " [ 1.72308443 -0.26567732 -1.45774929]\n",
      " [-2.37117221 -0.0548616   2.42645014]\n",
      " [-1.0968227  -0.87310184  1.97006922]]\n",
      "606000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15942842997958237\n",
      "[[ 0.72207961  0.60928346 -1.33149273]\n",
      " [ 1.7241142  -0.26551984 -1.45893654]\n",
      " [-2.37252976 -0.05512353  2.42806963]\n",
      " [-1.09746886 -0.87395211  1.97156565]]\n",
      "607000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15930331092408223\n",
      "[[ 0.72256632  0.6096793  -1.33237528]\n",
      " [ 1.72514256 -0.26536229 -1.46012245]\n",
      " [-2.37388549 -0.05538498  2.42968681]\n",
      " [-1.09811418 -0.8748013   1.97306017]]\n",
      "608000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15917851813666728\n",
      "[[ 0.72305241  0.61007433 -1.3332564 ]\n",
      " [ 1.72616952 -0.26520466 -1.46130704]\n",
      " [-2.37523941 -0.05564594  2.43130169]\n",
      " [-1.09875868 -0.87564942  1.97455278]]\n",
      "609000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1590540503007239\n",
      "[[ 0.72353789  0.61046855 -1.33413609]\n",
      " [ 1.72719509 -0.26504697 -1.4624903 ]\n",
      " [-2.37659152 -0.05590642  2.43291427]\n",
      " [-1.09940235 -0.87649646  1.97604349]]\n",
      "610000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1589299061067688\n",
      "[[ 0.72402274  0.61086197 -1.33501436]\n",
      " [ 1.72821926 -0.26488921 -1.46367223]\n",
      " [-2.37794183 -0.05616641  2.43452457]\n",
      " [-1.10004519 -0.87734243  1.9775323 ]]\n",
      "611000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15880608425240184\n",
      "[[ 0.72450699  0.61125458 -1.33589122]\n",
      " [ 1.72924205 -0.26473138 -1.46485285]\n",
      " [-2.37929033 -0.05642593  2.43613259]\n",
      " [-1.10068721 -0.87818733  1.97901922]]\n",
      "612000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15868258344225777\n",
      "[[ 0.72499061  0.61164639 -1.33676666]\n",
      " [ 1.73026345 -0.26457349 -1.46603214]\n",
      " [-2.38063704 -0.05668496  2.43773834]\n",
      " [-1.10132841 -0.87903116  1.98050426]]\n",
      "613000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15855940238795946\n",
      "[[ 0.72547363  0.6120374  -1.33764069]\n",
      " [ 1.73128347 -0.26441553 -1.46721013]\n",
      " [-2.38198197 -0.05694351  2.43934181]\n",
      " [-1.10196879 -0.87987393  1.98198741]]\n",
      "614000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1584365398080698\n",
      "[[ 0.72595604  0.61242762 -1.33851331]\n",
      " [ 1.73230212 -0.2642575  -1.4683868 ]\n",
      " [-2.38332511 -0.05720159  2.44094303]\n",
      " [-1.10260836 -0.88071564  1.98346868]]\n",
      "615000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15831399442804497\n",
      "[[ 0.72643784  0.61281704 -1.33938454]\n",
      " [ 1.73331939 -0.26409941 -1.46956216]\n",
      " [-2.38466646 -0.05745919  2.44254199]\n",
      " [-1.10324711 -0.88155629  1.98494809]]\n",
      "616000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1581917649801898\n",
      "[[ 0.72691903  0.61320568 -1.34025436]\n",
      " [ 1.7343353  -0.26394126 -1.47073622]\n",
      " [-2.38600605 -0.05771632  2.4441387 ]\n",
      " [-1.10388505 -0.88239589  1.98642562]]\n",
      "617000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1580698502036096\n",
      "[[ 0.72739962  0.61359352 -1.3411228 ]\n",
      " [ 1.73534983 -0.26378304 -1.47190898]\n",
      " [-2.38734386 -0.05797297  2.44573316]\n",
      " [-1.10452218 -0.88323443  1.9879013 ]]\n",
      "618000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15794824884416606\n",
      "[[ 0.72787961  0.61398058 -1.34198984]\n",
      " [ 1.73636301 -0.26362476 -1.47308043]\n",
      " [-2.38867991 -0.05822915  2.44732539]\n",
      " [-1.1051585  -0.88407193  1.98937512]]\n",
      "619000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15782695965443172\n",
      "[[ 0.72835899  0.61436686 -1.34285551]\n",
      " [ 1.73737483 -0.26346642 -1.47425059]\n",
      " [-2.39001419 -0.05848486  2.44891539]\n",
      " [-1.10579402 -0.88490838  1.99084708]]\n",
      "620000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15770598139364508\n",
      "[[ 0.72883777  0.61475236 -1.34371979]\n",
      " [ 1.7383853  -0.26330802 -1.47541946]\n",
      " [-2.39134672 -0.0587401   2.45050316]\n",
      " [-1.10642873 -0.88574379  1.9923172 ]]\n",
      "621000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15758531282766575\n",
      "[[ 0.72931596  0.61513708 -1.34458269]\n",
      " [ 1.73939441 -0.26314955 -1.47658704]\n",
      " [-2.3926775  -0.05899488  2.45208872]\n",
      " [-1.10706265 -0.88657815  1.99378548]]\n",
      "622000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1574649527289311\n",
      "[[ 0.72979354  0.61552102 -1.34544422]\n",
      " [ 1.74040218 -0.26299103 -1.47775332]\n",
      " [-2.39400654 -0.05924919  2.45367206]\n",
      " [-1.10769576 -0.88741148  1.99525192]]\n",
      "623000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15734489987641156\n",
      "[[ 0.73027054  0.61590419 -1.34630438]\n",
      " [ 1.7414086  -0.26283245 -1.47891833]\n",
      " [-2.39533383 -0.05950303  2.45525319]\n",
      " [-1.10832807 -0.88824377  1.99671653]]\n",
      "624000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15722515305556792\n",
      "[[ 0.73074693  0.61628659 -1.34716318]\n",
      " [ 1.74241368 -0.26267381 -1.48008205]\n",
      " [-2.39665938 -0.05975641  2.45683213]\n",
      " [-1.1089596  -0.88907504  1.99817932]]\n",
      "625000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.157105711058308\n",
      "[[ 0.73122274  0.61666822 -1.34802062]\n",
      " [ 1.74341743 -0.26251512 -1.48124449]\n",
      " [-2.3979832  -0.06000933  2.45840886]\n",
      " [-1.10959032 -0.88990527  1.99964028]]\n",
      "626000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1569865726829438\n",
      "[[ 0.73169795  0.61704909 -1.3488767 ]\n",
      " [ 1.74441985 -0.26235636 -1.48240566]\n",
      " [-2.39930529 -0.06026179  2.45998341]\n",
      " [-1.11022026 -0.89073447  2.00109942]]\n",
      "627000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15686773673414905\n",
      "[[ 0.73217257  0.6174292  -1.34973142]\n",
      " [ 1.74542093 -0.26219756 -1.48356556]\n",
      " [-2.40062566 -0.06051379  2.46155578]\n",
      " [-1.11084941 -0.89156266  2.00255675]]\n",
      "628000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15674920202291717\n",
      "[[ 0.73264661  0.61780854 -1.3505848 ]\n",
      " [ 1.74642069 -0.26203869 -1.48472418]\n",
      " [-2.40194431 -0.06076533  2.46312597]\n",
      " [-1.11147777 -0.89238982  2.00401228]]\n",
      "629000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15663096736652013\n",
      "[[ 0.73312006  0.61818712 -1.35143684]\n",
      " [ 1.74741913 -0.26187977 -1.48588153]\n",
      " [-2.40326124 -0.06101641  2.46469399]\n",
      " [-1.11210535 -0.89321596  2.005466  ]]\n",
      "630000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15651303158846583\n",
      "[[ 0.73359292  0.61856495 -1.35228753]\n",
      " [ 1.74841625 -0.2617208  -1.48703763]\n",
      " [-2.40457647 -0.06126704  2.46625984]\n",
      " [-1.11273215 -0.89404109  2.00691792]]\n",
      "631000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15639539351845844\n",
      "[[ 0.7340652   0.61894203 -1.35313688]\n",
      " [ 1.74941205 -0.26156177 -1.48819246]\n",
      " [-2.40588999 -0.06151721  2.46782353]\n",
      " [-1.11335816 -0.8948652   2.00836805]]\n",
      "632000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15627805199235653\n",
      "[[ 0.7345369   0.61931835 -1.3539849 ]\n",
      " [ 1.75040654 -0.26140269 -1.48934603]\n",
      " [-2.40720181 -0.06176693  2.46938507]\n",
      " [-1.1139834  -0.89568831  2.00981639]]\n",
      "633000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15616100585213322\n",
      "[[ 0.73500801  0.61969393 -1.3548316 ]\n",
      " [ 1.75139973 -0.26124356 -1.49049834]\n",
      " [-2.40851193 -0.0620162   2.47094446]\n",
      " [-1.11460785 -0.89651041  2.01126295]]\n",
      "634000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15604425394583543\n",
      "[[ 0.73547855  0.62006876 -1.35567696]\n",
      " [ 1.7523916  -0.26108438 -1.4916494 ]\n",
      " [-2.40982036 -0.06226502  2.47250171]\n",
      " [-1.11523154 -0.8973315   2.01270772]]\n",
      "635000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15592779512754482\n",
      "[[ 0.73594851  0.62044284 -1.35652101]\n",
      " [ 1.75338218 -0.26092515 -1.49279921]\n",
      " [-2.4111271  -0.06251339  2.47405683]\n",
      " [-1.11585445 -0.89815159  2.01415073]]\n",
      "636000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15581162825733855\n",
      "[[ 0.7364179   0.62081618 -1.35736373]\n",
      " [ 1.75437146 -0.26076586 -1.49394778]\n",
      " [-2.41243216 -0.06276132  2.47560981]\n",
      " [-1.11647659 -0.89897068  2.01559196]]\n",
      "637000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15569575220124868\n",
      "[[ 0.7368867   0.62118879 -1.35820515]\n",
      " [ 1.75535945 -0.26060653 -1.4950951 ]\n",
      " [-2.41373554 -0.06300879  2.47716066]\n",
      " [-1.11709797 -0.89978877  2.01703143]]\n",
      "638000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15558016583122433\n",
      "[[ 0.73735494  0.62156065 -1.35904525]\n",
      " [ 1.75634614 -0.26044715 -1.49624117]\n",
      " [-2.41503724 -0.06325583  2.4787094 ]\n",
      " [-1.11771857 -0.90060588  2.01846913]]\n",
      "639000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1554648680250929\n",
      "[[ 0.7378226   0.62193178 -1.35988404]\n",
      " [ 1.75733155 -0.26028772 -1.49738601]\n",
      " [-2.41633727 -0.06350241  2.48025602]\n",
      " [-1.11833841 -0.90142198  2.01990508]]\n",
      "640000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15534985766652215\n",
      "[[ 0.7382897   0.62230218 -1.36072153]\n",
      " [ 1.75831567 -0.26012824 -1.49852961]\n",
      " [-2.41763564 -0.06374856  2.48180054]\n",
      " [-1.11895749 -0.9022371   2.02133928]]\n",
      "641000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1552351336449811\n",
      "[[ 0.73875622  0.62267185 -1.36155772]\n",
      " [ 1.75929851 -0.25996872 -1.49967197]\n",
      " [-2.41893235 -0.06399427  2.48334295]\n",
      " [-1.11957581 -0.90305124  2.02277173]]\n",
      "642000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15512069485570434\n",
      "[[ 0.73922218  0.62304079 -1.36239262]\n",
      " [ 1.76028008 -0.25980915 -1.50081311]\n",
      " [-2.4202274  -0.06423953  2.48488326]\n",
      " [-1.12019337 -0.90386439  2.02420244]]\n",
      "643000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15500654019965288\n",
      "[[ 0.73968756  0.62340901 -1.36322622]\n",
      " [ 1.76126037 -0.25964953 -1.50195301]\n",
      " [-2.4215208  -0.06448436  2.48642149]\n",
      " [-1.12081017 -0.90467656  2.02563142]]\n",
      "644000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15489266858347692\n",
      "[[ 0.74015239  0.6237765  -1.36405854]\n",
      " [ 1.76223938 -0.25948987 -1.50309169]\n",
      " [-2.42281255 -0.06472875  2.48795763]\n",
      " [-1.12142622 -0.90548775  2.02705865]]\n",
      "645000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15477907891948103\n",
      "[[ 0.74061665  0.62414327 -1.36488957]\n",
      " [ 1.76321714 -0.25933017 -1.50422915]\n",
      " [-2.42410265 -0.0649727   2.48949168]\n",
      " [-1.12204152 -0.90629796  2.02848416]]\n",
      "646000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1546657701255851\n",
      "[[ 0.74108035  0.62450932 -1.36571932]\n",
      " [ 1.76419362 -0.25917042 -1.50536539]\n",
      " [-2.42539111 -0.06521622  2.49102366]\n",
      " [-1.12265606 -0.9071072   2.02990795]]\n",
      "647000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1545527411252903\n",
      "[[ 0.74154349  0.62487465 -1.36654779]\n",
      " [ 1.76516885 -0.25901062 -1.5065004 ]\n",
      " [-2.42667794 -0.0654593   2.49255358]\n",
      " [-1.12326986 -0.90791547  2.03133001]]\n",
      "648000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1544399908476413\n",
      "[[ 0.74200607  0.62523927 -1.36737499]\n",
      " [ 1.76614282 -0.25885079 -1.50763421]\n",
      " [-2.42796314 -0.06570195  2.49408142]\n",
      " [-1.1238829  -0.90872277  2.03275036]]\n",
      "649000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1543275182271921\n",
      "[[ 0.74246809  0.62560318 -1.36820092]\n",
      " [ 1.76711553 -0.25869091 -1.5087668 ]\n",
      " [-2.42924671 -0.06594418  2.49560721]\n",
      " [-1.1244952  -0.90952911  2.034169  ]]\n",
      "650000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1542153222039695\n",
      "[[ 0.74292955  0.62596637 -1.36902558]\n",
      " [ 1.76808699 -0.25853099 -1.50989818]\n",
      " [-2.43052865 -0.06618597  2.49713095]\n",
      " [-1.12510676 -0.91033448  2.03558593]]\n",
      "651000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15410340172343834\n",
      "[[ 0.74339046  0.62632886 -1.36984898]\n",
      " [ 1.76905721 -0.25837103 -1.51102835]\n",
      " [-2.43180898 -0.06642733  2.49865264]\n",
      " [-1.12571758 -0.91113889  2.03700116]]\n",
      "652000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15399175573646717\n",
      "[[ 0.74385082  0.62669065 -1.37067112]\n",
      " [ 1.77002617 -0.25821103 -1.51215732]\n",
      " [-2.43308769 -0.06666826  2.50017229]\n",
      " [-1.12632766 -0.91194235  2.03841469]]\n",
      "653000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1538803831992929\n",
      "[[ 0.74431062  0.62705172 -1.371492  ]\n",
      " [ 1.7709939  -0.25805099 -1.51328509]\n",
      " [-2.43436479 -0.06690877  2.50168989]\n",
      " [-1.126937   -0.91274484  2.03982652]]\n",
      "654000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1537692830734865\n",
      "[[ 0.74476988  0.6274121  -1.37231163]\n",
      " [ 1.77196039 -0.25789091 -1.51441166]\n",
      " [-2.43564028 -0.06714886  2.50320547]\n",
      " [-1.1275456  -0.91354639  2.04123667]]\n",
      "655000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1536584543259193\n",
      "[[ 0.74522858  0.62777178 -1.37313001]\n",
      " [ 1.77292565 -0.25773079 -1.51553703]\n",
      " [-2.43691417 -0.06738852  2.50471902]\n",
      " [-1.12815347 -0.91434698  2.04264513]]\n",
      "656000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15354789592872925\n",
      "[[ 0.74568673  0.62813076 -1.37394715]\n",
      " [ 1.77388967 -0.25757064 -1.51666121]\n",
      " [-2.43818646 -0.06762775  2.50623055]\n",
      " [-1.12876061 -0.91514662  2.04405192]]\n",
      "657000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15343760685928687\n",
      "[[ 0.74614434  0.62848905 -1.37476304]\n",
      " [ 1.77485246 -0.25741045 -1.51778419]\n",
      " [-2.43945716 -0.06786657  2.50774006]\n",
      " [-1.12936701 -0.91594532  2.04545702]]\n",
      "658000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15332758610016253\n",
      "[[ 0.7466014   0.62884664 -1.3755777 ]\n",
      " [ 1.77581403 -0.25725022 -1.51890599]\n",
      " [-2.44072627 -0.06810496  2.50924757]\n",
      " [-1.12997269 -0.91674308  2.04686045]]\n",
      "659000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15321783263909247\n",
      "[[ 0.74705792  0.62920354 -1.37639112]\n",
      " [ 1.77677437 -0.25708995 -1.5200266 ]\n",
      " [-2.44199379 -0.06834294  2.51075306]\n",
      " [-1.13057764 -0.91753989  2.04826222]]\n",
      "660000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.153108345468947\n",
      "[[ 0.7475139   0.62955976 -1.37720331]\n",
      " [ 1.7777335  -0.25692965 -1.52114603]\n",
      " [-2.44325973 -0.0685805   2.51225656]\n",
      " [-1.13118187 -0.91833577  2.04966232]]\n",
      "661000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15299912358769774\n",
      "[[ 0.74796933  0.62991528 -1.37801427]\n",
      " [ 1.77869141 -0.25676931 -1.52226427]\n",
      " [-2.44452409 -0.06881764  2.51375806]\n",
      " [-1.13178537 -0.91913071  2.05106076]]\n",
      "662000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15289016599838512\n",
      "[[ 0.74842422  0.63027013 -1.378824  ]\n",
      " [ 1.7796481  -0.25660894 -1.52338134]\n",
      " [-2.44578687 -0.06905437  2.51525757]\n",
      " [-1.13238815 -0.91992471  2.05245755]]\n",
      "663000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1527814717090859\n",
      "[[ 0.74887858  0.63062428 -1.37963252]\n",
      " [ 1.78060359 -0.25644853 -1.52449723]\n",
      " [-2.44704809 -0.06929068  2.5167551 ]\n",
      " [-1.13299021 -0.92071779  2.05385268]]\n",
      "664000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15267303973288218\n",
      "[[ 0.7493324   0.63097776 -1.38043981]\n",
      " [ 1.78155786 -0.2562881  -1.52561195]\n",
      " [-2.44830774 -0.06952658  2.51825065]\n",
      " [-1.13359155 -0.92150993  2.05524617]]\n",
      "665000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1525648690878296\n",
      "[[ 0.74978568  0.63133057 -1.38124589]\n",
      " [ 1.78251094 -0.25612762 -1.52672549]\n",
      " [-2.44956582 -0.06976206  2.51974422]\n",
      " [-1.13419218 -0.92230115  2.05663802]]\n",
      "666000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15245695879692528\n",
      "[[ 0.75023842  0.63168269 -1.38205076]\n",
      " [ 1.78346281 -0.25596712 -1.52783787]\n",
      " [-2.45082235 -0.06999714  2.52123582]\n",
      " [-1.13479209 -0.92309144  2.05802822]]\n",
      "667000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15234930788807793\n",
      "[[ 0.75069063  0.63203414 -1.38285443]\n",
      " [ 1.78441349 -0.25580658 -1.52894908]\n",
      " [-2.45207732 -0.0702318   2.52272546]\n",
      " [-1.1353913  -0.92388081  2.05941679]]\n",
      "668000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15224191539407608\n",
      "[[ 0.75114231  0.63238492 -1.38365688]\n",
      " [ 1.78536297 -0.25564601 -1.53005913]\n",
      " [-2.45333074 -0.07046606  2.52421314]\n",
      " [-1.13598979 -0.92466927  2.06080374]]\n",
      "669000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15213478035255776\n",
      "[[ 0.75159346  0.63273503 -1.38445814]\n",
      " [ 1.78631125 -0.25548542 -1.53116802]\n",
      " [-2.45458262 -0.07069991  2.52569886]\n",
      " [-1.13658757 -0.9254568   2.06218905]]\n",
      "670000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15202790180597991\n",
      "[[ 0.75204408  0.63308447 -1.3852582 ]\n",
      " [ 1.78725835 -0.25532479 -1.53227575]\n",
      " [-2.45583295 -0.07093335  2.52718263]\n",
      " [-1.13718464 -0.92624342  2.06357274]]\n",
      "671000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1519212788015888\n",
      "[[ 0.75249417  0.63343324 -1.38605706]\n",
      " [ 1.78820427 -0.25516413 -1.53338232]\n",
      " [-2.45708174 -0.07116639  2.52866446]\n",
      " [-1.13778101 -0.92702913  2.06495482]]\n",
      "672000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15181491039138933\n",
      "[[ 0.75294373  0.63378135 -1.38685473]\n",
      " [ 1.789149   -0.25500344 -1.53448774]\n",
      " [-2.458329   -0.07139902  2.53014436]\n",
      " [-1.13837667 -0.92781392  2.06633528]]\n",
      "673000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1517087956321154\n",
      "[[ 0.75339276  0.6341288  -1.38765121]\n",
      " [ 1.79009255 -0.25484272 -1.535592  ]\n",
      " [-2.45957472 -0.07163125  2.53162231]\n",
      " [-1.13897164 -0.92859781  2.06771413]]\n",
      "674000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1516029335852009\n",
      "[[ 0.75384127  0.63447558 -1.38844651]\n",
      " [ 1.79103492 -0.25468198 -1.53669512]\n",
      " [-2.46081892 -0.07186308  2.53309834]\n",
      " [-1.1395659  -0.92938079  2.06909137]]\n",
      "675000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15149732331675023\n",
      "[[ 0.75428926  0.63482171 -1.38924063]\n",
      " [ 1.79197612 -0.25452121 -1.53779709]\n",
      " [-2.4620616  -0.07209451  2.53457244]\n",
      " [-1.14015946 -0.93016287  2.07046702]]\n",
      "676000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15139196389750884\n",
      "[[ 0.75473673  0.63516719 -1.39003357]\n",
      " [ 1.79291615 -0.25436041 -1.53889792]\n",
      " [-2.46330275 -0.07232554  2.53604462]\n",
      " [-1.14075233 -0.93094405  2.07184106]]\n",
      "677000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15128685440283485\n",
      "[[ 0.75518367  0.635512   -1.39082533]\n",
      " [ 1.79385501 -0.25419958 -1.53999761]\n",
      " [-2.46454239 -0.07255617  2.53751489]\n",
      " [-1.1413445  -0.93172432  2.07321351]]\n",
      "678000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1511819939126707\n",
      "[[ 0.7556301   0.63585617 -1.39161592]\n",
      " [ 1.7947927  -0.25403873 -1.54109615]\n",
      " [-2.46578051 -0.0727864   2.53898324]\n",
      " [-1.14193598 -0.93250371  2.07458437]]\n",
      "679000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15107738151151348\n",
      "[[ 0.756076    0.63619969 -1.39240534]\n",
      " [ 1.79572923 -0.25387785 -1.54219356]\n",
      " [-2.46701713 -0.07301623  2.5404497 ]\n",
      " [-1.14252676 -0.93328219  2.07595364]]\n",
      "680000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15097301628838805\n",
      "[[ 0.75652139  0.63654255 -1.3931936 ]\n",
      " [ 1.7966646  -0.25371694 -1.54328984]\n",
      " [-2.46825224 -0.07324568  2.54191425]\n",
      " [-1.14311686 -0.93405979  2.07732133]]\n",
      "681000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15086889733681857\n",
      "[[ 0.75696626  0.63688477 -1.39398069]\n",
      " [ 1.79759882 -0.25355602 -1.54438498]\n",
      " [-2.46948585 -0.07347472  2.5433769 ]\n",
      " [-1.14370626 -0.93483649  2.07868744]]\n",
      "682000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15076502375480066\n",
      "[[ 0.75741062  0.63722635 -1.39476662]\n",
      " [ 1.79853188 -0.25339506 -1.545479  ]\n",
      " [-2.47071796 -0.07370337  2.54483767]\n",
      " [-1.14429498 -0.93561231  2.08005198]]\n",
      "683000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15066139464477346\n",
      "[[ 0.75785446  0.63756728 -1.3955514 ]\n",
      " [ 1.79946379 -0.25323409 -1.54657189]\n",
      " [-2.47194858 -0.07393164  2.54629655]\n",
      " [-1.14488302 -0.93638724  2.08141495]]\n",
      "684000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15055800911359285\n",
      "[[ 0.7582978   0.63790758 -1.39633503]\n",
      " [ 1.80039456 -0.25307309 -1.54766365]\n",
      " [-2.4731777  -0.07415951  2.54775354]\n",
      " [-1.14547037 -0.93716129  2.08277635]]\n",
      "685000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15045486627250393\n",
      "[[ 0.75874062  0.63824723 -1.3971175 ]\n",
      " [ 1.80132417 -0.25291206 -1.54875429]\n",
      " [-2.47440534 -0.07438699  2.54920866]\n",
      " [-1.14605704 -0.93793445  2.08413618]]\n",
      "686000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15035196523711414\n",
      "[[ 0.75918293  0.63858625 -1.39789883]\n",
      " [ 1.80225265 -0.25275102 -1.54984381]\n",
      " [-2.4756315  -0.07461408  2.55066191]\n",
      " [-1.14664303 -0.93870674  2.08549446]]\n",
      "687000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1502493051273667\n",
      "[[ 0.75962473  0.63892463 -1.39867901]\n",
      " [ 1.80317999 -0.25258995 -1.55093221]\n",
      " [-2.47685618 -0.07484078  2.55211329]\n",
      " [-1.14722834 -0.93947815  2.08685118]]\n",
      "688000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.15014688506751372\n",
      "[[ 0.76006602  0.63926238 -1.39945805]\n",
      " [ 1.80410619 -0.25242887 -1.5520195 ]\n",
      " [-2.47807938 -0.0750671   2.55356281]\n",
      " [-1.14781298 -0.94024869  2.08820635]]\n",
      "689000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1500447041860892\n",
      "[[ 0.76050681  0.6395995  -1.40023596]\n",
      " [ 1.80503125 -0.25226776 -1.55310567]\n",
      " [-2.47930111 -0.07529303  2.55501047]\n",
      " [-1.14839694 -0.94101835  2.08955997]]\n",
      "690000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14994276161588468\n",
      "[[ 0.76094709  0.63993598 -1.40101273]\n",
      " [ 1.80595519 -0.25210663 -1.55419074]\n",
      " [-2.48052137 -0.07551858  2.55645628]\n",
      " [-1.14898022 -0.94178714  2.09091205]]\n",
      "691000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14984105649392107\n",
      "[[ 0.76138687  0.64027184 -1.40178837]\n",
      " [ 1.80687799 -0.25194548 -1.55527469]\n",
      " [-2.48174017 -0.07574374  2.55790024]\n",
      " [-1.14956284 -0.94255507  2.09226259]]\n",
      "692000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1497395879614241\n",
      "[[ 0.76182615  0.64060708 -1.40256288]\n",
      " [ 1.80779967 -0.25178431 -1.55635754]\n",
      " [-2.4829575  -0.07596852  2.55934236]\n",
      " [-1.15014478 -0.94332213  2.09361159]]\n",
      "693000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14963835516379853\n",
      "[[ 0.76226492  0.64094169 -1.40333626]\n",
      " [ 1.80872023 -0.25162312 -1.55743929]\n",
      " [-2.48417338 -0.07619292  2.56078263]\n",
      " [-1.15072605 -0.94408832  2.09495906]]\n",
      "694000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1495373572506028\n",
      "[[ 0.76270319  0.64127568 -1.40410853]\n",
      " [ 1.80963967 -0.25146192 -1.55851993]\n",
      " [-2.4853878  -0.07641694  2.56222107]\n",
      " [-1.15130666 -0.94485365  2.096305  ]]\n",
      "695000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14943659337552304\n",
      "[[ 0.76314097  0.64160905 -1.40487967]\n",
      " [ 1.81055799 -0.25130069 -1.55959947]\n",
      " [-2.48660077 -0.07664058  2.56365768]\n",
      " [-1.1518866  -0.94561813  2.09764941]]\n",
      "696000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14933606269634903\n",
      "[[ 0.76357824  0.6419418  -1.40564969]\n",
      " [ 1.81147519 -0.25113945 -1.56067792]\n",
      " [-2.4878123  -0.07686384  2.56509247]\n",
      " [-1.15246588 -0.94638174  2.09899231]]\n",
      "697000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14923576437494843\n",
      "[[ 0.76401502  0.64227393 -1.40641861]\n",
      " [ 1.81239129 -0.25097819 -1.56175527]\n",
      " [-2.48902238 -0.07708672  2.56652543]\n",
      " [-1.15304449 -0.9471445   2.10033368]]\n",
      "698000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14913569757724265\n",
      "[[ 0.76445131  0.64260545 -1.40718641]\n",
      " [ 1.81330627 -0.25081692 -1.56283153]\n",
      " [-2.49023101 -0.07730923  2.56795658]\n",
      " [-1.15362245 -0.94790641  2.10167354]]\n",
      "699000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14903586147318237\n",
      "[[ 0.7648871   0.64293635 -1.4079531 ]\n",
      " [ 1.81422015 -0.25065562 -1.5639067 ]\n",
      " [-2.49143822 -0.07753136  2.56938591]\n",
      " [-1.15419974 -0.94866746  2.10301189]]\n",
      "700000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14893625523672221\n",
      "[[ 0.76532239  0.64326664 -1.40871869]\n",
      " [ 1.81513292 -0.25049432 -1.56498079]\n",
      " [-2.49264399 -0.07775312  2.57081344]\n",
      " [-1.15477638 -0.94942767  2.10434874]]\n",
      "701000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.148836878045798\n",
      "[[ 0.76575719  0.64359633 -1.40948318]\n",
      " [ 1.81604459 -0.25033299 -1.56605378]\n",
      " [-2.49384833 -0.0779745   2.57223916]\n",
      " [-1.15535236 -0.95018703  2.10568407]]\n",
      "702000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14873772908230173\n",
      "[[ 0.76619151  0.64392541 -1.41024657]\n",
      " [ 1.81695517 -0.25017165 -1.56712569]\n",
      " [-2.49505124 -0.07819552  2.57366309]\n",
      " [-1.15592769 -0.95094554  2.10701791]]\n",
      "703000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14863880753205802\n",
      "[[ 0.76662533  0.64425388 -1.41100886]\n",
      " [ 1.81786465 -0.2500103  -1.56819653]\n",
      " [-2.49625273 -0.07841616  2.57508522]\n",
      " [-1.15650236 -0.95170321  2.10835026]]\n",
      "704000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14854011258480043\n",
      "[[ 0.76705866  0.64458174 -1.41177006]\n",
      " [ 1.81877303 -0.24984894 -1.56926628]\n",
      " [-2.4974528  -0.07863643  2.57650556]\n",
      " [-1.15707638 -0.95246004  2.10968111]]\n",
      "705000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1484416434341485\n",
      "[[ 0.76749151  0.64490901 -1.41253017]\n",
      " [ 1.81968033 -0.24968755 -1.57033495]\n",
      " [-2.49865145 -0.07885633  2.57792411]\n",
      " [-1.15764975 -0.95321603  2.11101047]]\n",
      "706000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1483433992775837\n",
      "[[ 0.76792387  0.64523567 -1.41328919]\n",
      " [ 1.82058654 -0.24952616 -1.57140255]\n",
      " [-2.49984869 -0.07907586  2.57934089]\n",
      " [-1.15822247 -0.95397119  2.11233835]]\n",
      "707000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14824537931642628\n",
      "[[ 0.76835574  0.64556173 -1.41404713]\n",
      " [ 1.82149166 -0.24936475 -1.57246908]\n",
      " [-2.50104452 -0.07929503  2.58075589]\n",
      " [-1.15879455 -0.9547255   2.11366474]]\n",
      "708000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1481475827558128\n",
      "[[ 0.76878713  0.6458872  -1.41480398]\n",
      " [ 1.8223957  -0.24920334 -1.57353454]\n",
      " [-2.50223895 -0.07951383  2.58216911]\n",
      " [-1.15936598 -0.95547899  2.11498966]]\n",
      "709000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14805000880467317\n",
      "[[ 0.76921803  0.64621207 -1.41555976]\n",
      " [ 1.82329866 -0.2490419  -1.57459893]\n",
      " [-2.50343197 -0.07973226  2.58358057]\n",
      " [-1.15993677 -0.95623164  2.1163131 ]]\n",
      "710000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14795265667570792\n",
      "[[ 0.76964846  0.64653635 -1.41631446]\n",
      " [ 1.82420054 -0.24888046 -1.57566226]\n",
      " [-2.50462359 -0.07995033  2.58499026]\n",
      " [-1.16050691 -0.95698347  2.11763507]]\n",
      "711000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14785552558536538\n",
      "[[ 0.7700784   0.64686003 -1.41706809]\n",
      " [ 1.82510134 -0.24871901 -1.57672452]\n",
      " [-2.50581382 -0.08016804  2.58639819]\n",
      " [-1.16107642 -0.95773447  2.11895557]]\n",
      "712000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1477586147538199\n",
      "[[ 0.77050786  0.64718313 -1.41782064]\n",
      " [ 1.82600108 -0.24855754 -1.57778572]\n",
      " [-2.50700265 -0.08038538  2.58780437]\n",
      " [-1.16164528 -0.95848464  2.12027461]]\n",
      "713000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1476619234049493\n",
      "[[ 0.77093684  0.64750563 -1.41857213]\n",
      " [ 1.82689974 -0.24839607 -1.57884586]\n",
      " [-2.5081901  -0.08060236  2.58920879]\n",
      " [-1.16221351 -0.95923399  2.12159218]]\n",
      "714000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14756545076631325\n",
      "[[ 0.77136535  0.64782755 -1.41932256]\n",
      " [ 1.82779734 -0.24823458 -1.57990494]\n",
      " [-2.50937616 -0.08081898  2.59061147]\n",
      " [-1.1627811  -0.95998252  2.1229083 ]]\n",
      "715000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14746919606913061\n",
      "[[ 0.77179338  0.64814889 -1.42007192]\n",
      " [ 1.82869387 -0.24807309 -1.58096297]\n",
      " [-2.51056083 -0.08103525  2.59201241]\n",
      " [-1.16334805 -0.96073023  2.12422297]]\n",
      "716000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14737315854825903\n",
      "[[ 0.77222093  0.64846964 -1.42082022]\n",
      " [ 1.82958934 -0.24791159 -1.58201994]\n",
      " [-2.51174413 -0.08125115  2.59341161]\n",
      " [-1.16391437 -0.96147713  2.12553618]]\n",
      "717000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14727733744217217\n",
      "[[ 0.77264801  0.64878981 -1.42156747]\n",
      " [ 1.83048376 -0.24775007 -1.58307586]\n",
      " [-2.51292605 -0.08146669  2.59480907]\n",
      " [-1.16448006 -0.9622232   2.12684795]]\n",
      "718000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14718173199293838\n",
      "[[ 0.77307462  0.64910939 -1.42231366]\n",
      " [ 1.83137711 -0.24758855 -1.58413074]\n",
      " [-2.51410659 -0.08168188  2.59620481]\n",
      " [-1.16504512 -0.96296847  2.12815828]]\n",
      "719000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14708634144620067\n",
      "[[ 0.77350075  0.6494284  -1.42305881]\n",
      " [ 1.83226941 -0.24742703 -1.58518457]\n",
      " [-2.51528577 -0.08189672  2.59759882]\n",
      " [-1.16560955 -0.96371292  2.12946716]]\n",
      "720000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14699116505115417\n",
      "[[ 0.77392641  0.64974683 -1.4238029 ]\n",
      " [ 1.83316066 -0.24726549 -1.58623735]\n",
      " [-2.51646358 -0.0821112   2.59899111]\n",
      " [-1.16617335 -0.96445657  2.13077461]]\n",
      "721000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14689620206052628\n",
      "[[ 0.7743516   0.65006469 -1.42454595]\n",
      " [ 1.83405086 -0.24710395 -1.58728909]\n",
      " [-2.51764002 -0.08232532  2.60038167]\n",
      " [-1.16673653 -0.96519941  2.13208062]]\n",
      "722000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1468014517305548\n",
      "[[ 0.77477633  0.65038197 -1.42528795]\n",
      " [ 1.83494001 -0.2469424  -1.58833979]\n",
      " [-2.51881511 -0.08253909  2.60177053]\n",
      " [-1.16729908 -0.96594144  2.1333852 ]]\n",
      "723000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14670691332096877\n",
      "[[ 0.77520058  0.65069869 -1.42602892]\n",
      " [ 1.83582811 -0.24678084 -1.58938945]\n",
      " [-2.51998883 -0.08275251  2.60315768]\n",
      " [-1.16786101 -0.96668266  2.13468836]]\n",
      "724000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14661258609496583\n",
      "[[ 0.77562437  0.65101483 -1.42676885]\n",
      " [ 1.83671518 -0.24661928 -1.59043808]\n",
      " [-2.52116121 -0.08296558  2.60454312]\n",
      " [-1.16842231 -0.96742309  2.13599009]]\n",
      "725000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14651846931919407\n",
      "[[ 0.77604769  0.6513304  -1.42750774]\n",
      " [ 1.8376012  -0.24645771 -1.59148567]\n",
      " [-2.52233223 -0.0831783   2.60592686]\n",
      " [-1.168983   -0.96816272  2.1372904 ]]\n",
      "726000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14642456226373085\n",
      "[[ 0.77647055  0.6516454  -1.4282456 ]\n",
      " [ 1.83848619 -0.24629614 -1.59253223]\n",
      " [-2.52350191 -0.08339067  2.60730891]\n",
      " [-1.16954307 -0.96890155  2.1385893 ]]\n",
      "727000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14633086420206204\n",
      "[[ 0.77689294  0.65195984 -1.42898243]\n",
      " [ 1.83937014 -0.24613456 -1.59357777]\n",
      " [-2.52467024 -0.08360269  2.60868926]\n",
      " [-1.17010251 -0.96963958  2.13988678]]\n",
      "728000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1462373744110632\n",
      "[[ 0.77731487  0.65227371 -1.42971824]\n",
      " [ 1.84025307 -0.24597298 -1.59462227]\n",
      " [-2.52583723 -0.08381436  2.61006792]\n",
      " [-1.17066135 -0.97037682  2.14118285]]\n",
      "729000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14614409217097957\n",
      "[[ 0.77773634  0.65258703 -1.43045302]\n",
      " [ 1.84113496 -0.24581139 -1.59566575]\n",
      " [-2.52700288 -0.08402569  2.6114449 ]\n",
      " [-1.17121957 -0.97111326  2.14247752]]\n",
      "730000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14605101676540572\n",
      "[[ 0.77815734  0.65289978 -1.43118678]\n",
      " [ 1.84201582 -0.2456498  -1.5967082 ]\n",
      " [-2.52816719 -0.08423667  2.6128202 ]\n",
      " [-1.17177717 -0.97184892  2.14377078]]\n",
      "731000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14595814748126656\n",
      "[[ 0.77857789  0.65321197 -1.43191952]\n",
      " [ 1.84289566 -0.24548821 -1.59774963]\n",
      " [-2.52933018 -0.0844473   2.61419382]\n",
      " [-1.17233416 -0.97258379  2.14506264]]\n",
      "732000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14586548360879809\n",
      "[[ 0.77899798  0.6535236  -1.43265124]\n",
      " [ 1.84377447 -0.24532661 -1.59879004]\n",
      " [-2.53049183 -0.0846576   2.61556577]\n",
      " [-1.17289055 -0.97331787  2.1463531 ]]\n",
      "733000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14577302444152787\n",
      "[[ 0.77941761  0.65383468 -1.43338195]\n",
      " [ 1.84465227 -0.24516501 -1.59982944]\n",
      " [-2.53165216 -0.08486755  2.61693604]\n",
      " [-1.17344632 -0.97405116  2.14764217]]\n",
      "734000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1456807692762562\n",
      "[[ 0.77983679  0.65414521 -1.43411165]\n",
      " [ 1.84552905 -0.24500341 -1.60086781]\n",
      " [-2.53281117 -0.08507715  2.61830466]\n",
      " [-1.17400149 -0.97478367  2.14892985]]\n",
      "735000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14558871741303642\n",
      "[[ 0.78025551  0.65445518 -1.43484034]\n",
      " [ 1.84640481 -0.24484181 -1.60190518]\n",
      " [-2.53396886 -0.08528642  2.61967161]\n",
      " [-1.17455605 -0.9755154   2.15021614]]\n",
      "736000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14549686815515714\n",
      "[[ 0.78067377  0.65476459 -1.43556802]\n",
      " [ 1.84727956 -0.2446802  -1.60294153]\n",
      " [-2.53512523 -0.08549535  2.62103691]\n",
      " [-1.17511    -0.97624636  2.15150104]]\n",
      "737000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1454052208091227\n",
      "[[ 0.78109158  0.65507346 -1.4362947 ]\n",
      " [ 1.84815329 -0.2445186  -1.60397688]\n",
      " [-2.53628028 -0.08570393  2.62240055]\n",
      " [-1.17566335 -0.97697653  2.15278457]]\n",
      "738000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14531377468463466\n",
      "[[ 0.78150894  0.65538178 -1.43702038]\n",
      " [ 1.84902602 -0.24435699 -1.60501121]\n",
      " [-2.53743403 -0.08591218  2.62376255]\n",
      " [-1.1762161  -0.97770593  2.15406671]]\n",
      "739000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14522252909457392\n",
      "[[ 0.78192585  0.65568956 -1.43774506]\n",
      " [ 1.84989775 -0.24419538 -1.60604454]\n",
      " [-2.53858647 -0.08612009  2.6251229 ]\n",
      " [-1.17676825 -0.97843455  2.15534749]]\n",
      "740000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14513148335498138\n",
      "[[ 0.78234231  0.65599679 -1.43846875]\n",
      " [ 1.85076847 -0.24403378 -1.60707687]\n",
      " [-2.5397376  -0.08632767  2.6264816 ]\n",
      " [-1.1773198  -0.9791624   2.15662689]]\n",
      "741000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14504063678504073\n",
      "[[ 0.78275831  0.65630347 -1.43919144]\n",
      " [ 1.85163818 -0.24387217 -1.60810819]\n",
      " [-2.54088743 -0.0865349   2.62783867]\n",
      " [-1.17787075 -0.97988949  2.15790492]]\n",
      "742000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1449499887070604\n",
      "[[ 0.78317387  0.65660961 -1.43991314]\n",
      " [ 1.8525069  -0.24371056 -1.60913852]\n",
      " [-2.54203597 -0.08674181  2.62919411]\n",
      " [-1.1784211  -0.9806158   2.15918159]]\n",
      "743000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1448595384464542\n",
      "[[ 0.78358898  0.65691521 -1.44063385]\n",
      " [ 1.85337462 -0.24354896 -1.61016785]\n",
      " [-2.54318321 -0.08694838  2.63054792]\n",
      " [-1.17897086 -0.98134135  2.16045689]]\n",
      "744000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14476928533172523\n",
      "[[ 0.78400365  0.65722028 -1.44135358]\n",
      " [ 1.85424135 -0.24338735 -1.61119618]\n",
      " [-2.54432915 -0.08715461  2.6319001 ]\n",
      " [-1.17952002 -0.98206613  2.16173083]]\n",
      "745000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14467922869444702\n",
      "[[ 0.78441787  0.6575248  -1.44207232]\n",
      " [ 1.85510709 -0.24322575 -1.61222351]\n",
      " [-2.54547381 -0.08736051  2.63325066]\n",
      " [-1.18006859 -0.98279014  2.16300342]]\n",
      "746000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14458936786924634\n",
      "[[ 0.78483164  0.65782879 -1.44279008]\n",
      " [ 1.85597183 -0.24306415 -1.61324986]\n",
      " [-2.54661718 -0.08756609  2.6345996 ]\n",
      " [-1.18061657 -0.9835134   2.16427466]]\n",
      "747000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1444997021937859\n",
      "[[ 0.78524497  0.65813224 -1.44350687]\n",
      " [ 1.85683559 -0.24290255 -1.61427522]\n",
      " [-2.54775926 -0.08777133  2.63594692]\n",
      " [-1.18116396 -0.9842359   2.16554454]]\n",
      "748000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14441023100874686\n",
      "[[ 0.78565786  0.65843516 -1.44422268]\n",
      " [ 1.85769836 -0.24274096 -1.61529958]\n",
      " [-2.54890006 -0.08797624  2.63729264]\n",
      " [-1.18171076 -0.98495763  2.16681308]]\n",
      "749000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14432095365781142\n",
      "[[ 0.78607031  0.65873755 -1.44493751]\n",
      " [ 1.85856015 -0.24257936 -1.61632297]\n",
      " [-2.55003959 -0.08818082  2.63863674]\n",
      " [-1.18225698 -0.98567862  2.16808028]]\n",
      "750000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1442318694876458\n",
      "[[ 0.78648231  0.65903941 -1.44565137]\n",
      " [ 1.85942096 -0.24241778 -1.61734536]\n",
      " [-2.55117784 -0.08838507  2.63997925]\n",
      " [-1.1828026  -0.98639884  2.16934613]]\n",
      "751000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14414297784788352\n",
      "[[ 0.78689388  0.65934074 -1.44636427]\n",
      " [ 1.86028079 -0.24225619 -1.61836678]\n",
      " [-2.55231482 -0.088589    2.64132015]\n",
      " [-1.18334765 -0.98711832  2.17061065]]\n",
      "752000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1440542780911079\n",
      "[[ 0.78730501  0.65964154 -1.4470762 ]\n",
      " [ 1.86113964 -0.24209461 -1.61938721]\n",
      " [-2.55345053 -0.0887926   2.64265946]\n",
      " [-1.1838921  -0.98783704  2.17187383]]\n",
      "753000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14396576957283597\n",
      "[[ 0.7877157   0.65994181 -1.44778716]\n",
      " [ 1.86199752 -0.24193303 -1.62040667]\n",
      " [-2.55458497 -0.08899587  2.64399718]\n",
      " [-1.18443598 -0.98855502  2.17313568]]\n",
      "754000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1438774516515017\n",
      "[[ 0.78812595  0.66024156 -1.44849717]\n",
      " [ 1.86285442 -0.24177146 -1.62142515]\n",
      " [-2.55571815 -0.08919882  2.64533331]\n",
      " [-1.18497928 -0.98927224  2.1743962 ]]\n",
      "755000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14378932368843889\n",
      "[[ 0.78853577  0.66054079 -1.44920621]\n",
      " [ 1.86371036 -0.24160989 -1.62244265]\n",
      " [-2.55685007 -0.08940145  2.64666785]\n",
      " [-1.18552199 -0.98998872  2.1756554 ]]\n",
      "756000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14370138504786575\n",
      "[[ 0.78894515  0.6608395  -1.4499143 ]\n",
      " [ 1.86456533 -0.24144833 -1.62345919]\n",
      " [-2.55798073 -0.08960375  2.64800081]\n",
      " [-1.18606413 -0.99070446  2.17691327]]\n",
      "757000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1436136350968674\n",
      "[[ 0.7893541   0.66113768 -1.45062143]\n",
      " [ 1.86541933 -0.24128677 -1.62447475]\n",
      " [-2.55911013 -0.08980573  2.6493322 ]\n",
      " [-1.18660569 -0.99141945  2.17816982]]\n",
      "758000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14352607320538047\n",
      "[[ 0.78976261  0.66143535 -1.45132761]\n",
      " [ 1.86627238 -0.24112522 -1.62548934]\n",
      " [-2.56023829 -0.09000739  2.65066201]\n",
      " [-1.18714667 -0.9921337   2.17942506]]\n",
      "759000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14343869874617696\n",
      "[[ 0.79017069  0.6617325  -1.45203285]\n",
      " [ 1.86712446 -0.24096367 -1.62650296]\n",
      " [-2.56136519 -0.09020873  2.65199025]\n",
      " [-1.18768708 -0.99284721  2.18067898]]\n",
      "760000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14335151109484812\n",
      "[[ 0.79057835  0.66202913 -1.45273713]\n",
      " [ 1.86797558 -0.24080213 -1.62751562]\n",
      " [-2.56249085 -0.09040974  2.65331692]\n",
      " [-1.18822692 -0.99355999  2.1819316 ]]\n",
      "761000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1432645096297884\n",
      "[[ 0.79098557  0.66232525 -1.45344047]\n",
      " [ 1.86882574 -0.2406406  -1.62852732]\n",
      " [-2.56361526 -0.09061044  2.65464204]\n",
      " [-1.18876619 -0.99427203  2.1831829 ]]\n",
      "762000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1431776937321798\n",
      "[[ 0.79139236  0.66262085 -1.45414287]\n",
      " [ 1.86967495 -0.24047908 -1.62953805]\n",
      " [-2.56473843 -0.09081082  2.65596559]\n",
      " [-1.18930488 -0.99498333  2.1844329 ]]\n",
      "763000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14309106278597633\n",
      "[[ 0.79179872  0.66291595 -1.45484433]\n",
      " [ 1.87052321 -0.24031756 -1.63054783]\n",
      " [-2.56586037 -0.09101089  2.65728758]\n",
      " [-1.189843   -0.99569391  2.18568159]]\n",
      "764000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14300461617788837\n",
      "[[ 0.79220466  0.66321053 -1.45554485]\n",
      " [ 1.87137052 -0.24015605 -1.63155665]\n",
      " [-2.56698106 -0.09121063  2.65860803]\n",
      " [-1.19038056 -0.99640375  2.18692899]]\n",
      "765000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14291835329736738\n",
      "[[ 0.79261017  0.66350461 -1.45624443]\n",
      " [ 1.87221688 -0.23999455 -1.63256451]\n",
      " [-2.56810053 -0.09141006  2.65992692]\n",
      " [-1.19091755 -0.99711286  2.18817509]]\n",
      "766000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1428322735365902\n",
      "[[ 0.79301525  0.66379817 -1.45694308]\n",
      " [ 1.87306229 -0.23983306 -1.63357141]\n",
      " [-2.56921876 -0.09160918  2.66124428]\n",
      " [-1.19145397 -0.99782124  2.1894199 ]]\n",
      "767000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14274637629044412\n",
      "[[ 0.79341991  0.66409123 -1.4576408 ]\n",
      " [ 1.87390676 -0.23967157 -1.63457737]\n",
      " [-2.57033577 -0.09180798  2.66256008]\n",
      " [-1.19198983 -0.9985289   2.19066342]]\n",
      "768000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14266066095651136\n",
      "[[ 0.79382415  0.66438379 -1.45833759]\n",
      " [ 1.87475029 -0.2395101  -1.63558237]\n",
      " [-2.57145156 -0.09200646  2.66387435]\n",
      " [-1.19252513 -0.99923583  2.19190565]]\n",
      "769000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14257512693505467\n",
      "[[ 0.79422796  0.66467584 -1.45903346]\n",
      " [ 1.87559287 -0.23934863 -1.63658643]\n",
      " [-2.57256612 -0.09220464  2.66518709]\n",
      " [-1.19305986 -0.99994204  2.19314659]]\n",
      "770000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14248977362900142\n",
      "[[ 0.79463135  0.66496739 -1.4597284 ]\n",
      " [ 1.87643453 -0.23918717 -1.63758953]\n",
      " [-2.57367946 -0.0924025   2.6664983 ]\n",
      " [-1.19359403 -1.00064753  2.19438625]]\n",
      "771000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14240460044393052\n",
      "[[ 0.79503432  0.66525844 -1.46042242]\n",
      " [ 1.87727524 -0.23902572 -1.6385917 ]\n",
      " [-2.57479159 -0.09260005  2.66780797]\n",
      " [-1.19412765 -1.0013523   2.19562464]]\n",
      "772000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14231960678805508\n",
      "[[ 0.79543687  0.66554899 -1.46111552]\n",
      " [ 1.87811502 -0.23886429 -1.63959292]\n",
      " [-2.5759025  -0.09279729  2.66911613]\n",
      " [-1.1946607  -1.00205636  2.19686174]]\n",
      "773000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14223479207220993\n",
      "[[ 0.79583901  0.66583904 -1.4618077 ]\n",
      " [ 1.87895388 -0.23870286 -1.64059319]\n",
      " [-2.5770122  -0.09299422  2.67042276]\n",
      " [-1.1951932  -1.00275969  2.19809758]]\n",
      "774000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14215015570983633\n",
      "[[ 0.79624072  0.66612859 -1.46249897]\n",
      " [ 1.8797918  -0.23854145 -1.64159253]\n",
      " [-2.5781207  -0.09319085  2.67172788]\n",
      " [-1.19572514 -1.00346231  2.19933214]]\n",
      "775000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14206569711696748\n",
      "[[ 0.79664201  0.66641765 -1.46318932]\n",
      " [ 1.88062879 -0.23838004 -1.64259093]\n",
      " [-2.57922798 -0.09338716  2.67303148]\n",
      " [-1.19625653 -1.00416422  2.20056544]]\n",
      "776000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1419814157122141\n",
      "[[ 0.79704289  0.66670622 -1.46387876]\n",
      " [ 1.88146486 -0.23821865 -1.6435884 ]\n",
      " [-2.58033407 -0.09358317  2.67433357]\n",
      " [-1.19678736 -1.00486542  2.20179747]]\n",
      "777000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14189731091675042\n",
      "[[ 0.79744335  0.66699429 -1.4645673 ]\n",
      " [ 1.88230001 -0.23805726 -1.64458493]\n",
      " [-2.58143895 -0.09377887  2.67563416]\n",
      " [-1.19731764 -1.0055659   2.20302823]]\n",
      "778000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1418133821542999\n",
      "[[ 0.7978434   0.66728187 -1.46525493]\n",
      " [ 1.88313424 -0.23789589 -1.64558052]\n",
      " [-2.58254264 -0.09397426  2.67693324]\n",
      " [-1.19784737 -1.00626568  2.20425774]]\n",
      "779000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1417296288511209\n",
      "[[ 0.79824304  0.66756896 -1.46594165]\n",
      " [ 1.88396754 -0.23773454 -1.64657519]\n",
      " [-2.58364513 -0.09416935  2.67823082]\n",
      " [-1.19837656 -1.00696475  2.20548599]]\n",
      "780000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1416460504359928\n",
      "[[ 0.79864226  0.66785556 -1.46662748]\n",
      " [ 1.88479994 -0.23757319 -1.64756893]\n",
      " [-2.58474643 -0.09436414  2.6795269 ]\n",
      " [-1.19890519 -1.00766311  2.20671299]]\n",
      "781000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14156264634020274\n",
      "[[ 0.79904107  0.66814168 -1.4673124 ]\n",
      " [ 1.88563141 -0.23741186 -1.64856173]\n",
      " [-2.58584654 -0.09455862  2.68082149]\n",
      " [-1.19943327 -1.00836078  2.20793873]]\n",
      "782000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14147941599753117\n",
      "[[ 0.79943947  0.66842731 -1.46799643]\n",
      " [ 1.88646198 -0.23725054 -1.64955362]\n",
      " [-2.58694546 -0.0947528   2.6821146 ]\n",
      " [-1.19996081 -1.00905774  2.20916323]]\n",
      "783000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14139635884423818\n",
      "[[ 0.79983745  0.66871245 -1.46867956]\n",
      " [ 1.88729163 -0.23708923 -1.65054458]\n",
      " [-2.5880432  -0.09494668  2.68340621]\n",
      " [-1.2004878  -1.00975399  2.21038648]]\n",
      "784000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14131347431905028\n",
      "[[ 0.80023503  0.66899711 -1.4693618 ]\n",
      " [ 1.88812037 -0.23692794 -1.65153462]\n",
      " [-2.58913975 -0.09514025  2.68469634]\n",
      " [-1.20101425 -1.01044955  2.21160849]]\n",
      "785000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14123076186314643\n",
      "[[ 0.8006322   0.66928129 -1.47004314]\n",
      " [ 1.88894821 -0.23676666 -1.65252373]\n",
      " [-2.59023513 -0.09533353  2.68598499]\n",
      " [-1.20154015 -1.01114441  2.21282925]]\n",
      "786000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14114822092014478\n",
      "[[ 0.80102896  0.66956498 -1.4707236 ]\n",
      " [ 1.88977514 -0.23660539 -1.65351193]\n",
      " [-2.59132933 -0.09552651  2.68727217]\n",
      " [-1.20206552 -1.01183858  2.21404878]]\n",
      "787000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14106585093608962\n",
      "[[ 0.80142532  0.6698482  -1.47140317]\n",
      " [ 1.89060117 -0.23644414 -1.65449921]\n",
      " [-2.59242235 -0.09571918  2.68855787]\n",
      " [-1.20259034 -1.01253205  2.21526708]]\n",
      "788000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14098365135943755\n",
      "[[ 0.80182126  0.67013094 -1.47208186]\n",
      " [ 1.8914263  -0.2362829  -1.65548558]\n",
      " [-2.59351421 -0.09591156  2.6898421 ]\n",
      " [-1.20311463 -1.01322483  2.21648414]]\n",
      "789000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14090162164104467\n",
      "[[ 0.80221681  0.6704132  -1.47275966]\n",
      " [ 1.89225053 -0.23612168 -1.65647103]\n",
      " [-2.59460489 -0.09610364  2.69112487]\n",
      " [-1.20363837 -1.01391691  2.21769997]]\n",
      "790000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14081976123415352\n",
      "[[ 0.80261195  0.67069499 -1.47343659]\n",
      " [ 1.89307387 -0.23596048 -1.65745557]\n",
      " [-2.59569441 -0.09629543  2.69240617]\n",
      " [-1.20416158 -1.01460831  2.21891458]]\n",
      "791000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14073806959437993\n",
      "[[ 0.80300668  0.6709763  -1.47411263]\n",
      " [ 1.8938963  -0.23579928 -1.6584392 ]\n",
      " [-2.59678276 -0.09648691  2.69368601]\n",
      " [-1.20468425 -1.01529902  2.22012796]]\n",
      "792000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14065654617970028\n",
      "[[ 0.80340101  0.67125713 -1.4747878 ]\n",
      " [ 1.89471785 -0.23563811 -1.65942192]\n",
      " [-2.59786995 -0.09667811  2.69496439]\n",
      " [-1.20520639 -1.01598904  2.22134012]]\n",
      "793000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14057519045043862\n",
      "[[ 0.80379495  0.6715375  -1.4754621 ]\n",
      " [ 1.89553851 -0.23547695 -1.66040374]\n",
      " [-2.59895598 -0.09686901  2.69624132]\n",
      " [-1.205728   -1.01667838  2.22255106]]\n",
      "794000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1404940018692536\n",
      "[[ 0.80418847  0.67181739 -1.47613552]\n",
      " [ 1.89635827 -0.2353158  -1.66138465]\n",
      " [-2.60004086 -0.09705961  2.6975168 ]\n",
      " [-1.20624907 -1.01736703  2.22376078]]\n",
      "795000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14041297990112603\n",
      "[[ 0.8045816   0.67209682 -1.47680808]\n",
      " [ 1.89717715 -0.23515468 -1.66236465]\n",
      " [-2.60112458 -0.09724992  2.69879084]\n",
      " [-1.20676961 -1.01805499  2.22496929]]\n",
      "796000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14033212401334672\n",
      "[[ 0.80497434  0.67237577 -1.47747976]\n",
      " [ 1.89799515 -0.23499357 -1.66334376]\n",
      " [-2.60220715 -0.09743994  2.70006342]\n",
      " [-1.20728962 -1.01874228  2.22617659]]\n",
      "797000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14025143367550347\n",
      "[[ 0.80536667  0.67265426 -1.47815058]\n",
      " [ 1.89881226 -0.23483247 -1.66432196]\n",
      " [-2.60328857 -0.09762967  2.70133457]\n",
      " [-1.2078091  -1.01942889  2.22738268]]\n",
      "798000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14017090835946877\n",
      "[[ 0.8057586   0.67293228 -1.47882054]\n",
      " [ 1.89962849 -0.2346714  -1.66529927]\n",
      " [-2.60436884 -0.0978191   2.70260428]\n",
      " [-1.20832805 -1.02011482  2.22858756]]\n",
      "799000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.14009054753938727\n",
      "[[ 0.80615014  0.67320984 -1.47948963]\n",
      " [ 1.90044384 -0.23451034 -1.66627568]\n",
      " [-2.60544797 -0.09800825  2.70387256]\n",
      " [-1.20884648 -1.02080007  2.22979124]]\n",
      "800000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1400103506916639\n",
      "[[ 0.80654128  0.67348694 -1.48015787]\n",
      " [ 1.90125831 -0.2343493  -1.66725119]\n",
      " [-2.60652596 -0.0981971   2.7051394 ]\n",
      " [-1.20936438 -1.02148465  2.23099372]]\n",
      "801000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13993031729495192\n",
      "[[ 0.80693203  0.67376357 -1.48082525]\n",
      " [ 1.90207191 -0.23418827 -1.66822582]\n",
      " [-2.60760281 -0.09838567  2.70640482]\n",
      " [-1.20988175 -1.02216856  2.232195  ]]\n",
      "802000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13985044683013967\n",
      "[[ 0.80732238  0.67403974 -1.48149177]\n",
      " [ 1.90288463 -0.23402727 -1.66919954]\n",
      " [-2.60867852 -0.09857395  2.70766881]\n",
      " [-1.21039861 -1.02285179  2.23339508]]\n",
      "803000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1397707387803398\n",
      "[[ 0.80771234  0.67431545 -1.48215744]\n",
      " [ 1.90369648 -0.23386628 -1.67017238]\n",
      " [-2.6097531  -0.09876194  2.70893138]\n",
      " [-1.21091494 -1.02353435  2.23459397]]\n",
      "804000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13969119263087676\n",
      "[[ 0.8081019   0.6745907  -1.48282226]\n",
      " [ 1.90450746 -0.23370531 -1.67114433]\n",
      " [-2.61082655 -0.09894965  2.71019252]\n",
      " [-1.21143074 -1.02421624  2.23579167]]\n",
      "805000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13961180786927463\n",
      "[[ 0.80849108  0.6748655  -1.48348623]\n",
      " [ 1.90531758 -0.23354436 -1.6721154 ]\n",
      " [-2.61189886 -0.09913706  2.71145226]\n",
      " [-1.21194603 -1.02489746  2.23698818]]\n",
      "806000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13953258398524634\n",
      "[[ 0.80887986  0.67513984 -1.48414935]\n",
      " [ 1.90612683 -0.23338343 -1.67308558]\n",
      " [-2.61297005 -0.0993242   2.71271058]\n",
      " [-1.2124608  -1.02557802  2.23818351]]\n",
      "807000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1394535204706809\n",
      "[[ 0.80926825  0.67541372 -1.48481162]\n",
      " [ 1.90693521 -0.23322252 -1.67405487]\n",
      " [-2.61404011 -0.09951104  2.71396749]\n",
      " [-1.21297505 -1.02625791  2.23937765]]\n",
      "808000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.139374616819632\n",
      "[[ 0.80965625  0.67568715 -1.48547306]\n",
      " [ 1.90774273 -0.23306163 -1.67502328]\n",
      " [-2.61510906 -0.09969761  2.715223  ]\n",
      " [-1.21348879 -1.02693714  2.24057061]]\n",
      "809000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13929587252830727\n",
      "[[ 0.81004387  0.67596012 -1.48613365]\n",
      " [ 1.90854939 -0.23290076 -1.67599082]\n",
      " [-2.61617688 -0.09988389  2.7164771 ]\n",
      " [-1.214002   -1.02761571  2.2417624 ]]\n",
      "810000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13921728709505554\n",
      "[[ 0.81043109  0.67623265 -1.4867934 ]\n",
      " [ 1.90935519 -0.2327399  -1.67695747]\n",
      " [-2.61724358 -0.10006989  2.7177298 ]\n",
      " [-1.21451471 -1.02829361  2.24295301]]\n",
      "811000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1391388600203562\n",
      "[[ 0.81081793  0.67650472 -1.48745231]\n",
      " [ 1.91016014 -0.23257907 -1.67792325]\n",
      " [-2.61830917 -0.1002556   2.71898111]\n",
      " [-1.2150269  -1.02897086  2.24414244]]\n",
      "812000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13906059080680808\n",
      "[[ 0.81120439  0.67677635 -1.48811039]\n",
      " [ 1.91096423 -0.23241826 -1.67888815]\n",
      " [-2.61937365 -0.10044104  2.72023102]\n",
      " [-1.21553857 -1.02964745  2.24533071]]\n",
      "813000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13898247895911686\n",
      "[[ 0.81159045  0.67704753 -1.48876763]\n",
      " [ 1.91176747 -0.23225747 -1.67985217]\n",
      " [-2.62043701 -0.10062619  2.72147954]\n",
      " [-1.21604974 -1.03032338  2.2465178 ]]\n",
      "814000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1389045239840857\n",
      "[[ 0.81197614  0.67731826 -1.48942405]\n",
      " [ 1.91256985 -0.2320967  -1.68081533]\n",
      " [-2.62149927 -0.10081107  2.72272667]\n",
      " [-1.21656039 -1.03099865  2.24770373]]\n",
      "815000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13882672539060248\n",
      "[[ 0.81236143  0.67758854 -1.49007963]\n",
      " [ 1.91337139 -0.23193595 -1.68177761]\n",
      " [-2.62256042 -0.10099566  2.72397242]\n",
      " [-1.21707054 -1.03167327  2.2488885 ]]\n",
      "816000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13874908268963002\n",
      "[[ 0.81274635  0.67785838 -1.49073439]\n",
      " [ 1.91417208 -0.23177523 -1.68273903]\n",
      " [-2.62362047 -0.10117998  2.72521678]\n",
      " [-1.21758018 -1.03234724  2.25007211]]\n",
      "817000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1386715953941943\n",
      "[[ 0.81313088  0.67812778 -1.49138832]\n",
      " [ 1.91497192 -0.23161452 -1.68369957]\n",
      " [-2.62467941 -0.10136402  2.72645977]\n",
      " [-1.21808931 -1.03302056  2.25125455]]\n",
      "818000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13859426301937366\n",
      "[[ 0.81351503  0.67839673 -1.49204142]\n",
      " [ 1.91577092 -0.23145384 -1.68465926]\n",
      " [-2.62573726 -0.10154778  2.72770137]\n",
      " [-1.21859793 -1.03369323  2.25243584]]\n",
      "819000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13851708508228824\n",
      "[[ 0.8138988   0.67866525 -1.49269371]\n",
      " [ 1.91656907 -0.23129318 -1.68561807]\n",
      " [-2.62679401 -0.10173126  2.72894161]\n",
      " [-1.21910605 -1.03436525  2.25361598]]\n",
      "820000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13844006110208895\n",
      "[[ 0.8142822   0.67893332 -1.49334517]\n",
      " [ 1.91736639 -0.23113254 -1.68657603]\n",
      " [-2.62784967 -0.10191447  2.73018048]\n",
      " [-1.21961366 -1.03503662  2.25479497]]\n",
      "821000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13836319059994692\n",
      "[[ 0.81466521  0.67920096 -1.49399582]\n",
      " [ 1.91816286 -0.23097193 -1.68753312]\n",
      " [-2.62890424 -0.10209741  2.73141797]\n",
      " [-1.22012077 -1.03570735  2.25597281]]\n",
      "822000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13828647309904246\n",
      "[[ 0.81504784  0.67946815 -1.49464565]\n",
      " [ 1.9189585  -0.23081133 -1.68848935]\n",
      " [-2.62995771 -0.10228006  2.73265411]\n",
      " [-1.22062738 -1.03637744  2.2571495 ]]\n",
      "823000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1382099081245553\n",
      "[[ 0.81543009  0.67973491 -1.49529466]\n",
      " [ 1.91975331 -0.23065076 -1.68944472]\n",
      " [-2.6310101  -0.10246245  2.73388888]\n",
      " [-1.22113348 -1.03704688  2.25832505]]\n",
      "824000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13813349520365303\n",
      "[[ 0.81581197  0.68000124 -1.49594286]\n",
      " [ 1.92054728 -0.23049022 -1.69039924]\n",
      " [-2.6320614  -0.10264456  2.7351223 ]\n",
      " [-1.22163909 -1.03771567  2.25949945]]\n",
      "825000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13805723386548166\n",
      "[[ 0.81619347  0.68026713 -1.49659026]\n",
      " [ 1.92134042 -0.23032969 -1.6913529 ]\n",
      " [-2.63311162 -0.1028264   2.73635436]\n",
      " [-1.2221442  -1.03838383  2.26067272]]\n",
      "826000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13798112364115425\n",
      "[[ 0.8165746   0.68053258 -1.49723684]\n",
      " [ 1.92213272 -0.23016919 -1.69230571]\n",
      " [-2.63416076 -0.10300796  2.73758506]\n",
      " [-1.22264881 -1.03905135  2.26184485]]\n",
      "827000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13790516406374181\n",
      "[[ 0.81695535  0.68079761 -1.49788261]\n",
      " [ 1.9229242  -0.23000872 -1.69325767]\n",
      " [-2.63520883 -0.10318926  2.73881442]\n",
      " [-1.22315292 -1.03971823  2.26301584]]\n",
      "828000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13782935466826168\n",
      "[[ 0.81733573  0.6810622  -1.49852759]\n",
      " [ 1.92371486 -0.22984826 -1.69420877]\n",
      " [-2.63625581 -0.10337028  2.74004243]\n",
      " [-1.22365654 -1.04038448  2.26418571]]\n",
      "829000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13775369499166842\n",
      "[[ 0.81771574  0.68132636 -1.49917175]\n",
      " [ 1.92450469 -0.22968784 -1.69515903]\n",
      " [-2.63730172 -0.10355104  2.7412691 ]\n",
      " [-1.22415966 -1.04105009  2.26535444]]\n",
      "830000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13767818457284361\n",
      "[[ 0.81809537  0.6815901  -1.49981512]\n",
      " [ 1.92529369 -0.22952743 -1.69610844]\n",
      " [-2.63834656 -0.10373152  2.74249442]\n",
      " [-1.22466229 -1.04171507  2.26652204]]\n",
      "831000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13760282295258472\n",
      "[[ 0.81847463  0.68185341 -1.50045769]\n",
      " [ 1.92608188 -0.22936706 -1.697057  ]\n",
      " [-2.63939033 -0.10391174  2.74371841]\n",
      " [-1.22516442 -1.04237941  2.26768853]]\n",
      "832000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13752760967359637\n",
      "[[ 0.81885352  0.68211629 -1.50109946]\n",
      " [ 1.92686924 -0.2292067  -1.69800472]\n",
      " [-2.64043304 -0.10409169  2.74494106]\n",
      " [-1.22566607 -1.04304313  2.26885388]]\n",
      "833000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13745254428047993\n",
      "[[ 0.81923204  0.68237874 -1.50174043]\n",
      " [ 1.92765579 -0.22904637 -1.6989516 ]\n",
      " [-2.64147468 -0.10427137  2.74616238]\n",
      " [-1.22616722 -1.04370621  2.27001812]]\n",
      "834000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13737762631972336\n",
      "[[ 0.81961019  0.68264077 -1.50238061]\n",
      " [ 1.92844152 -0.22888607 -1.69989763]\n",
      " [-2.64251525 -0.10445078  2.74738237]\n",
      " [-1.22666788 -1.04436867  2.27118124]]\n",
      "835000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13730285533969197\n",
      "[[ 0.81998797  0.68290238 -1.50302   ]\n",
      " [ 1.92922644 -0.22872579 -1.70084283]\n",
      " [-2.64355477 -0.10462993  2.74860103]\n",
      " [-1.22716806 -1.0450305   2.27234324]]\n",
      "836000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13722823089061825\n",
      "[[ 0.82036538  0.68316356 -1.5036586 ]\n",
      " [ 1.93001055 -0.22856554 -1.70178718]\n",
      " [-2.64459323 -0.10480881  2.74981837]\n",
      " [-1.22766774 -1.0456917   2.27350413]]\n",
      "837000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1371537525245924\n",
      "[[ 0.82074243  0.68342432 -1.50429641]\n",
      " [ 1.93079384 -0.22840532 -1.7027307 ]\n",
      " [-2.64563063 -0.10498743  2.75103439]\n",
      " [-1.22816694 -1.04635228  2.27466391]]\n",
      "838000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13707941979555238\n",
      "[[ 0.82111911  0.68368466 -1.50493343]\n",
      " [ 1.93157632 -0.22824512 -1.70367339]\n",
      " [-2.64666697 -0.10516578  2.75224909]\n",
      " [-1.22866565 -1.04701224  2.27582258]]\n",
      "839000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13700523225927527\n",
      "[[ 0.82149542  0.68394459 -1.50556967]\n",
      " [ 1.932358   -0.22808494 -1.70461524]\n",
      " [-2.64770227 -0.10534387  2.75346247]\n",
      " [-1.22916388 -1.04767157  2.27698014]]\n",
      "840000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13693118947336597\n",
      "[[ 0.82187137  0.68420409 -1.50620512]\n",
      " [ 1.93313887 -0.2279248  -1.70555625]\n",
      " [-2.64873652 -0.10552169  2.75467454]\n",
      " [-1.22966162 -1.04833029  2.2781366 ]]\n",
      "841000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1368572909972499\n",
      "[[ 0.82224696  0.68446318 -1.50683979]\n",
      " [ 1.93391893 -0.22776468 -1.70649644]\n",
      " [-2.64976971 -0.10569925  2.7558853 ]\n",
      " [-1.23015888 -1.04898838  2.27929195]]\n",
      "842000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13678353639216198\n",
      "[[ 0.82262218  0.68472185 -1.50747369]\n",
      " [ 1.9346982  -0.22760458 -1.7074358 ]\n",
      " [-2.65080187 -0.10587655  2.75709476]\n",
      " [-1.23065566 -1.04964586  2.28044621]]\n",
      "843000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13670992522113806\n",
      "[[ 0.82299704  0.68498011 -1.5081068 ]\n",
      " [ 1.93547666 -0.22744452 -1.70837433]\n",
      " [-2.65183298 -0.10605359  2.75830291]\n",
      " [-1.23115196 -1.05030272  2.28159936]]\n",
      "844000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1366364570490057\n",
      "[[ 0.82337153  0.68523795 -1.50873914]\n",
      " [ 1.93625432 -0.22728448 -1.70931203]\n",
      " [-2.65286305 -0.10623037  2.75950975]\n",
      " [-1.23164778 -1.05095896  2.28275142]]\n",
      "845000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13656313144237434\n",
      "[[ 0.82374567  0.68549538 -1.50937071]\n",
      " [ 1.93703119 -0.22712447 -1.7102489 ]\n",
      " [-2.65389208 -0.10640689  2.7607153 ]\n",
      " [-1.23214312 -1.05161459  2.28390239]]\n",
      "846000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.136489947969627\n",
      "[[ 0.82411944  0.6857524  -1.5100015 ]\n",
      " [ 1.93780726 -0.22696448 -1.71118496]\n",
      " [-2.65492007 -0.10658315  2.76191955]\n",
      " [-1.23263798 -1.05226961  2.28505227]]\n",
      "847000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1364169062009102\n",
      "[[ 0.82449286  0.68600901 -1.51063152]\n",
      " [ 1.93858253 -0.22680453 -1.71212019]\n",
      " [-2.65594703 -0.10675915  2.76312251]\n",
      " [-1.23313236 -1.05292401  2.28620106]]\n",
      "848000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1363440057081258\n",
      "[[ 0.82486591  0.68626521 -1.51126077]\n",
      " [ 1.93935701 -0.2266446  -1.7130546 ]\n",
      " [-2.65697295 -0.10693489  2.76432418]\n",
      " [-1.23362626 -1.05357781  2.28734876]]\n",
      "849000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13627124606492141\n",
      "[[ 0.82523861  0.686521   -1.51188926]\n",
      " [ 1.94013071 -0.2264847  -1.71398819]\n",
      " [-2.65799785 -0.10711038  2.76552456]\n",
      " [-1.2341197  -1.05423099  2.28849538]]\n",
      "850000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13619862684668216\n",
      "[[ 0.82561095  0.68677638 -1.51251698]\n",
      " [ 1.94090361 -0.22632483 -1.71492096]\n",
      " [-2.65902172 -0.1072856   2.76672365]\n",
      " [-1.23461265 -1.05488357  2.28964091]]\n",
      "851000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13612614763052086\n",
      "[[ 0.82598293  0.68703135 -1.51314393]\n",
      " [ 1.94167572 -0.22616499 -1.71585292]\n",
      " [-2.66004456 -0.10746057  2.76792147]\n",
      " [-1.23510514 -1.05553554  2.29078537]]\n",
      "852000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1360538079952699\n",
      "[[ 0.82635455  0.68728592 -1.51377013]\n",
      " [ 1.94244705 -0.22600517 -1.71678406]\n",
      " [-2.66106638 -0.10763529  2.769118  ]\n",
      " [-1.23559715 -1.05618691  2.29192874]]\n",
      "853000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13598160752147212\n",
      "[[ 0.82672582  0.68754008 -1.51439556]\n",
      " [ 1.94321759 -0.22584539 -1.71771438]\n",
      " [-2.66208717 -0.10780975  2.77031325]\n",
      " [-1.23608869 -1.05683767  2.29307104]]\n",
      "854000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13590954579137218\n",
      "[[ 0.82709674  0.68779384 -1.51502023]\n",
      " [ 1.94398735 -0.22568563 -1.7186439 ]\n",
      " [-2.66310695 -0.10798395  2.77150723]\n",
      " [-1.23657976 -1.05748783  2.29421227]]\n",
      "855000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1358376223889081\n",
      "[[ 0.8274673   0.6880472  -1.51564415]\n",
      " [ 1.94475633 -0.22552591 -1.7195726 ]\n",
      " [-2.6641257  -0.1081579   2.77269994]\n",
      " [-1.23707036 -1.05813739  2.29535243]]\n",
      "856000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13576583689970265\n",
      "[[ 0.8278375   0.68830016 -1.51626731]\n",
      " [ 1.94552453 -0.22536621 -1.7205005 ]\n",
      " [-2.66514345 -0.1083316   2.77389138]\n",
      " [-1.23756049 -1.05878634  2.29649151]]\n",
      "857000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13569418891105417\n",
      "[[ 0.82820736  0.68855271 -1.51688972]\n",
      " [ 1.94629195 -0.22520654 -1.72142758]\n",
      " [-2.66616017 -0.10850504  2.77508155]\n",
      " [-1.23805015 -1.0594347   2.29762953]]\n",
      "858000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13562267801192873\n",
      "[[ 0.82857686  0.68880487 -1.51751138]\n",
      " [ 1.94705859 -0.22504691 -1.72235387]\n",
      " [-2.66717589 -0.10867823  2.77627046]\n",
      " [-1.23853935 -1.06008246  2.29876649]]\n",
      "859000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13555130379295152\n",
      "[[ 0.82894601  0.68905662 -1.51813228]\n",
      " [ 1.94782446 -0.2248873  -1.72327934]\n",
      " [-2.6681906  -0.10885117  2.7774581 ]\n",
      " [-1.23902808 -1.06072962  2.29990238]]\n",
      "860000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13548006584639827\n",
      "[[ 0.8293148   0.68930798 -1.51875244]\n",
      " [ 1.94858955 -0.22472772 -1.72420401]\n",
      " [-2.66920429 -0.10902386  2.77864449]\n",
      " [-1.23951634 -1.06137618  2.30103721]]\n",
      "861000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.135408963766187\n",
      "[[ 0.82968325  0.68955895 -1.51937185]\n",
      " [ 1.94935388 -0.22456818 -1.72512788]\n",
      " [-2.67021699 -0.1091963   2.77982962]\n",
      " [-1.24000414 -1.06202215  2.30217098]]\n",
      "862000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13533799714786998\n",
      "[[ 0.83005135  0.68980951 -1.51999052]\n",
      " [ 1.95011743 -0.22440866 -1.72605095]\n",
      " [-2.67122868 -0.10936849  2.7810135 ]\n",
      " [-1.24049148 -1.06266753  2.3033037 ]]\n",
      "863000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13526716558862484\n",
      "[[ 0.8304191   0.69005968 -1.52060844]\n",
      " [ 1.95088021 -0.22424918 -1.72697322]\n",
      " [-2.67223936 -0.10954042  2.78219612]\n",
      " [-1.24097836 -1.06331232  2.30443536]]\n",
      "864000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13519646868724705\n",
      "[[ 0.8307865   0.69030946 -1.52122562]\n",
      " [ 1.95164223 -0.22408972 -1.72789469]\n",
      " [-2.67324905 -0.10971211  2.7833775 ]\n",
      " [-1.24146477 -1.06395651  2.30556597]]\n",
      "865000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1351259060441415\n",
      "[[ 0.83115356  0.69055885 -1.52184206]\n",
      " [ 1.95240348 -0.2239303  -1.72881536]\n",
      " [-2.67425774 -0.10988356  2.78455763]\n",
      " [-1.24195073 -1.06460012  2.30669553]]\n",
      "866000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1350554772613142\n",
      "[[ 0.83152026  0.69080784 -1.52245776]\n",
      " [ 1.95316397 -0.22377091 -1.72973524]\n",
      " [-2.67526544 -0.11005475  2.78573652]\n",
      " [-1.24243622 -1.06524313  2.30782404]]\n",
      "867000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1349851819423643\n",
      "[[ 0.83188662  0.69105644 -1.52307272]\n",
      " [ 1.95392369 -0.22361155 -1.73065432]\n",
      " [-2.67627214 -0.11022569  2.78691417]\n",
      " [-1.24292126 -1.06588556  2.3089515 ]]\n",
      "868000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13491501969247646\n",
      "[[ 0.83225264  0.69130466 -1.52368695]\n",
      " [ 1.95468265 -0.22345222 -1.73157262]\n",
      " [-2.67727785 -0.11039639  2.78809057]\n",
      " [-1.24340584 -1.0665274   2.31007793]]\n",
      "869000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13484499011841292\n",
      "[[ 0.83261831  0.69155248 -1.52430045]\n",
      " [ 1.95544086 -0.22329292 -1.73249012]\n",
      " [-2.67828257 -0.11056685  2.78926575]\n",
      " [-1.24388996 -1.06716866  2.3112033 ]]\n",
      "870000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13477509282850433\n",
      "[[ 0.83298364  0.69179992 -1.52491321]\n",
      " [ 1.9561983  -0.22313366 -1.73340683]\n",
      " [-2.6792863  -0.11073705  2.79043969]\n",
      " [-1.24437362 -1.06780934  2.31232764]]\n",
      "871000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1347053274326438\n",
      "[[ 0.83334862  0.69204696 -1.52552524]\n",
      " [ 1.95695499 -0.22297442 -1.73432275]\n",
      " [-2.68028905 -0.11090702  2.7916124 ]\n",
      " [-1.24485683 -1.06844943  2.31345095]]\n",
      "872000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13463569354227764\n",
      "[[ 0.83371326  0.69229363 -1.52613654]\n",
      " [ 1.95771093 -0.22281522 -1.73523788]\n",
      " [-2.68129081 -0.11107674  2.79278388]\n",
      " [-1.24533959 -1.06908893  2.31457321]]\n",
      "873000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13456619077039816\n",
      "[[ 0.83407756  0.6925399  -1.52674712]\n",
      " [ 1.95846611 -0.22265606 -1.73615223]\n",
      " [-2.68229159 -0.11124621  2.79395413]\n",
      " [-1.24582189 -1.06972786  2.31569444]]\n",
      "874000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13449681873153593\n",
      "[[ 0.83444152  0.6927858  -1.52735697]\n",
      " [ 1.95922054 -0.22249692 -1.73706579]\n",
      " [-2.68329139 -0.11141544  2.79512317]\n",
      " [-1.24630375 -1.07036621  2.31681464]]\n",
      "875000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13442757704175232\n",
      "[[ 0.83480513  0.69303131 -1.52796609]\n",
      " [ 1.95997421 -0.22233782 -1.73797858]\n",
      " [-2.68429022 -0.11158443  2.79629098]\n",
      " [-1.24678515 -1.07100398  2.31793382]]\n",
      "876000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13435846531863122\n",
      "[[ 0.83516841  0.69327643 -1.5285745 ]\n",
      " [ 1.96072714 -0.22217875 -1.73889057]\n",
      " [-2.68528806 -0.11175318  2.79745757]\n",
      " [-1.2472661  -1.07164118  2.31905196]]\n",
      "877000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13428948318127168\n",
      "[[ 0.83553134  0.69352118 -1.52918218]\n",
      " [ 1.96147933 -0.22201971 -1.73980179]\n",
      " [-2.68628494 -0.11192168  2.79862295]\n",
      " [-1.24774659 -1.0722778   2.32016908]]\n",
      "878000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13422063025028116\n",
      "[[ 0.83589394  0.69376555 -1.52978914]\n",
      " [ 1.96223076 -0.22186071 -1.74071223]\n",
      " [-2.68728084 -0.11208995  2.79978712]\n",
      " [-1.24822665 -1.07291384  2.32128517]]\n",
      "879000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1341519061477669\n",
      "[[ 0.8362562   0.69400953 -1.53039539]\n",
      " [ 1.96298145 -0.22170174 -1.74162189]\n",
      " [-2.68827577 -0.11225797  2.80095007]\n",
      " [-1.24870625 -1.07354931  2.32240025]]\n",
      "880000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1340833104973293\n",
      "[[ 0.83661812  0.69425314 -1.53100092]\n",
      " [ 1.9637314  -0.2215428  -1.74253078]\n",
      " [-2.68926973 -0.11242575  2.80211182]\n",
      " [-1.2491854  -1.07418421  2.3235143 ]]\n",
      "881000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1340148429240539\n",
      "[[ 0.83697971  0.69449637 -1.53160573]\n",
      " [ 1.96448061 -0.2213839  -1.74343889]\n",
      " [-2.69026273 -0.1125933   2.80327236]\n",
      " [-1.24966411 -1.07481853  2.32462733]]\n",
      "882000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13394650305450484\n",
      "[[ 0.83734096  0.69473922 -1.53220983]\n",
      " [ 1.96522908 -0.22122503 -1.74434622]\n",
      " [-2.69125476 -0.1127606   2.8044317 ]\n",
      " [-1.25014238 -1.07545229  2.32573936]]\n",
      "883000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13387829051671649\n",
      "[[ 0.83770187  0.6949817  -1.53281322]\n",
      " [ 1.96597681 -0.2210662  -1.74525279]\n",
      " [-2.69224583 -0.11292767  2.80558983]\n",
      " [-1.2506202  -1.07608548  2.32685036]]\n",
      "884000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13381020494018686\n",
      "[[ 0.83806245  0.6952238  -1.5334159 ]\n",
      " [ 1.9667238  -0.2209074  -1.74615858]\n",
      " [-2.69323594 -0.1130945   2.80674677]\n",
      " [-1.25109757 -1.0767181   2.32796036]]\n",
      "885000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13374224595587023\n",
      "[[ 0.83842269  0.69546553 -1.53401787]\n",
      " [ 1.96747005 -0.22074863 -1.7470636 ]\n",
      " [-2.69422509 -0.11326109  2.80790251]\n",
      " [-1.25157451 -1.07735015  2.32906934]]\n",
      "886000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13367441319617043\n",
      "[[ 0.8387826   0.69570688 -1.53461913]\n",
      " [ 1.96821558 -0.2205899  -1.74796786]\n",
      " [-2.69521329 -0.11342744  2.80905706]\n",
      " [-1.252051   -1.07798164  2.33017732]]\n",
      "887000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13360670629493257\n",
      "[[ 0.83914218  0.69594786 -1.53521969]\n",
      " [ 1.96896037 -0.2204312  -1.74887134]\n",
      " [-2.69620052 -0.11359356  2.81021042]\n",
      " [-1.25252705 -1.07861256  2.33128429]]\n",
      "888000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13353912488743697\n",
      "[[ 0.83950142  0.69618847 -1.53581955]\n",
      " [ 1.96970442 -0.22027254 -1.74977406]\n",
      " [-2.69718681 -0.11375944  2.81136259]\n",
      " [-1.25300266 -1.07924292  2.33239026]]\n",
      "889000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13347166861039167\n",
      "[[ 0.83986033  0.69642872 -1.5364187 ]\n",
      " [ 1.97044775 -0.22011391 -1.75067602]\n",
      " [-2.69817215 -0.11392509  2.81251357]\n",
      " [-1.25347783 -1.07987271  2.33349523]]\n",
      "890000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13340433710192542\n",
      "[[ 0.84021891  0.69666859 -1.53701715]\n",
      " [ 1.97119035 -0.21995532 -1.75157721]\n",
      " [-2.69915653 -0.1140905   2.81366337]\n",
      " [-1.25395257 -1.08050195  2.3345992 ]]\n",
      "891000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13333713000158062\n",
      "[[ 0.84057716  0.69690809 -1.53761491]\n",
      " [ 1.97193223 -0.21979677 -1.75247764]\n",
      " [-2.70013997 -0.11425568  2.81481198]\n",
      " [-1.25442686 -1.08113062  2.33570217]]\n",
      "892000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13327004695030686\n",
      "[[ 0.84093508  0.69714722 -1.53821196]\n",
      " [ 1.97267337 -0.21963824 -1.75337731]\n",
      " [-2.70112246 -0.11442063  2.81595942]\n",
      " [-1.25490072 -1.08175874  2.33680414]]\n",
      "893000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13320308759045352\n",
      "[[ 0.84129267  0.69738599 -1.53880832]\n",
      " [ 1.9734138  -0.21947976 -1.75427622]\n",
      " [-2.70210401 -0.11458534  2.81710568]\n",
      " [-1.25537414 -1.08238629  2.33790512]]\n",
      "894000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13313625156576292\n",
      "[[ 0.84164994  0.69762439 -1.53940398]\n",
      " [ 1.9741535  -0.21932131 -1.75517437]\n",
      " [-2.70308462 -0.11474982  2.81825077]\n",
      " [-1.25584713 -1.08301329  2.33900511]]\n",
      "895000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13306953852136422\n",
      "[[ 0.84200687  0.69786243 -1.53999895]\n",
      " [ 1.97489248 -0.21916289 -1.75607177]\n",
      " [-2.70406428 -0.11491406  2.81939468]\n",
      " [-1.25631968 -1.08363974  2.34010411]]\n",
      "896000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13300294810376537\n",
      "[[ 0.84236348  0.6981001  -1.54059323]\n",
      " [ 1.97563074 -0.21900451 -1.7569684 ]\n",
      " [-2.70504301 -0.11507808  2.82053742]\n",
      " [-1.2567918  -1.08426563  2.34120211]]\n",
      "897000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13293647996084756\n",
      "[[ 0.84271976  0.69833741 -1.54118682]\n",
      " [ 1.97636828 -0.21884617 -1.75786429]\n",
      " [-2.7060208  -0.11524187  2.821679  ]\n",
      " [-1.25726349 -1.08489097  2.34229914]]\n",
      "898000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13287013374185808\n",
      "[[ 0.84307571  0.69857436 -1.54177972]\n",
      " [ 1.97710511 -0.21868787 -1.75875942]\n",
      " [-2.70699766 -0.11540542  2.82281941]\n",
      " [-1.25773474 -1.08551575  2.34339518]]\n",
      "899000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13280390909740353\n",
      "[[ 0.84343134  0.69881094 -1.54237193]\n",
      " [ 1.97784121 -0.2185296  -1.7596538 ]\n",
      " [-2.70797358 -0.11556874  2.82395866]\n",
      " [-1.25820557 -1.08613998  2.34449023]]\n",
      "900000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1327378056794433\n",
      "[[ 0.84378664  0.69904716 -1.54296346]\n",
      " [ 1.97857661 -0.21837136 -1.76054743]\n",
      " [-2.70894857 -0.11573184  2.82509675]\n",
      " [-1.25867596 -1.08676366  2.34558431]]\n",
      "901000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13267182314128295\n",
      "[[ 0.84414162  0.69928303 -1.5435543 ]\n",
      " [ 1.97931129 -0.21821317 -1.76144031]\n",
      " [-2.70992264 -0.1158947   2.82623368]\n",
      " [-1.25914592 -1.08738679  2.3466774 ]]\n",
      "902000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13260596113756817\n",
      "[[ 0.84449628  0.69951853 -1.54414446]\n",
      " [ 1.98004526 -0.21805501 -1.76233244]\n",
      " [-2.71089577 -0.11605734  2.82736945]\n",
      " [-1.25961546 -1.08800938  2.34776952]]\n",
      "903000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13254021932427767\n",
      "[[ 0.84485061  0.69975368 -1.54473394]\n",
      " [ 1.98077852 -0.21789688 -1.76322382]\n",
      " [-2.71186798 -0.11621975  2.82850407]\n",
      " [-1.26008457 -1.08863141  2.34886067]]\n",
      "904000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1324745973587165\n",
      "[[ 0.84520462  0.69998847 -1.54532274]\n",
      " [ 1.98151108 -0.2177388  -1.76411446]\n",
      " [-2.71283927 -0.11638193  2.82963754]\n",
      " [-1.26055325 -1.0892529   2.34995084]]\n",
      "905000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13240909489951044\n",
      "[[ 0.8455583   0.7002229  -1.54591086]\n",
      " [ 1.98224292 -0.21758075 -1.76500435]\n",
      " [-2.71380964 -0.11654389  2.83076986]\n",
      " [-1.2610215  -1.08987385  2.35104004]]\n",
      "906000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13234371160659908\n",
      "[[ 0.84591167  0.70045698 -1.5464983 ]\n",
      " [ 1.98297406 -0.21742274 -1.7658935 ]\n",
      " [-2.71477908 -0.11670562  2.83190103]\n",
      " [-1.26148933 -1.09049425  2.35212827]]\n",
      "907000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13227844714122974\n",
      "[[ 0.84626471  0.7006907  -1.54708507]\n",
      " [ 1.9837045  -0.21726476 -1.76678191]\n",
      " [-2.71574761 -0.11686712  2.83303106]\n",
      " [-1.26195674 -1.0911141   2.35321553]]\n",
      "908000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13221330116595073\n",
      "[[ 0.84661744  0.70092407 -1.54767116]\n",
      " [ 1.98443423 -0.21710683 -1.76766958]\n",
      " [-2.71671521 -0.1170284   2.83415995]\n",
      " [-1.26242372 -1.09173342  2.35430183]]\n",
      "909000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13214827334460574\n",
      "[[ 0.84696984  0.70115708 -1.54825658]\n",
      " [ 1.98516326 -0.21694893 -1.76855651]\n",
      " [-2.71768191 -0.11718945  2.83528769]\n",
      " [-1.26289028 -1.09235219  2.35538716]]\n",
      "910000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1320833633423266\n",
      "[[ 0.84732193  0.70138974 -1.54884133]\n",
      " [ 1.98589159 -0.21679107 -1.7694427 ]\n",
      " [-2.71864769 -0.11735028  2.8364143 ]\n",
      " [-1.26335642 -1.09297043  2.35647153]]\n",
      "911000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13201857082552854\n",
      "[[ 0.8476737   0.70162205 -1.54942541]\n",
      " [ 1.98661922 -0.21663325 -1.77032815]\n",
      " [-2.71961256 -0.11751088  2.83753978]\n",
      " [-1.26382213 -1.09358812  2.35755494]]\n",
      "912000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13195389546190234\n",
      "[[ 0.84802515  0.70185402 -1.55000882]\n",
      " [ 1.98734615 -0.21647546 -1.77121287]\n",
      " [-2.72057652 -0.11767126  2.83866412]\n",
      " [-1.26428743 -1.09420528  2.35863739]]\n",
      "913000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1318893369204095\n",
      "[[ 0.84837628  0.70208563 -1.55059156]\n",
      " [ 1.98807239 -0.21631772 -1.77209685]\n",
      " [-2.72153957 -0.11783142  2.83978732]\n",
      " [-1.2647523  -1.0948219   2.35971889]]\n",
      "914000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13182489487127544\n",
      "[[ 0.8487271   0.70231689 -1.55117364]\n",
      " [ 1.98879793 -0.21616001 -1.7729801 ]\n",
      " [-2.72250171 -0.11799136  2.84090941]\n",
      " [-1.26521676 -1.09543798  2.36079943]]\n",
      "915000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13176056898598384\n",
      "[[ 0.8490776   0.7025478  -1.55175505]\n",
      " [ 1.98952278 -0.21600234 -1.77386262]\n",
      " [-2.72346296 -0.11815107  2.84203036]\n",
      " [-1.2656808  -1.09605353  2.36187901]]\n",
      "916000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13169635893727027\n",
      "[[ 0.84942778  0.70277837 -1.5523358 ]\n",
      " [ 1.99024694 -0.21584471 -1.77474441]\n",
      " [-2.72442329 -0.11831056  2.84315019]\n",
      " [-1.26614442 -1.09666855  2.36295765]]\n",
      "917000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1316322643991165\n",
      "[[ 0.84977765  0.70300859 -1.55291589]\n",
      " [ 1.9909704  -0.21568712 -1.77562547]\n",
      " [-2.72538273 -0.11846983  2.8442689 ]\n",
      " [-1.26660762 -1.09728303  2.36403534]]\n",
      "918000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13156828504674445\n",
      "[[ 0.85012721  0.70323846 -1.55349532]\n",
      " [ 1.99169318 -0.21552956 -1.77650579]\n",
      " [-2.72634127 -0.11862888  2.84538648]\n",
      " [-1.26707041 -1.09789698  2.36511208]]\n",
      "919000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13150442055660994\n",
      "[[ 0.85047645  0.70346799 -1.55407409]\n",
      " [ 1.99241526 -0.21537205 -1.77738539]\n",
      " [-2.72729891 -0.11878771  2.84650295]\n",
      " [-1.26753278 -1.0985104   2.36618787]]\n",
      "920000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1314406706063972\n",
      "[[ 0.85082538  0.70369717 -1.5546522 ]\n",
      " [ 1.99313666 -0.21521457 -1.77826427]\n",
      " [-2.72825565 -0.11894632  2.84761831]\n",
      " [-1.26799474 -1.09912329  2.36726272]]\n",
      "921000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13137703487501326\n",
      "[[ 0.85117399  0.70392602 -1.55522966]\n",
      " [ 1.99385738 -0.21505714 -1.77914242]\n",
      " [-2.7292115  -0.11910471  2.84873255]\n",
      " [-1.26845629 -1.09973565  2.36833662]]\n",
      "922000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13131351304258118\n",
      "[[ 0.8515223   0.70415451 -1.55580646]\n",
      " [ 1.99457741 -0.21489974 -1.78001985]\n",
      " [-2.73016646 -0.11926289  2.84984568]\n",
      " [-1.26891742 -1.10034748  2.36940959]]\n",
      "923000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.131250104790435\n",
      "[[ 0.85187029  0.70438267 -1.55638261]\n",
      " [ 1.99529675 -0.21474239 -1.78089655]\n",
      " [-2.73112052 -0.11942084  2.8509577 ]\n",
      " [-1.26937814 -1.10095879  2.37048162]]\n",
      "924000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13118680980111416\n",
      "[[ 0.85221797  0.70461049 -1.55695811]\n",
      " [ 1.99601542 -0.21458507 -1.78177253]\n",
      " [-2.7320737  -0.11957858  2.85206861]\n",
      " [-1.26983845 -1.10156957  2.37155271]]\n",
      "925000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13112362775835712\n",
      "[[ 0.85256534  0.70483796 -1.55753296]\n",
      " [ 1.9967334  -0.21442779 -1.78264779]\n",
      " [-2.73302599 -0.1197361   2.85317842]\n",
      " [-1.27029835 -1.10217982  2.37262286]]\n",
      "926000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1310605583470961\n",
      "[[ 0.8529124   0.7050651  -1.55810716]\n",
      " [ 1.99745071 -0.21427055 -1.78352234]\n",
      " [-2.73397739 -0.1198934   2.85428713]\n",
      " [-1.27075784 -1.10278955  2.37369208]]\n",
      "927000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13099760125345125\n",
      "[[ 0.85325916  0.7052919  -1.55868071]\n",
      " [ 1.99816734 -0.21411336 -1.78439616]\n",
      " [-2.73492791 -0.12005049  2.85539473]\n",
      " [-1.27121692 -1.10339876  2.37476037]]\n",
      "928000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13093475616472494\n",
      "[[ 0.8536056   0.70551836 -1.55925361]\n",
      " [ 1.99888329 -0.2139562  -1.78526927]\n",
      " [-2.73587755 -0.12020736  2.85650124]\n",
      " [-1.2716756  -1.10400745  2.37582773]]\n",
      "929000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1308720227693966\n",
      "[[ 0.85395174  0.70574448 -1.55982587]\n",
      " [ 1.99959856 -0.21379908 -1.78614166]\n",
      " [-2.7368263  -0.12036401  2.85760665]\n",
      " [-1.27213386 -1.10461562  2.37689416]]\n",
      "930000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13080940075711658\n",
      "[[ 0.85429756  0.70597027 -1.56039749]\n",
      " [ 2.00031317 -0.21364201 -1.78701334]\n",
      " [-2.73777418 -0.12052046  2.85871097]\n",
      " [-1.27259172 -1.10522326  2.37795967]]\n",
      "931000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13074688981870133\n",
      "[[ 0.85464309  0.70619572 -1.56096846]\n",
      " [ 2.0010271  -0.21348497 -1.78788431]\n",
      " [-2.73872118 -0.12067668  2.8598142 ]\n",
      " [-1.27304918 -1.10583039  2.37902425]]\n",
      "932000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13068448964612708\n",
      "[[ 0.8549883   0.70642084 -1.5615388 ]\n",
      " [ 2.00174035 -0.21332797 -1.78875456]\n",
      " [-2.7396673  -0.12083269  2.86091633]\n",
      " [-1.27350622 -1.106437    2.38008791]]\n",
      "933000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13062219993252497\n",
      "[[ 0.85533321  0.70664563 -1.56210849]\n",
      " [ 2.00245294 -0.21317102 -1.7896241 ]\n",
      " [-2.74061255 -0.12098849  2.86201738]\n",
      " [-1.27396287 -1.10704309  2.38115064]]\n",
      "934000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1305600203721749\n",
      "[[ 0.85567781  0.70687008 -1.56267754]\n",
      " [ 2.00316486 -0.2130141  -1.79049294]\n",
      " [-2.74155693 -0.12114408  2.86311734]\n",
      " [-1.27441911 -1.10764866  2.38221246]]\n",
      "935000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13049795066050165\n",
      "[[ 0.85602211  0.7070942  -1.56324596]\n",
      " [ 2.00387611 -0.21285723 -1.79136106]\n",
      " [-2.74250043 -0.12129945  2.86421622]\n",
      " [-1.27487495 -1.10825372  2.38327335]]\n",
      "936000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1304359904940674\n",
      "[[ 0.85636611  0.70731798 -1.56381374]\n",
      " [ 2.00458669 -0.2127004  -1.79222848]\n",
      " [-2.74344307 -0.12145462  2.86531402]\n",
      " [-1.27533038 -1.10885827  2.38433334]]\n",
      "937000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13037413957056804\n",
      "[[ 0.8567098   0.70754144 -1.56438089]\n",
      " [ 2.00529661 -0.21254361 -1.79309519]\n",
      " [-2.74438484 -0.12160957  2.86641074]\n",
      " [-1.27578542 -1.1094623   2.3853924 ]]\n",
      "938000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13031239758882737\n",
      "[[ 0.85705319  0.70776456 -1.56494741]\n",
      " [ 2.00600587 -0.21238686 -1.79396119]\n",
      " [-2.74532574 -0.1217643   2.86750638]\n",
      " [-1.27624005 -1.11006582  2.38645056]]\n",
      "939000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13025076424879128\n",
      "[[ 0.85739628  0.70798736 -1.56551329]\n",
      " [ 2.00671446 -0.21223015 -1.79482649]\n",
      " [-2.74626578 -0.12191883  2.86860094]\n",
      " [-1.27669428 -1.11066883  2.3875078 ]]\n",
      "940000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13018923925152345\n",
      "[[ 0.85773906  0.70820983 -1.56607854]\n",
      " [ 2.00742239 -0.21207348 -1.79569109]\n",
      " [-2.74720495 -0.12207315  2.86969444]\n",
      " [-1.27714812 -1.11127133  2.38856413]]\n",
      "941000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13012782229919911\n",
      "[[ 0.85808154  0.70843197 -1.56664317]\n",
      " [ 2.00812967 -0.21191686 -1.79655499]\n",
      " [-2.74814327 -0.12222726  2.87078686]\n",
      " [-1.27760155 -1.11187332  2.38961956]]\n",
      "942000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13006651309510092\n",
      "[[ 0.85842372  0.70865379 -1.56720716]\n",
      " [ 2.00883628 -0.21176027 -1.79741819]\n",
      " [-2.74908072 -0.12238116  2.87187821]\n",
      " [-1.27805459 -1.1124748   2.39067407]]\n",
      "943000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.13000531134361248\n",
      "[[ 0.85876561  0.70887527 -1.56777053]\n",
      " [ 2.00954223 -0.21160373 -1.79828068]\n",
      " [-2.75001732 -0.12253485  2.8729685 ]\n",
      " [-1.27850723 -1.11307577  2.39172769]]\n",
      "944000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12994421675021467\n",
      "[[ 0.85910719  0.70909644 -1.56833328]\n",
      " [ 2.01024753 -0.21144723 -1.79914248]\n",
      " [-2.75095306 -0.12268833  2.87405772]\n",
      " [-1.27895948 -1.11367624  2.3927804 ]]\n",
      "945000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12988322902147942\n",
      "[[ 0.85944847  0.70931727 -1.5688954 ]\n",
      " [ 2.01095218 -0.21129077 -1.80000358]\n",
      " [-2.75188794 -0.1228416   2.87514588]\n",
      " [-1.27941133 -1.1142762   2.39383221]]\n",
      "946000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12982234786506502\n",
      "[[ 0.85978946  0.70953779 -1.5694569 ]\n",
      " [ 2.01165616 -0.21113436 -1.80086399]\n",
      " [-2.75282197 -0.12299467  2.87623297]\n",
      " [-1.27986278 -1.11487565  2.39488312]]\n",
      "947000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1297615729897114\n",
      "[[ 0.86013014  0.70975798 -1.57001777]\n",
      " [ 2.0123595  -0.21097798 -1.8017237 ]\n",
      " [-2.75375515 -0.12314752  2.87731901]\n",
      " [-1.28031384 -1.11547461  2.39593313]]\n",
      "948000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12970090410523416\n",
      "[[ 0.86047053  0.70997785 -1.57057803]\n",
      " [ 2.01306219 -0.21082165 -1.80258272]\n",
      " [-2.75468748 -0.12330018  2.87840399]\n",
      " [-1.28076451 -1.11607306  2.39698225]]\n",
      "949000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12964034092252055\n",
      "[[ 0.86081062  0.71019739 -1.57113767]\n",
      " [ 2.01376422 -0.21066536 -1.80344104]\n",
      " [-2.75561896 -0.12345262  2.87948792]\n",
      " [-1.28121478 -1.116671    2.39803047]]\n",
      "950000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1295798831535242\n",
      "[[ 0.86115042  0.71041662 -1.57169669]\n",
      " [ 2.01446561 -0.21050911 -1.80429867]\n",
      " [-2.7565496  -0.12360486  2.88057079]\n",
      " [-1.28166466 -1.11726845  2.3990778 ]]\n",
      "951000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12951953051126006\n",
      "[[ 0.86148991  0.71063552 -1.57225509]\n",
      " [ 2.01516634 -0.21035291 -1.80515561]\n",
      " [-2.75747939 -0.12375689  2.88165261]\n",
      " [-1.28211416 -1.1178654   2.40012424]]\n",
      "952000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12945928270979942\n",
      "[[ 0.86182912  0.71085411 -1.57281288]\n",
      " [ 2.01586644 -0.21019675 -1.80601187]\n",
      " [-2.75840833 -0.12390872  2.88273339]\n",
      " [-1.28256326 -1.11846184  2.40116978]]\n",
      "953000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12939913946426534\n",
      "[[ 0.86216803  0.71107238 -1.57337006]\n",
      " [ 2.01656588 -0.21004063 -1.80686743]\n",
      " [-2.75933643 -0.12406035  2.88381312]\n",
      " [-1.28301197 -1.11905779  2.40221444]]\n",
      "954000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12933910049082734\n",
      "[[ 0.86250664  0.71129033 -1.57392662]\n",
      " [ 2.01726468 -0.20988456 -1.80772231]\n",
      " [-2.76026369 -0.12421177  2.8848918 ]\n",
      " [-1.28346029 -1.11965324  2.40325822]]\n",
      "955000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12927916550669669\n",
      "[[ 0.86284496  0.71150796 -1.57448257]\n",
      " [ 2.01796284 -0.20972852 -1.8085765 ]\n",
      " [-2.76119012 -0.12436299  2.88596944]\n",
      " [-1.28390822 -1.1202482   2.4043011 ]]\n",
      "956000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12921933423012236\n",
      "[[ 0.86318299  0.71172527 -1.57503791]\n",
      " [ 2.01866036 -0.20957253 -1.80943   ]\n",
      " [-2.7621157  -0.124514    2.88704604]\n",
      " [-1.28435577 -1.12084266  2.40534311]]\n",
      "957000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12915960638038507\n",
      "[[ 0.86352072  0.71194227 -1.57559265]\n",
      " [ 2.01935723 -0.20941659 -1.81028283]\n",
      " [-2.76304045 -0.12466481  2.8881216 ]\n",
      " [-1.28480293 -1.12143662  2.40638423]]\n",
      "958000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12909998167779327\n",
      "[[ 0.86385816  0.71215895 -1.57614677]\n",
      " [ 2.02005347 -0.20926069 -1.81113496]\n",
      " [-2.76396436 -0.12481542  2.88919612]\n",
      " [-1.2852497  -1.12203009  2.40742447]]\n",
      "959000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12904045984367807\n",
      "[[ 0.86419531  0.71237532 -1.57670029]\n",
      " [ 2.02074907 -0.20910483 -1.81198642]\n",
      " [-2.76488745 -0.12496583  2.89026961]\n",
      " [-1.28569608 -1.12262307  2.40846384]]\n",
      "960000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12898104060038904\n",
      "[[ 0.86453217  0.71259138 -1.5772532 ]\n",
      " [ 2.02144403 -0.20894901 -1.8128372 ]\n",
      " [-2.7658097  -0.12511603  2.89134206]\n",
      " [-1.28614209 -1.12321555  2.40950233]]\n",
      "961000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.128921723671289\n",
      "[[ 0.86486874  0.71280712 -1.57780551]\n",
      " [ 2.02213835 -0.20879324 -1.81368729]\n",
      " [-2.76673111 -0.12526604  2.89241349]\n",
      " [-1.2865877  -1.12380755  2.41053994]]\n",
      "962000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12886250878074917\n",
      "[[ 0.86520501  0.71302255 -1.57835722]\n",
      " [ 2.02283204 -0.20863751 -1.81453671]\n",
      " [-2.76765171 -0.12541584  2.89348388]\n",
      " [-1.28703294 -1.12439905  2.41157668]]\n",
      "963000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12880339565414567\n",
      "[[ 0.865541    0.71323767 -1.57890833]\n",
      " [ 2.0235251  -0.20848183 -1.81538545]\n",
      " [-2.76857147 -0.12556544  2.89455325]\n",
      " [-1.28747779 -1.12499007  2.41261254]]\n",
      "964000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12874438401785365\n",
      "[[ 0.8658767   0.71345248 -1.57945883]\n",
      " [ 2.02421752 -0.20832619 -1.81623352]\n",
      " [-2.76949041 -0.12571485  2.89562159]\n",
      " [-1.28792226 -1.12558059  2.41364754]]\n",
      "965000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1286854735992434\n",
      "[[ 0.86621211  0.71366698 -1.58000874]\n",
      " [ 2.02490932 -0.20817059 -1.81708091]\n",
      " [-2.77040852 -0.12586405  2.89668891]\n",
      " [-1.28836635 -1.12617063  2.41468166]]\n",
      "966000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12862666412667575\n",
      "[[ 0.86654723  0.71388116 -1.58055805]\n",
      " [ 2.02560048 -0.20801504 -1.81792762]\n",
      " [-2.77132581 -0.12601306  2.8977552 ]\n",
      " [-1.28881005 -1.12676018  2.41571492]]\n",
      "967000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1285679553294974\n",
      "[[ 0.86688206  0.71409504 -1.58110676]\n",
      " [ 2.02629101 -0.20785953 -1.81877366]\n",
      " [-2.77224228 -0.12616186  2.89882048]\n",
      " [-1.28925338 -1.12734925  2.41674731]]\n",
      "968000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12850934693803634\n",
      "[[ 0.86721661  0.71430861 -1.58165488]\n",
      " [ 2.02698092 -0.20770406 -1.81961903]\n",
      " [-2.77315794 -0.12631047  2.89988474]\n",
      " [-1.28969633 -1.12793783  2.41777884]]\n",
      "969000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12845083868359775\n",
      "[[ 0.86755087  0.71452188 -1.5822024 ]\n",
      " [ 2.0276702  -0.20754864 -1.82046373]\n",
      " [-2.77407277 -0.12645888  2.90094799]\n",
      " [-1.29013889 -1.12852593  2.41880951]]\n",
      "970000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1283924302984594\n",
      "[[ 0.86788484  0.71473483 -1.58274933]\n",
      " [ 2.02835885 -0.20739327 -1.82130776]\n",
      " [-2.77498679 -0.1266071   2.90201022]\n",
      " [-1.29058108 -1.12911354  2.41983931]]\n",
      "971000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12833412151586696\n",
      "[[ 0.86821853  0.71494748 -1.58329567]\n",
      " [ 2.02904688 -0.20723794 -1.82215112]\n",
      " [-2.77589999 -0.12675511  2.90307143]\n",
      " [-1.2910229  -1.12970067  2.42086826]]\n",
      "972000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12827591207002959\n",
      "[[ 0.86855193  0.71515983 -1.58384142]\n",
      " [ 2.02973428 -0.20708265 -1.82299381]\n",
      " [-2.77681238 -0.12690293  2.90413164]\n",
      " [-1.29146433 -1.13028732  2.42189634]]\n",
      "973000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1282178016961159\n",
      "[[ 0.86888505  0.71537187 -1.58438658]\n",
      " [ 2.03042107 -0.20692741 -1.82383584]\n",
      " [-2.77772395 -0.12705056  2.90519084]\n",
      " [-1.29190539 -1.13087349  2.42292357]]\n",
      "974000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12815979013024986\n",
      "[[ 0.86921789  0.71558361 -1.58493115]\n",
      " [ 2.03110723 -0.20677222 -1.8246772 ]\n",
      " [-2.77863472 -0.12719798  2.90624904]\n",
      " [-1.29234608 -1.13145918  2.42394995]]\n",
      "975000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12810187710950546\n",
      "[[ 0.86955043  0.71579504 -1.58547513]\n",
      " [ 2.03179277 -0.20661706 -1.82551789]\n",
      " [-2.77954467 -0.12734522  2.90730623]\n",
      " [-1.29278639 -1.1320444   2.42497547]]\n",
      "976000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12804406237190377\n",
      "[[ 0.8698827   0.71600617 -1.58601853]\n",
      " [ 2.0324777  -0.20646196 -1.82635792]\n",
      " [-2.78045382 -0.12749226  2.90836241]\n",
      " [-1.29322632 -1.13262913  2.42600014]]\n",
      "977000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12798634565640715\n",
      "[[ 0.87021469  0.716217   -1.58656134]\n",
      " [ 2.033162   -0.2063069  -1.82719729]\n",
      " [-2.78136216 -0.1276391   2.9094176 ]\n",
      " [-1.29366588 -1.13321338  2.42702395]]\n",
      "978000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1279287267029161\n",
      "[[ 0.87054639  0.71642753 -1.58710357]\n",
      " [ 2.03384569 -0.20615188 -1.828036  ]\n",
      " [-2.7822697  -0.12778575  2.91047179]\n",
      " [-1.29410507 -1.13379716  2.42804692]]\n",
      "979000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12787120525226464\n",
      "[[ 0.87087781  0.71663775 -1.58764521]\n",
      " [ 2.03452877 -0.20599691 -1.82887404]\n",
      " [-2.78317644 -0.12793221  2.91152498]\n",
      " [-1.29454389 -1.13438047  2.42906905]]\n",
      "980000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12781378104621607\n",
      "[[ 0.87120895  0.71684768 -1.58818628]\n",
      " [ 2.03521123 -0.20584198 -1.82971143]\n",
      " [-2.78408237 -0.12807847  2.91257717]\n",
      " [-1.29498234 -1.1349633   2.43009032]]\n",
      "981000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12775645382745898\n",
      "[[ 0.8715398   0.71705731 -1.58872677]\n",
      " [ 2.03589308 -0.2056871  -1.83054815]\n",
      " [-2.7849875  -0.12822454  2.91362837]\n",
      " [-1.29542041 -1.13554565  2.43111075]]\n",
      "982000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12769922333960287\n",
      "[[ 0.87187038  0.71726664 -1.58926667]\n",
      " [ 2.03657431 -0.20553227 -1.83138422]\n",
      " [-2.78589183 -0.12837042  2.91467858]\n",
      " [-1.29585812 -1.13612754  2.43213034]]\n",
      "983000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.12764208932717425\n",
      "[[ 0.87220068  0.71747567 -1.589806  ]\n",
      " [ 2.03725494 -0.20537748 -1.83221964]\n",
      " [-2.78679537 -0.1285161   2.9157278 ]\n",
      " [-1.29629545 -1.13670895  2.43314909]]\n",
      "984000 번째 학습중입니다.\n",
      "Accuracy :  0.98\n",
      "Loss :      0.1275850515356119\n",
      "[[ 0.8725307   0.7176844  -1.59034475]\n",
      " [ 2.03793495 -0.20522274 -1.8330544 ]\n",
      " [-2.78769811 -0.12866159  2.91677603]\n",
      " [-1.29673242 -1.13728989  2.43416699]]\n",
      "985000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12752810971126372\n",
      "[[ 0.87286044  0.71789284 -1.59088293]\n",
      " [ 2.03861436 -0.20506804 -1.8338885 ]\n",
      " [-2.78860005 -0.1288069   2.91782328]\n",
      " [-1.29716902 -1.13787035  2.43518406]]\n",
      "986000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12747126360138197\n",
      "[[ 0.8731899   0.71810098 -1.59142053]\n",
      " [ 2.03929315 -0.20491339 -1.83472195]\n",
      " [-2.7895012  -0.12895201  2.91886954]\n",
      " [-1.29760525 -1.13845035  2.43620029]]\n",
      "987000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12741451295411926\n",
      "[[ 0.87351908  0.71830882 -1.59195756]\n",
      " [ 2.03997135 -0.20475878 -1.83555475]\n",
      " [-2.79040156 -0.12909693  2.91991482]\n",
      " [-1.29804111 -1.13902988  2.43721568]]\n",
      "988000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1273578575185248\n",
      "[[ 0.87384799  0.71851638 -1.59249402]\n",
      " [ 2.04064893 -0.20460422 -1.83638689]\n",
      " [-2.79130113 -0.12924166  2.92095912]\n",
      " [-1.29847661 -1.13960895  2.43823024]]\n",
      "989000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1273012970445405\n",
      "[[ 0.87417662  0.71872363 -1.59302991]\n",
      " [ 2.04132591 -0.20444971 -1.83721839]\n",
      " [-2.79219991 -0.1293862   2.92200244]\n",
      " [-1.29891174 -1.14018754  2.43924397]]\n",
      "990000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12724483128299618\n",
      "[[ 0.87450497  0.7189306  -1.59356522]\n",
      " [ 2.04200229 -0.20429524 -1.83804923]\n",
      " [-2.7930979  -0.12953056  2.92304479]\n",
      " [-1.29934651 -1.14076567  2.44025687]]\n",
      "991000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12718845998560677\n",
      "[[ 0.87483305  0.71913727 -1.59409997]\n",
      " [ 2.04267807 -0.20414082 -1.83887943]\n",
      " [-2.7939951  -0.12967472  2.92408616]\n",
      " [-1.29978091 -1.14134333  2.44126893]]\n",
      "992000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1271321829049673\n",
      "[[ 0.87516085  0.71934365 -1.59463415]\n",
      " [ 2.04335325 -0.20398644 -1.83970898]\n",
      " [-2.79489152 -0.12981869  2.92512655]\n",
      " [-1.30021495 -1.14192053  2.44228017]]\n",
      "993000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12707599979454953\n",
      "[[ 0.87548838  0.71954973 -1.59516777]\n",
      " [ 2.04402782 -0.20383212 -1.84053789]\n",
      " [-2.79578716 -0.12996248  2.92616597]\n",
      " [-1.30064863 -1.14249727  2.44329058]]\n",
      "994000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12701991040869795\n",
      "[[ 0.87581563  0.71975553 -1.59570081]\n",
      " [ 2.0447018  -0.20367783 -1.84136615]\n",
      " [-2.79668201 -0.13010608  2.92720443]\n",
      " [-1.30108194 -1.14307354  2.44430017]]\n",
      "995000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12696391450262604\n",
      "[[ 0.87614261  0.71996104 -1.5962333 ]\n",
      " [ 2.04537518 -0.2035236  -1.84219376]\n",
      " [-2.79757609 -0.13024949  2.92824191]\n",
      " [-1.3015149  -1.14364935  2.44530893]]\n",
      "996000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1269080118324119\n",
      "[[ 0.87646931  0.72016625 -1.59676522]\n",
      " [ 2.04604796 -0.20336941 -1.84302073]\n",
      " [-2.79846938 -0.13039272  2.92927843]\n",
      " [-1.30194749 -1.1442247   2.44631687]]\n",
      "997000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12685220215499524\n",
      "[[ 0.87679574  0.72037118 -1.59729658]\n",
      " [ 2.04672014 -0.20321527 -1.84384706]\n",
      " [-2.7993619  -0.13053575  2.93031399]\n",
      " [-1.30237972 -1.14479959  2.44732399]]\n",
      "998000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12679648522817252\n",
      "[[ 0.8771219   0.72057582 -1.59782738]\n",
      " [ 2.04739174 -0.20306117 -1.84467274]\n",
      " [-2.80025364 -0.1306786   2.93134858]\n",
      " [-1.30281159 -1.14537402  2.44833029]]\n",
      "999000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12674086081059396\n",
      "[[ 0.87744779  0.72078017 -1.59835762]\n",
      " [ 2.04806273 -0.20290712 -1.84549779]\n",
      " [-2.8011446  -0.13082127  2.93238221]\n",
      " [-1.3032431  -1.14594798  2.44933577]]\n",
      "1000000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1266853286617598\n",
      "[[ 0.87777341  0.72098424 -1.5988873 ]\n",
      " [ 2.04873314 -0.20275312 -1.8463222 ]\n",
      " [-2.80203479 -0.13096375  2.93341488]\n",
      " [-1.30367425 -1.1465215   2.45034043]]\n",
      "1001000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12662988854201576\n",
      "[[ 0.87809875  0.72118802 -1.59941642]\n",
      " [ 2.04940295 -0.20259917 -1.84714597]\n",
      " [-2.80292421 -0.13110605  2.93444659]\n",
      " [-1.30410505 -1.14709455  2.45134428]]\n",
      "1002000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1265745402125501\n",
      "[[ 0.87842382  0.72139151 -1.59994499]\n",
      " [ 2.05007218 -0.20244526 -1.8479691 ]\n",
      " [-2.80381286 -0.13124816  2.93547735]\n",
      " [-1.30453548 -1.14766715  2.45234731]]\n",
      "1003000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12651928343538946\n",
      "[[ 0.87874863  0.72159472 -1.600473  ]\n",
      " [ 2.05074081 -0.2022914  -1.84879159]\n",
      " [-2.80470074 -0.13139008  2.93650715]\n",
      " [-1.30496556 -1.14823929  2.45334954]]\n",
      "1004000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1264641179733953\n",
      "[[ 0.87907316  0.72179764 -1.60100045]\n",
      " [ 2.05140886 -0.20213759 -1.84961345]\n",
      " [-2.80558784 -0.13153183  2.93753601]\n",
      " [-1.30539529 -1.14881097  2.45435095]]\n",
      "1005000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12640904359026023\n",
      "[[ 0.87939742  0.72200028 -1.60152736]\n",
      " [ 2.05207632 -0.20198382 -1.85043467]\n",
      " [-2.80647419 -0.13167339  2.93856391]\n",
      " [-1.30582465 -1.14938221  2.45535155]]\n",
      "1006000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12635406005050417\n",
      "[[ 0.87972142  0.72220264 -1.60205371]\n",
      " [ 2.05274319 -0.2018301  -1.85125526]\n",
      " [-2.80735976 -0.13181476  2.93959086]\n",
      " [-1.30625367 -1.14995298  2.45635134]]\n",
      "1007000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12629916711947098\n",
      "[[ 0.88004514  0.72240471 -1.60257951]\n",
      " [ 2.05340947 -0.20167643 -1.85207522]\n",
      " [-2.80824457 -0.13195595  2.94061686]\n",
      " [-1.30668233 -1.15052331  2.45735032]]\n",
      "1008000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12624436456332447\n",
      "[[ 0.8803686   0.7226065  -1.60310476]\n",
      " [ 2.05407518 -0.20152281 -1.85289455]\n",
      " [-2.80912862 -0.13209696  2.94164192]\n",
      " [-1.30711063 -1.15109318  2.4583485 ]]\n",
      "1009000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12618965214904537\n",
      "[[ 0.88069179  0.72280801 -1.60362946]\n",
      " [ 2.0547403  -0.20136923 -1.85371324]\n",
      " [-2.81001191 -0.13223779  2.94266604]\n",
      " [-1.30753859 -1.15166261  2.45934588]]\n",
      "1010000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12613502964442744\n",
      "[[ 0.88101471  0.72300924 -1.60415361]\n",
      " [ 2.05540483 -0.20121571 -1.85453131]\n",
      " [-2.81089444 -0.13237844  2.94368921]\n",
      " [-1.30796619 -1.15223158  2.46034245]]\n",
      "1011000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12608049681807365\n",
      "[[ 0.88133737  0.72321019 -1.60467722]\n",
      " [ 2.05606879 -0.20106223 -1.85534874]\n",
      " [-2.8117762  -0.1325189   2.94471144]\n",
      " [-1.30839343 -1.1528001   2.46133822]]\n",
      "1012000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12602605343939288\n",
      "[[ 0.88165976  0.72341086 -1.60520028]\n",
      " [ 2.05673217 -0.20090879 -1.85616555]\n",
      " [-2.81265721 -0.13265919  2.94573274]\n",
      " [-1.30882033 -1.15336818  2.46233319]]\n",
      "1013000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12597169927859625\n",
      "[[ 0.88198189  0.72361126 -1.6057228 ]\n",
      " [ 2.05739496 -0.20075541 -1.85698173]\n",
      " [-2.81353747 -0.13279929  2.94675309]\n",
      " [-1.30924688 -1.1539358   2.46332736]]\n",
      "1014000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1259174341066941\n",
      "[[ 0.88230375  0.72381137 -1.60624477]\n",
      " [ 2.05805718 -0.20060207 -1.85779729]\n",
      " [-2.81441696 -0.13293922  2.94777251]\n",
      " [-1.30967307 -1.15450298  2.46432074]]\n",
      "1015000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12586325769549173\n",
      "[[ 0.88262534  0.7240112  -1.6067662 ]\n",
      " [ 2.05871883 -0.20044879 -1.85861222]\n",
      " [-2.81529571 -0.13307896  2.948791  ]\n",
      " [-1.31009892 -1.15506971  2.46531332]]\n",
      "1016000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1258091698175866\n",
      "[[ 0.88294667  0.72421076 -1.60728709]\n",
      " [ 2.05937989 -0.20029554 -1.85942653]\n",
      " [-2.8161737  -0.13321852  2.94980856]\n",
      " [-1.31052441 -1.155636    2.4663051 ]]\n",
      "1017000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12575517024636446\n",
      "[[ 0.88326774  0.72441004 -1.60780744]\n",
      " [ 2.06004038 -0.20014235 -1.86024021]\n",
      " [-2.81705094 -0.13335791  2.95082518]\n",
      " [-1.31094956 -1.15620184  2.46729609]]\n",
      "1018000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12570125875599586\n",
      "[[ 0.88358854  0.72460905 -1.60832724]\n",
      " [ 2.0607003  -0.19998921 -1.86105327]\n",
      " [-2.81792743 -0.13349712  2.95184088]\n",
      " [-1.31137436 -1.15676724  2.46828629]]\n",
      "1019000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1256474351214332\n",
      "[[ 0.88390908  0.72480778 -1.60884651]\n",
      " [ 2.06135964 -0.19983611 -1.86186571]\n",
      " [-2.81880317 -0.13363614  2.95285565]\n",
      " [-1.31179882 -1.1573322   2.4692757 ]]\n",
      "1020000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1255936991184071\n",
      "[[ 0.88422936  0.72500623 -1.60936525]\n",
      " [ 2.06201842 -0.19968307 -1.86267753]\n",
      " [-2.81967817 -0.13377499  2.9538695 ]\n",
      " [-1.31222293 -1.15789671  2.47026432]]\n",
      "1021000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1255400505234228\n",
      "[[ 0.88454937  0.72520441 -1.60988344]\n",
      " [ 2.06267662 -0.19953007 -1.86348873]\n",
      " [-2.82055242 -0.13391366  2.95488242]\n",
      " [-1.31264669 -1.15846078  2.47125215]]\n",
      "1022000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12548648911375704\n",
      "[[ 0.88486913  0.72540232 -1.6104011 ]\n",
      " [ 2.06333425 -0.19937712 -1.86429931]\n",
      " [-2.82142592 -0.13405216  2.95589442]\n",
      " [-1.3130701  -1.15902441  2.4722392 ]]\n",
      "1023000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12543301466745432\n",
      "[[ 0.88518862  0.72559996 -1.61091823]\n",
      " [ 2.06399131 -0.19922421 -1.86510928]\n",
      " [-2.82229868 -0.13419048  2.95690549]\n",
      " [-1.31349318 -1.1595876   2.47322546]]\n",
      "1024000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12537962696332436\n",
      "[[ 0.88550785  0.72579732 -1.61143482]\n",
      " [ 2.06464781 -0.19907136 -1.86591862]\n",
      " [-2.8231707  -0.13432862  2.95791565]\n",
      " [-1.3139159  -1.16015035  2.47421093]]\n",
      "1025000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12532632578093789\n",
      "[[ 0.88582682  0.72599441 -1.61195088]\n",
      " [ 2.06530373 -0.19891856 -1.86672736]\n",
      " [-2.82404198 -0.13446658  2.9589249 ]\n",
      " [-1.31433829 -1.16071266  2.47519563]]\n",
      "1026000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12527311090062385\n",
      "[[ 0.88614553  0.72619123 -1.61246641]\n",
      " [ 2.06595909 -0.1987658  -1.86753547]\n",
      " [-2.82491252 -0.13460437  2.95993322]\n",
      " [-1.31476033 -1.16127453  2.47617954]]\n",
      "1027000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12521998210346644\n",
      "[[ 0.88646398  0.72638778 -1.61298141]\n",
      " [ 2.06661389 -0.19861309 -1.86834298]\n",
      " [-2.82578232 -0.13474198  2.96094064]\n",
      " [-1.31518203 -1.16183596  2.47716267]]\n",
      "1028000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12516693917130126\n",
      "[[ 0.88678217  0.72658406 -1.61349588]\n",
      " [ 2.06726812 -0.19846044 -1.86914987]\n",
      " [-2.82665138 -0.13487942  2.96194714]\n",
      " [-1.31560338 -1.16239696  2.47814503]]\n",
      "1029000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12511398188671158\n",
      "[[ 0.88710011  0.72678006 -1.61400983]\n",
      " [ 2.06792179 -0.19830783 -1.86995615]\n",
      " [-2.82751971 -0.13501668  2.96295273]\n",
      " [-1.3160244  -1.16295752  2.47912661]]\n",
      "1030000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12506111003302664\n",
      "[[ 0.88741778  0.7269758  -1.61452324]\n",
      " [ 2.0685749  -0.19815527 -1.87076181]\n",
      " [-2.8283873  -0.13515377  2.96395741]\n",
      " [-1.31644507 -1.16351765  2.48010741]]\n",
      "1031000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1250083233943173\n",
      "[[ 0.8877352   0.72717128 -1.61503613]\n",
      " [ 2.06922744 -0.19800276 -1.87156687]\n",
      " [-2.82925416 -0.13529068  2.96496118]\n",
      " [-1.31686541 -1.16407734  2.48108744]]\n",
      "1032000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12495562175539317\n",
      "[[ 0.88805236  0.72736648 -1.61554849]\n",
      " [ 2.06987943 -0.19785029 -1.87237132]\n",
      " [-2.83012029 -0.13542743  2.96596405]\n",
      " [-1.3172854  -1.1646366   2.48206669]]\n",
      "1033000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12490300490179902\n",
      "[[ 0.88836926  0.72756142 -1.61606033]\n",
      " [ 2.07053086 -0.19769788 -1.87317516]\n",
      " [-2.83098569 -0.13556399  2.96696602]\n",
      " [-1.31770506 -1.16519543  2.48304517]]\n",
      "1034000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12485047261981241\n",
      "[[ 0.88868591  0.72775609 -1.61657165]\n",
      " [ 2.07118173 -0.19754552 -1.87397839]\n",
      " [-2.83185036 -0.13570038  2.96796708]\n",
      " [-1.31812438 -1.16575382  2.48402288]]\n",
      "1035000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1247980246964401\n",
      "[[ 0.8890023   0.72795049 -1.61708244]\n",
      " [ 2.07183204 -0.1973932  -1.87478101]\n",
      " [-2.8327143  -0.13583661  2.96896724]\n",
      " [-1.31854335 -1.16631178  2.48499982]]\n",
      "1036000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12474566091941487\n",
      "[[ 0.88931843  0.72814463 -1.61759272]\n",
      " [ 2.07248179 -0.19724094 -1.87558303]\n",
      " [-2.83357751 -0.13597265  2.9699665 ]\n",
      " [-1.318962   -1.16686932  2.485976  ]]\n",
      "1037000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12469338107719231\n",
      "[[ 0.88963431  0.7283385  -1.61810247]\n",
      " [ 2.07313099 -0.19708872 -1.87638445]\n",
      " [-2.83444    -0.13610853  2.97096486]\n",
      " [-1.3193803  -1.16742642  2.48695141]]\n",
      "1038000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12464118495894795\n",
      "[[ 0.88994994  0.72853211 -1.6186117 ]\n",
      " [ 2.07377964 -0.19693656 -1.87718526]\n",
      " [-2.83530176 -0.13624423  2.97196233]\n",
      " [-1.31979827 -1.16798309  2.48792605]]\n",
      "1039000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12458907235457453\n",
      "[[ 0.89026531  0.72872546 -1.61912042]\n",
      " [ 2.07442773 -0.19678444 -1.87798547]\n",
      " [-2.8361628  -0.13637977  2.9729589 ]\n",
      " [-1.32021591 -1.16853933  2.48889993]]\n",
      "1040000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1245370430546779\n",
      "[[ 0.89058042  0.72891854 -1.61962862]\n",
      " [ 2.07507527 -0.19663237 -1.87878507]\n",
      " [-2.83702312 -0.13651513  2.97395458]\n",
      " [-1.3206332  -1.16909515  2.48987304]]\n",
      "1041000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12448509685057497\n",
      "[[ 0.89089528  0.72911136 -1.6201363 ]\n",
      " [ 2.07572225 -0.19648036 -1.87958408]\n",
      " [-2.83788271 -0.13665032  2.97494937]\n",
      " [-1.32105017 -1.16965054  2.49084539]]\n",
      "1042000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12443323353429027\n",
      "[[ 0.89120989  0.72930392 -1.62064347]\n",
      " [ 2.07636869 -0.19632839 -1.88038248]\n",
      " [-2.83874159 -0.13678534  2.97594326]\n",
      " [-1.3214668  -1.1702055   2.49181699]]\n",
      "1043000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12438145289855287\n",
      "[[ 0.89152425  0.72949621 -1.62115012]\n",
      " [ 2.07701458 -0.19617647 -1.88118029]\n",
      " [-2.83959975 -0.13692019  2.97693627]\n",
      " [-1.3218831  -1.17076004  2.49278782]]\n",
      "1044000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12432975473679359\n",
      "[[ 0.89183835  0.72968825 -1.62165626]\n",
      " [ 2.07765992 -0.1960246  -1.8819775 ]\n",
      " [-2.84045719 -0.13705487  2.97792839]\n",
      " [-1.32229906 -1.17131415  2.4937579 ]]\n",
      "1045000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12427813884314179\n",
      "[[ 0.89215221  0.72988002 -1.62216188]\n",
      " [ 2.07830471 -0.19587279 -1.8827741 ]\n",
      " [-2.84131392 -0.13718938  2.97891963]\n",
      " [-1.32271469 -1.17186784  2.49472721]]\n",
      "1046000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12422660501242265\n",
      "[[ 0.89246581  0.73007154 -1.622667  ]\n",
      " [ 2.07894895 -0.19572102 -1.88357012]\n",
      " [-2.84216993 -0.13732372  2.97990998]\n",
      " [-1.32312999 -1.1724211   2.49569578]]\n",
      "1047000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12417515304015365\n",
      "[[ 0.89277916  0.73026279 -1.6231716 ]\n",
      " [ 2.07959265 -0.1955693  -1.88436553]\n",
      " [-2.84302522 -0.13745789  2.98089945]\n",
      " [-1.32354496 -1.17297394  2.49666359]]\n",
      "1048000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12412378272254265\n",
      "[[ 0.89309225  0.73045379 -1.6236757 ]\n",
      " [ 2.08023581 -0.19541763 -1.88516035]\n",
      " [-2.84387981 -0.1375919   2.98188804]\n",
      " [-1.3239596  -1.17352636  2.49763065]]\n",
      "1049000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12407249385648403\n",
      "[[ 0.8934051   0.73064453 -1.62417928]\n",
      " [ 2.08087841 -0.19526601 -1.88595458]\n",
      " [-2.84473368 -0.13772574  2.98287575]\n",
      " [-1.32437391 -1.17407836  2.49859695]]\n",
      "1050000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12402128623955615\n",
      "[[ 0.8937177   0.73083501 -1.62468236]\n",
      " [ 2.08152048 -0.19511445 -1.88674822]\n",
      " [-2.84558685 -0.1378594   2.98386259]\n",
      " [-1.32478789 -1.17462993  2.49956251]]\n",
      "1051000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12397015967001827\n",
      "[[ 0.89403005  0.73102523 -1.62518494]\n",
      " [ 2.08216201 -0.19496293 -1.88754126]\n",
      " [-2.8464393  -0.13799291  2.98484854]\n",
      " [-1.32520154 -1.17518109  2.50052732]]\n",
      "1052000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1239191139468079\n",
      "[[ 0.89434215  0.7312152  -1.625687  ]\n",
      " [ 2.08280299 -0.19481146 -1.88833371]\n",
      " [-2.84729105 -0.13812624  2.98583363]\n",
      " [-1.32561486 -1.17573183  2.50149137]]\n",
      "1053000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12386814886953808\n",
      "[[ 0.894654    0.73140491 -1.62618856]\n",
      " [ 2.08344343 -0.19466004 -1.88912557]\n",
      " [-2.84814209 -0.13825941  2.98681784]\n",
      " [-1.32602786 -1.17628215  2.50245469]]\n",
      "1054000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12381726423849396\n",
      "[[ 0.8949656   0.73159436 -1.62668962]\n",
      " [ 2.08408333 -0.19450868 -1.88991684]\n",
      " [-2.84899243 -0.13839241  2.98780117]\n",
      " [-1.32644052 -1.17683205  2.50341725]]\n",
      "1055000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12376645985463043\n",
      "[[ 0.89527696  0.73178356 -1.62719018]\n",
      " [ 2.0847227  -0.19435736 -1.89070752]\n",
      " [-2.84984206 -0.13852524  2.98878364]\n",
      " [-1.32685286 -1.17738153  2.50437908]]\n",
      "1056000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12371573551956906\n",
      "[[ 0.89558807  0.73197251 -1.62769023]\n",
      " [ 2.08536153 -0.19420609 -1.89149761]\n",
      " [-2.85069099 -0.13865791  2.98976524]\n",
      " [-1.32726488 -1.1779306   2.50534016]]\n",
      "1057000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12366509103559563\n",
      "[[ 0.89589893  0.7321612  -1.62818978]\n",
      " [ 2.08599982 -0.19405488 -1.89228712]\n",
      " [-2.85153922 -0.13879041  2.99074597]\n",
      " [-1.32767656 -1.17847925  2.5063005 ]]\n",
      "1058000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12361452620565676\n",
      "[[ 0.89620954  0.73234964 -1.62868883]\n",
      " [ 2.08663757 -0.19390371 -1.89307604]\n",
      " [-2.85238675 -0.13892275  2.99172584]\n",
      " [-1.32808793 -1.17902748  2.50726009]]\n",
      "1059000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12356404083335766\n",
      "[[ 0.89651991  0.73253782 -1.62918739]\n",
      " [ 2.08727479 -0.1937526  -1.89386437]\n",
      " [-2.85323358 -0.13905493  2.99270484]\n",
      " [-1.32849896 -1.1795753   2.50821895]]\n",
      "1060000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12351363472295906\n",
      "[[ 0.89683003  0.73272575 -1.62968544]\n",
      " [ 2.08791148 -0.19360154 -1.89465212]\n",
      " [-2.85407971 -0.13918693  2.99368298]\n",
      " [-1.32890968 -1.18012271  2.50917708]]\n",
      "1061000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12346330767937455\n",
      "[[ 0.89713991  0.73291344 -1.630183  ]\n",
      " [ 2.08854763 -0.19345052 -1.89543929]\n",
      " [-2.85492515 -0.13931878  2.99466026]\n",
      " [-1.32932007 -1.1806697   2.51013446]]\n",
      "1062000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12341305950816794\n",
      "[[ 0.89744954  0.73310086 -1.63068006]\n",
      " [ 2.08918325 -0.19329956 -1.89622587]\n",
      " [-2.85576989 -0.13945046  2.99563668]\n",
      " [-1.32973014 -1.18121629  2.51109111]]\n",
      "1063000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1233628900155507\n",
      "[[ 0.89775893  0.73328804 -1.63117663]\n",
      " [ 2.08981834 -0.19314865 -1.89701187]\n",
      " [-2.85661393 -0.13958198  2.99661224]\n",
      " [-1.33013988 -1.18176246  2.51204702]]\n",
      "1064000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12331279900837833\n",
      "[[ 0.89806807  0.73347497 -1.6316727 ]\n",
      " [ 2.0904529  -0.19299779 -1.89779729]\n",
      " [-2.85745728 -0.13971333  2.99758694]\n",
      " [-1.33054931 -1.18230821  2.51300221]]\n",
      "1065000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1232627862941488\n",
      "[[ 0.89837697  0.73366165 -1.63216828]\n",
      " [ 2.09108693 -0.19284698 -1.89858213]\n",
      " [-2.85829994 -0.13984452  2.99856079]\n",
      " [-1.33095841 -1.18285356  2.51395666]]\n",
      "1066000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12321285168099927\n",
      "[[ 0.89868563  0.73384808 -1.63266336]\n",
      " [ 2.09172043 -0.19269622 -1.89936639]\n",
      " [-2.85914191 -0.13997555  2.99953379]\n",
      " [-1.33136719 -1.1833985   2.51491037]]\n",
      "1067000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12316299497770357\n",
      "[[ 0.89899404  0.73403426 -1.63315795]\n",
      " [ 2.0923534  -0.19254551 -1.90015007]\n",
      " [-2.85998318 -0.14010641  3.00050593]\n",
      " [-1.33177565 -1.18394303  2.51586336]]\n",
      "1068000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12311321599366956\n",
      "[[ 0.89930221  0.73422019 -1.63365206]\n",
      " [ 2.09298585 -0.19239486 -1.90093317]\n",
      " [-2.86082377 -0.14023712  3.00147722]\n",
      " [-1.33218379 -1.18448715  2.51681563]]\n",
      "1069000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12306351453893617\n",
      "[[ 0.89961014  0.73440588 -1.63414567]\n",
      " [ 2.09361777 -0.19224425 -1.9017157 ]\n",
      " [-2.86166367 -0.14036766  3.00244767]\n",
      " [-1.33259161 -1.18503086  2.51776716]]\n",
      "1070000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12301389042417132\n",
      "[[ 0.89991782  0.73459132 -1.63463879]\n",
      " [ 2.09424917 -0.1920937  -1.90249765]\n",
      " [-2.86250289 -0.14049804  3.00341726]\n",
      " [-1.33299911 -1.18557417  2.51871797]]\n",
      "1071000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12296434346066874\n",
      "[[ 0.90022527  0.73477651 -1.63513143]\n",
      " [ 2.09488004 -0.19194319 -1.90327903]\n",
      " [-2.86334142 -0.14062826  3.00438601]\n",
      " [-1.3334063  -1.18611707  2.51966805]]\n",
      "1072000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1229148734603461\n",
      "[[ 0.90053247  0.73496145 -1.63562358]\n",
      " [ 2.09551039 -0.19179274 -1.90405983]\n",
      " [-2.86417926 -0.14075832  3.00535392]\n",
      " [-1.33381316 -1.18665956  2.52061741]]\n",
      "1073000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12286548023574163\n",
      "[[ 0.90083943  0.73514615 -1.63611524]\n",
      " [ 2.09614021 -0.19164234 -1.90484005]\n",
      " [-2.86501643 -0.14088822  3.00632098]\n",
      " [-1.33421971 -1.18720165  2.52156605]]\n",
      "1074000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12281616360001175\n",
      "[[ 0.90114615  0.7353306  -1.63660641]\n",
      " [ 2.09676952 -0.19149199 -1.90561971]\n",
      " [-2.86585291 -0.14101796  3.00728719]\n",
      " [-1.33462595 -1.18774333  2.52251397]]\n",
      "1075000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12276692336692895\n",
      "[[ 0.90145264  0.73551481 -1.63709711]\n",
      " [ 2.0973983  -0.19134169 -1.90639879]\n",
      " [-2.86668871 -0.14114753  3.00825257]\n",
      " [-1.33503186 -1.18828461  2.52346116]]\n",
      "1076000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1227177593508786\n",
      "[[ 0.90175888  0.73569878 -1.63758731]\n",
      " [ 2.09802657 -0.19119145 -1.9071773 ]\n",
      " [-2.86752383 -0.14127695  3.00921711]\n",
      " [-1.33543746 -1.18882549  2.52440764]]\n",
      "1077000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12266867136685687\n",
      "[[ 0.90206488  0.7358825  -1.63807704]\n",
      " [ 2.09865431 -0.19104125 -1.90795524]\n",
      " [-2.86835827 -0.14140621  3.01018081]\n",
      " [-1.33584275 -1.18936597  2.5253534 ]]\n",
      "1078000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12261965923046816\n",
      "[[ 0.90237065  0.73606598 -1.63856628]\n",
      " [ 2.09928154 -0.19089111 -1.90873261]\n",
      " [-2.86919203 -0.14153531  3.01114368]\n",
      " [-1.33624772 -1.18990604  2.52629844]]\n",
      "1079000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12257072275792234\n",
      "[[ 0.90267617  0.73624922 -1.63905504]\n",
      " [ 2.09990825 -0.19074102 -1.90950941]\n",
      " [-2.87002512 -0.14166425  3.01210571]\n",
      " [-1.33665237 -1.19044571  2.52724277]]\n",
      "1080000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12252186176603251\n",
      "[[ 0.90298146  0.73643221 -1.63954333]\n",
      " [ 2.10053444 -0.19059098 -1.91028564]\n",
      " [-2.87085753 -0.14179304  3.0130669 ]\n",
      " [-1.33705672 -1.19098498  2.52818638]]\n",
      "1081000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1224730760722121\n",
      "[[ 0.90328651  0.73661496 -1.64003113]\n",
      " [ 2.10116012 -0.19044099 -1.91106131]\n",
      " [-2.87168927 -0.14192166  3.01402727]\n",
      " [-1.33746075 -1.19152385  2.52912929]]\n",
      "1082000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12242436549447296\n",
      "[[ 0.90359133  0.73679747 -1.64051845]\n",
      " [ 2.10178528 -0.19029105 -1.91183641]\n",
      " [-2.87252033 -0.14205013  3.0149868 ]\n",
      " [-1.33786446 -1.19206232  2.53007147]]\n",
      "1083000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12237572985142246\n",
      "[[ 0.9038959   0.73697974 -1.6410053 ]\n",
      " [ 2.10240993 -0.19014116 -1.91261095]\n",
      " [-2.87335073 -0.14217844  3.0159455 ]\n",
      " [-1.33826787 -1.1926004   2.53101295]]\n",
      "1084000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12232716896226137\n",
      "[[ 0.90420024  0.73716177 -1.64149167]\n",
      " [ 2.10303407 -0.18999133 -1.91338492]\n",
      " [-2.87418045 -0.1423066   3.01690338]\n",
      " [-1.33867096 -1.19313807  2.53195372]]\n",
      "1085000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12227868264678103\n",
      "[[ 0.90450435  0.73734356 -1.64197756]\n",
      " [ 2.10365769 -0.18984155 -1.91415832]\n",
      " [-2.8750095  -0.14243459  3.01786043]\n",
      " [-1.33907374 -1.19367535  2.53289378]]\n",
      "1086000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12223027072536122\n",
      "[[ 0.90480821  0.73752512 -1.64246298]\n",
      " [ 2.10428081 -0.18969182 -1.91493117]\n",
      " [-2.87583789 -0.14256243  3.01881665]\n",
      " [-1.33947622 -1.19421223  2.53383313]]\n",
      "1087000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12218193301896765\n",
      "[[ 0.90511185  0.73770643 -1.64294793]\n",
      " [ 2.10490341 -0.18954214 -1.91570345]\n",
      " [-2.8766656  -0.14269012  3.01977205]\n",
      " [-1.33987838 -1.19474872  2.53477178]]\n",
      "1088000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12213366934914949\n",
      "[[ 0.90541524  0.7378875  -1.6434324 ]\n",
      " [ 2.1055255  -0.18939251 -1.91647517]\n",
      " [-2.87749265 -0.14281765  3.02072663]\n",
      " [-1.34028023 -1.19528481  2.53570972]]\n",
      "1089000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12208547953803728\n",
      "[[ 0.90571841  0.73806834 -1.6439164 ]\n",
      " [ 2.10614709 -0.18924294 -1.91724633]\n",
      " [-2.87831904 -0.14294502  3.02168039]\n",
      " [-1.34068177 -1.1958205   2.53664696]]\n",
      "1090000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12203736340834015\n",
      "[[ 0.90602134  0.73824894 -1.64439993]\n",
      " [ 2.10676816 -0.18909342 -1.91801693]\n",
      " [-2.87914476 -0.14307223  3.02263333]\n",
      " [-1.341083   -1.1963558   2.53758349]]\n",
      "1091000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12198932078334347\n",
      "[[ 0.90632403  0.7384293  -1.64488299]\n",
      " [ 2.10738873 -0.18894395 -1.91878697]\n",
      " [-2.87996982 -0.1431993   3.02358545]\n",
      " [-1.34148393 -1.19689071  2.53851933]]\n",
      "1092000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12194135148690684\n",
      "[[ 0.90662649  0.73860943 -1.64536558]\n",
      " [ 2.1080088  -0.18879453 -1.91955645]\n",
      " [-2.88079421 -0.1433262   3.02453675]\n",
      " [-1.34188455 -1.19742523  2.53945446]]\n",
      "1093000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12189345534346141\n",
      "[[ 0.90692872  0.73878932 -1.6458477 ]\n",
      " [ 2.10862836 -0.18864516 -1.92032537]\n",
      " [-2.88161795 -0.14345296  3.02548724]\n",
      " [-1.34228486 -1.19795935  2.54038889]]\n",
      "1094000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12184563217800767\n",
      "[[ 0.90723072  0.73896898 -1.64632935]\n",
      " [ 2.10924741 -0.18849585 -1.92109374]\n",
      " [-2.88244102 -0.14357956  3.02643691]\n",
      " [-1.34268486 -1.19849308  2.54132263]]\n",
      "1095000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1217978818161135\n",
      "[[ 0.90753248  0.7391484  -1.64681053]\n",
      " [ 2.10986596 -0.18834659 -1.92186155]\n",
      " [-2.88326344 -0.143706    3.02738577]\n",
      " [-1.34308456 -1.19902642  2.54225566]]\n",
      "1096000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12175020408391096\n",
      "[[ 0.90783401  0.73932758 -1.64729125]\n",
      " [ 2.11048401 -0.18819738 -1.92262881]\n",
      " [-2.8840852  -0.14383229  3.02833382]\n",
      " [-1.34348395 -1.19955937  2.54318801]]\n",
      "1097000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12170259880809482\n",
      "[[ 0.90813531  0.73950654 -1.6477715 ]\n",
      " [ 2.11110155 -0.18804822 -1.92339551]\n",
      " [-2.8849063  -0.14395843  3.02928106]\n",
      " [-1.34388304 -1.20009193  2.54411965]]\n",
      "1098000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12165506581591973\n",
      "[[ 0.90843638  0.73968526 -1.64825129]\n",
      " [ 2.1117186  -0.18789912 -1.92416166]\n",
      " [-2.88572674 -0.14408442  3.03022749]\n",
      " [-1.34428182 -1.2006241   2.54505061]]\n",
      "1099000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12160760493519855\n",
      "[[ 0.90873721  0.73986374 -1.64873061]\n",
      " [ 2.11233514 -0.18775006 -1.92492726]\n",
      " [-2.88654654 -0.14421025  3.03117312]\n",
      " [-1.3446803  -1.20115588  2.54598087]]\n",
      "1100000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12156021599429946\n",
      "[[ 0.90903782  0.740042   -1.64920947]\n",
      " [ 2.11295119 -0.18760106 -1.9256923 ]\n",
      " [-2.88736567 -0.14433593  3.03211794]\n",
      " [-1.34507847 -1.20168727  2.54691043]]\n",
      "1101000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12151289882214394\n",
      "[[ 0.9093382   0.74022002 -1.64968787]\n",
      " [ 2.11356673 -0.18745212 -1.9264568 ]\n",
      " [-2.88818416 -0.14446146  3.03306195]\n",
      " [-1.34547635 -1.20221828  2.54783931]]\n",
      "1102000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12146565324820453\n",
      "[[ 0.90963834  0.74039781 -1.65016581]\n",
      " [ 2.11418178 -0.18730322 -1.92722074]\n",
      " [-2.88900199 -0.14458683  3.03400516]\n",
      " [-1.34587391 -1.2027489   2.5487675 ]]\n",
      "1103000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12141847910250289\n",
      "[[ 0.90993826  0.74057537 -1.65064328]\n",
      " [ 2.11479633 -0.18715438 -1.92798413]\n",
      " [-2.88981918 -0.14471206  3.03494757]\n",
      " [-1.34627118 -1.20327913  2.549695  ]]\n",
      "1104000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12137137621560702\n",
      "[[ 0.91023795  0.7407527  -1.6511203 ]\n",
      " [ 2.11541038 -0.18700559 -1.92874698]\n",
      " [-2.89063571 -0.14483713  3.03588918]\n",
      " [-1.34666814 -1.20380898  2.55062181]]\n",
      "1105000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12132434441862938\n",
      "[[ 0.91053741  0.7409298  -1.65159686]\n",
      " [ 2.11602394 -0.18685685 -1.92950927]\n",
      " [-2.8914516  -0.14496205  3.03682998]\n",
      " [-1.34706481 -1.20433845  2.55154794]]\n",
      "1106000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12127738354322422\n",
      "[[ 0.91083664  0.74110667 -1.65207296]\n",
      " [ 2.116637   -0.18670816 -1.93027102]\n",
      " [-2.89226684 -0.14508682  3.03776999]\n",
      " [-1.34746117 -1.20486753  2.55247338]]\n",
      "1107000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.121230493421587\n",
      "[[ 0.91113564  0.74128331 -1.6525486 ]\n",
      " [ 2.11724957 -0.18655953 -1.93103222]\n",
      " [-2.89308143 -0.14521145  3.03870921]\n",
      " [-1.34785723 -1.20539622  2.55339814]]\n",
      "1108000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12118367388644974\n",
      "[[ 0.91143441  0.74145972 -1.65302379]\n",
      " [ 2.11786165 -0.18641095 -1.93179288]\n",
      " [-2.89389538 -0.14533592  3.03964763]\n",
      " [-1.34825299 -1.20592454  2.55432221]]\n",
      "1109000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12113692477108076\n",
      "[[ 0.91173296  0.7416359  -1.65349852]\n",
      " [ 2.11847323 -0.18626242 -1.93255299]\n",
      " [-2.89470868 -0.14546024  3.04058525]\n",
      " [-1.34864845 -1.20645247  2.5552456 ]]\n",
      "1110000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12109024590928184\n",
      "[[ 0.91203128  0.74181186 -1.65397279]\n",
      " [ 2.11908433 -0.18611395 -1.93331256]\n",
      " [-2.89552134 -0.14558441  3.04152208]\n",
      " [-1.34904362 -1.20698001  2.55616832]]\n",
      "1111000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12104363713538585\n",
      "[[ 0.91232937  0.74198759 -1.65444661]\n",
      " [ 2.11969493 -0.18596553 -1.93407158]\n",
      " [-2.89633336 -0.14570843  3.04245813]\n",
      " [-1.34943848 -1.20750718  2.55709035]]\n",
      "1112000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1209970982842548\n",
      "[[ 0.91262724  0.74216309 -1.65491998]\n",
      " [ 2.12030504 -0.18581716 -1.93483006]\n",
      " [-2.89714474 -0.14583231  3.04339338]\n",
      " [-1.34983305 -1.20803397  2.5580117 ]]\n",
      "1113000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12095062919127846\n",
      "[[ 0.91292488  0.74233836 -1.6553929 ]\n",
      " [ 2.12091466 -0.18566884 -1.935588  ]\n",
      " [-2.89795548 -0.14595603  3.04432784]\n",
      " [-1.35022732 -1.20856038  2.55893238]]\n",
      "1114000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1209042296923711\n",
      "[[ 0.9132223   0.74251341 -1.65586536]\n",
      " [ 2.1215238  -0.18552058 -1.9363454 ]\n",
      " [-2.89876557 -0.14607961  3.04526151]\n",
      " [-1.35062129 -1.2090864   2.55985238]]\n",
      "1115000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1208578996239698\n",
      "[[ 0.91351949  0.74268824 -1.65633738]\n",
      " [ 2.12213245 -0.18537237 -1.93710226]\n",
      " [-2.89957503 -0.14620303  3.0461944 ]\n",
      " [-1.35101496 -1.20961205  2.5607717 ]]\n",
      "1116000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12081163882303239\n",
      "[[ 0.91381645  0.74286283 -1.65680894]\n",
      " [ 2.12274061 -0.18522421 -1.93785858]\n",
      " [-2.90038386 -0.14632631  3.04712651]\n",
      " [-1.35140834 -1.21013732  2.56169035]]\n",
      "1117000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1207654471270357\n",
      "[[ 0.91411319  0.74303721 -1.65728006]\n",
      " [ 2.12334828 -0.18507611 -1.93861436]\n",
      " [-2.90119205 -0.14644945  3.04805783]\n",
      " [-1.35180142 -1.21066222  2.56260833]]\n",
      "1118000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1207193243739729\n",
      "[[ 0.91440971  0.74321136 -1.65775072]\n",
      " [ 2.12395547 -0.18492805 -1.9393696 ]\n",
      " [-2.9019996  -0.14657243  3.04898837]\n",
      " [-1.35219421 -1.21118673  2.56352563]]\n",
      "1119000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1206732704023517\n",
      "[[ 0.914706    0.74338528 -1.65822094]\n",
      " [ 2.12456218 -0.18478006 -1.9401243 ]\n",
      " [-2.90280652 -0.14669527  3.04991812]\n",
      " [-1.35258671 -1.21171087  2.56444226]]\n",
      "1120000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12062728505119241\n",
      "[[ 0.91500207  0.74355899 -1.65869071]\n",
      " [ 2.1251684  -0.18463211 -1.94087847]\n",
      " [-2.90361281 -0.14681796  3.0508471 ]\n",
      " [-1.3529789  -1.21223464  2.56535823]]\n",
      "1121000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12058136816002564\n",
      "[[ 0.91529792  0.74373247 -1.65916004]\n",
      " [ 2.12577413 -0.18448422 -1.9416321 ]\n",
      " [-2.90441846 -0.14694051  3.0517753 ]\n",
      " [-1.35337081 -1.21275802  2.56627352]]\n",
      "1122000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12053551956889057\n",
      "[[ 0.91559354  0.74390572 -1.65962892]\n",
      " [ 2.12637939 -0.18433638 -1.94238519]\n",
      " [-2.90522348 -0.1470629   3.05270272]\n",
      " [-1.35376242 -1.21328104  2.56718814]]\n",
      "1123000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12048973911833254\n",
      "[[ 0.91588894  0.74407876 -1.66009736]\n",
      " [ 2.12698417 -0.18418859 -1.94313775]\n",
      " [-2.90602788 -0.14718516  3.05362937]\n",
      " [-1.35415374 -1.21380368  2.5681021 ]]\n",
      "1124000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12044402664940139\n",
      "[[ 0.91618412  0.74425157 -1.66056535]\n",
      " [ 2.12758846 -0.18404086 -1.94388978]\n",
      " [-2.90683164 -0.14730726  3.05455524]\n",
      " [-1.35454477 -1.21432594  2.56901539]]\n",
      "1125000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12039838200364907\n",
      "[[ 0.91647908  0.74442417 -1.6610329 ]\n",
      " [ 2.12819227 -0.18389318 -1.94464127]\n",
      " [-2.90763478 -0.14742923  3.05548034]\n",
      " [-1.3549355  -1.21484784  2.56992802]]\n",
      "1126000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12035280502312837\n",
      "[[ 0.91677381  0.74459654 -1.66150001]\n",
      " [ 2.12879561 -0.18374555 -1.94539224]\n",
      " [-2.90843729 -0.14755104  3.05640467]\n",
      " [-1.35532594 -1.21536936  2.57083999]]\n",
      "1127000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12030729555038995\n",
      "[[ 0.91706833  0.74476869 -1.66196667]\n",
      " [ 2.12939847 -0.18359798 -1.94614267]\n",
      " [-2.90923918 -0.14767271  3.05732822]\n",
      " [-1.35571609 -1.21589051  2.57175129]]\n",
      "1128000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12026185342848104\n",
      "[[ 0.91736262  0.74494062 -1.6624329 ]\n",
      " [ 2.13000085 -0.18345046 -1.94689257]\n",
      " [-2.91004044 -0.14779424  3.05825101]\n",
      " [-1.35610596 -1.21641128  2.57266192]]\n",
      "1129000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1202164785009433\n",
      "[[ 0.91765669  0.74511234 -1.66289869]\n",
      " [ 2.13060275 -0.18330299 -1.94764194]\n",
      " [-2.91084107 -0.14791562  3.05917303]\n",
      " [-1.35649553 -1.21693169  2.5735719 ]]\n",
      "1130000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1201711706118108\n",
      "[[ 0.91795055  0.74528383 -1.66336403]\n",
      " [ 2.13120418 -0.18315558 -1.94839078]\n",
      " [-2.91164109 -0.14803686  3.06009428]\n",
      " [-1.35688481 -1.21745173  2.57448122]]\n",
      "1131000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1201259296056079\n",
      "[[ 0.91824418  0.74545511 -1.66382894]\n",
      " [ 2.13180513 -0.18300822 -1.94913909]\n",
      " [-2.91244048 -0.14815795  3.06101477]\n",
      " [-1.3572738  -1.2179714   2.57538988]]\n",
      "1132000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12008075532734781\n",
      "[[ 0.91853759  0.74562616 -1.66429341]\n",
      " [ 2.13240561 -0.18286091 -1.94988687]\n",
      " [-2.91323925 -0.14827891  3.06193449]\n",
      " [-1.3576625  -1.21849069  2.57629788]]\n",
      "1133000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.12003564762253043\n",
      "[[ 0.91883079  0.74579701 -1.66475745]\n",
      " [ 2.13300561 -0.18271366 -1.95063413]\n",
      " [-2.9140374  -0.14839971  3.06285344]\n",
      " [-1.35805092 -1.21900962  2.57720523]]\n",
      "1134000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11999060633714013\n",
      "[[ 0.91912377  0.74596763 -1.66522105]\n",
      " [ 2.13360514 -0.18256646 -1.95138086]\n",
      " [-2.91483493 -0.14852038  3.06377164]\n",
      " [-1.35843904 -1.21952819  2.57811191]]\n",
      "1135000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11994563131764399\n",
      "[[ 0.91941652  0.74613803 -1.66568421]\n",
      " [ 2.1342042  -0.18241931 -1.95212707]\n",
      " [-2.91563184 -0.1486409   3.06468908]\n",
      " [-1.35882688 -1.22004638  2.57901795]]\n",
      "1136000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11990072241099033\n",
      "[[ 0.91970906  0.74630823 -1.66614694]\n",
      " [ 2.13480279 -0.18227222 -1.95287275]\n",
      " [-2.91642814 -0.14876128  3.06560575]\n",
      " [-1.35921443 -1.22056421  2.57992333]]\n",
      "1137000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11985587946460591\n",
      "[[ 0.92000138  0.7464782  -1.66660924]\n",
      " [ 2.1354009  -0.18212518 -1.9536179 ]\n",
      " [-2.91722382 -0.14888152  3.06652167]\n",
      " [-1.3596017  -1.22108167  2.58082806]]\n",
      "1138000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11981110232639527\n",
      "[[ 0.92029349  0.74664796 -1.6670711 ]\n",
      " [ 2.13599855 -0.1819782  -1.95436253]\n",
      " [-2.91801888 -0.14900161  3.06743683]\n",
      " [-1.35998868 -1.22159877  2.58173213]]\n",
      "1139000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11976639084473736\n",
      "[[ 0.92058538  0.7468175  -1.66753253]\n",
      " [ 2.13659573 -0.18183127 -1.95510664]\n",
      " [-2.91881334 -0.14912156  3.06835123]\n",
      " [-1.36037537 -1.2221155   2.58263556]]\n",
      "1140000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11972174486848534\n",
      "[[ 0.92087705  0.74698683 -1.66799353]\n",
      " [ 2.13719244 -0.18168439 -1.95585023]\n",
      " [-2.91960717 -0.14924138  3.06926488]\n",
      " [-1.36076178 -1.22263187  2.58353833]]\n",
      "1141000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11967716424696301\n",
      "[[ 0.9211685   0.74715595 -1.6684541 ]\n",
      " [ 2.13778868 -0.18153756 -1.9565933 ]\n",
      " [-2.9204004  -0.14936105  3.07017778]\n",
      " [-1.3611479  -1.22314787  2.58444046]]\n",
      "1142000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11963264882996448\n",
      "[[ 0.92145974  0.74732485 -1.66891424]\n",
      " [ 2.13838445 -0.18139079 -1.95733584]\n",
      " [-2.92119302 -0.14948058  3.07108992]\n",
      " [-1.36153374 -1.22366352  2.58534194]]\n",
      "1143000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11958819846775152\n",
      "[[ 0.92175076  0.74749354 -1.66937395]\n",
      " [ 2.13897976 -0.18124407 -1.95807787]\n",
      " [-2.92198502 -0.14959996  3.07200132]\n",
      " [-1.36191929 -1.22417879  2.58624277]]\n",
      "1144000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11954381301105159\n",
      "[[ 0.92204157  0.74766201 -1.66983323]\n",
      " [ 2.1395746  -0.18109741 -1.95881937]\n",
      " [-2.92277641 -0.14971921  3.07291196]\n",
      " [-1.36230456 -1.22469371  2.58714296]]\n",
      "1145000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11949949231105629\n",
      "[[ 0.92233216  0.74783027 -1.67029209]\n",
      " [ 2.14016898 -0.1809508  -1.95956036]\n",
      " [-2.9235672  -0.14983832  3.07382186]\n",
      " [-1.36268955 -1.22520826  2.5880425 ]]\n",
      "1146000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11945523621941997\n",
      "[[ 0.92262254  0.74799833 -1.67075052]\n",
      " [ 2.1407629  -0.18080424 -1.96030083]\n",
      " [-2.92435738 -0.14995729  3.074731  ]\n",
      " [-1.36307426 -1.22572246  2.5889414 ]]\n",
      "1147000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11941104458825706\n",
      "[[ 0.9229127   0.74816616 -1.67120852]\n",
      " [ 2.14135635 -0.18065774 -1.96104079]\n",
      " [-2.92514695 -0.15007612  3.07563941]\n",
      " [-1.36345868 -1.22623629  2.58983965]]\n",
      "1148000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11936691727014086\n",
      "[[ 0.92320265  0.74833379 -1.67166609]\n",
      " [ 2.14194933 -0.18051129 -1.96178022]\n",
      " [-2.92593592 -0.15019481  3.07654706]\n",
      " [-1.36384282 -1.22674976  2.59073727]]\n",
      "1149000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11932285411810142\n",
      "[[ 0.92349238  0.74850121 -1.67212324]\n",
      " [ 2.14254186 -0.1803649  -1.96251914]\n",
      " [-2.92672428 -0.15031336  3.07745398]\n",
      " [-1.36422668 -1.22726288  2.59163424]]\n",
      "1150000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11927885498562446\n",
      "[[ 0.9237819   0.74866842 -1.67257997]\n",
      " [ 2.14313393 -0.18021856 -1.96325755]\n",
      " [-2.92751204 -0.15043177  3.07836015]\n",
      " [-1.36461026 -1.22777563  2.59253057]]\n",
      "1151000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11923491972664815\n",
      "[[ 0.92407121  0.74883541 -1.67303628]\n",
      " [ 2.14372553 -0.18007227 -1.96399544]\n",
      " [-2.9282992  -0.15055004  3.07926557]\n",
      " [-1.36499356 -1.22828803  2.59342627]]\n",
      "1152000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.119191048195563\n",
      "[[ 0.9243603   0.7490022  -1.67349216]\n",
      " [ 2.14431668 -0.17992604 -1.96473282]\n",
      " [-2.92908576 -0.15066817  3.08017026]\n",
      " [-1.36537657 -1.22880006  2.59432132]]\n",
      "1153000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1191472402472094\n",
      "[[ 0.92464919  0.74916878 -1.67394762]\n",
      " [ 2.14490736 -0.17977986 -1.96546968]\n",
      " [-2.92987171 -0.15078617  3.08107421]\n",
      " [-1.36575931 -1.22931175  2.59521574]]\n",
      "1154000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11910349573687529\n",
      "[[ 0.92493786  0.74933515 -1.67440266]\n",
      " [ 2.14549759 -0.17963373 -1.96620604]\n",
      " [-2.93065706 -0.15090403  3.08197743]\n",
      " [-1.36614177 -1.22982307  2.59610953]]\n",
      "1155000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11905981452029515\n",
      "[[ 0.92522631  0.74950131 -1.67485728]\n",
      " [ 2.14608736 -0.17948766 -1.96694188]\n",
      " [-2.93144182 -0.15102175  3.0828799 ]\n",
      " [-1.36652395 -1.23033404  2.59700267]]\n",
      "1156000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11901619645364851\n",
      "[[ 0.92551456  0.74966726 -1.67531147]\n",
      " [ 2.14667667 -0.17934164 -1.96767721]\n",
      " [-2.93222598 -0.15113933  3.08378164]\n",
      " [-1.36690585 -1.23084465  2.59789519]]\n",
      "1157000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11897264139355712\n",
      "[[ 0.9258026   0.749833   -1.67576525]\n",
      " [ 2.14726553 -0.17919568 -1.96841203]\n",
      " [-2.93300954 -0.15125678  3.08468265]\n",
      " [-1.36728748 -1.23135491  2.59878707]]\n",
      "1158000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11892914919708422\n",
      "[[ 0.92609042  0.74999854 -1.67621862]\n",
      " [ 2.14785393 -0.17904977 -1.96914634]\n",
      " [-2.9337925  -0.15137408  3.08558292]\n",
      " [-1.36766882 -1.23186481  2.59967832]]\n",
      "1159000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11888571972173262\n",
      "[[ 0.92637803  0.75016387 -1.67667156]\n",
      " [ 2.14844188 -0.17890392 -1.96988014]\n",
      " [-2.93457487 -0.15149126  3.08648246]\n",
      " [-1.36804989 -1.23237436  2.60056894]]\n",
      "1160000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11884235282544267\n",
      "[[ 0.92666544  0.750329   -1.67712409]\n",
      " [ 2.14902937 -0.17875812 -1.97061344]\n",
      " [-2.93535664 -0.15160829  3.08738127]\n",
      " [-1.36843068 -1.23288356  2.60145893]]\n",
      "1161000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11879904836659089\n",
      "[[ 0.92695263  0.75049392 -1.6775762 ]\n",
      " [ 2.14961641 -0.17861237 -1.97134622]\n",
      " [-2.93613782 -0.15172519  3.08827935]\n",
      " [-1.3688112  -1.2333924   2.60234828]]\n",
      "1162000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11875580620398805\n",
      "[[ 0.92723961  0.75065863 -1.6780279 ]\n",
      " [ 2.150203   -0.17846668 -1.9720785 ]\n",
      " [-2.93691841 -0.15184196  3.0891767 ]\n",
      " [-1.36919144 -1.23390089  2.60323701]]\n",
      "1163000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11871262619687797\n",
      "[[ 0.92752639  0.75082314 -1.67847918]\n",
      " [ 2.15078914 -0.17832104 -1.97281028]\n",
      " [-2.93769841 -0.15195858  3.09007333]\n",
      " [-1.3695714  -1.23440903  2.60412512]]\n",
      "1164000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11866950820493515\n",
      "[[ 0.92781295  0.75098744 -1.67893005]\n",
      " [ 2.15137482 -0.17817545 -1.97354155]\n",
      " [-2.93847781 -0.15207508  3.09096922]\n",
      " [-1.36995109 -1.23491681  2.60501259]]\n",
      "1165000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11862645208826356\n",
      "[[ 0.92809931  0.75115154 -1.67938051]\n",
      " [ 2.15196005 -0.17802992 -1.97427231]\n",
      " [-2.93925663 -0.15219143  3.0918644 ]\n",
      " [-1.37033051 -1.23542425  2.60589944]]\n",
      "1166000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11858345770739499\n",
      "[[ 0.92838546  0.75131544 -1.67983055]\n",
      " [ 2.15254484 -0.17788445 -1.97500257]\n",
      " [-2.94003486 -0.15230766  3.09275885]\n",
      " [-1.37070965 -1.23593134  2.60678567]]\n",
      "1167000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11854052492328729\n",
      "[[ 0.9286714   0.75147913 -1.68028018]\n",
      " [ 2.15312917 -0.17773902 -1.97573233]\n",
      " [-2.9408125  -0.15242374  3.09365257]\n",
      " [-1.37108852 -1.23643807  2.60767127]]\n",
      "1168000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1184976535973226\n",
      "[[ 0.92895713  0.75164262 -1.6807294 ]\n",
      " [ 2.15371306 -0.17759366 -1.97646158]\n",
      " [-2.94158955 -0.1525397   3.09454558]\n",
      " [-1.37146711 -1.23694446  2.60855625]]\n",
      "1169000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11845484359130586\n",
      "[[ 0.92924266  0.7518059  -1.68117821]\n",
      " [ 2.1542965  -0.17744834 -1.97719034]\n",
      " [-2.94236602 -0.15265551  3.09543786]\n",
      " [-1.37184543 -1.2374505   2.60944061]]\n",
      "1170000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11841209476746328\n",
      "[[ 0.92952797  0.75196898 -1.68162661]\n",
      " [ 2.15487949 -0.17730308 -1.97791859]\n",
      " [-2.9431419  -0.1527712   3.09632943]\n",
      " [-1.37222348 -1.23795619  2.61032435]]\n",
      "1171000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11836940698844084\n",
      "[[ 0.92981308  0.75213187 -1.6820746 ]\n",
      " [ 2.15546204 -0.17715788 -1.97864634]\n",
      " [-2.94391719 -0.15288675  3.09722028]\n",
      " [-1.37260125 -1.23846153  2.61120747]]\n",
      "1172000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11832678011730205\n",
      "[[ 0.93009799  0.75229454 -1.68252219]\n",
      " [ 2.15604414 -0.17701273 -1.97937359]\n",
      " [-2.94469191 -0.15300217  3.09811041]\n",
      " [-1.37297876 -1.23896652  2.61208997]]\n",
      "1173000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11828421401752696\n",
      "[[ 0.93038269  0.75245702 -1.68296936]\n",
      " [ 2.1566258  -0.17686763 -1.98010034]\n",
      " [-2.94546604 -0.15311745  3.09899982]\n",
      " [-1.37335599 -1.23947117  2.61297185]]\n",
      "1174000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11824170855301058\n",
      "[[ 0.93066718  0.7526193  -1.68341613]\n",
      " [ 2.15720701 -0.17672259 -1.9808266 ]\n",
      " [-2.94623958 -0.1532326   3.09988852]\n",
      " [-1.37373295 -1.23997548  2.61385311]]\n",
      "1175000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11819926358806067\n",
      "[[ 0.93095146  0.75278138 -1.6838625 ]\n",
      " [ 2.15778777 -0.1765776  -1.98155235]\n",
      " [-2.94701255 -0.15334762  3.10077651]\n",
      " [-1.37410964 -1.24047943  2.61473376]]\n",
      "1176000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11815687898739663\n",
      "[[ 0.93123555  0.75294325 -1.68430845]\n",
      " [ 2.1583681  -0.17643267 -1.98227761]\n",
      " [-2.94778494 -0.15346251  3.10166378]\n",
      " [-1.37448607 -1.24098304  2.61561379]]\n",
      "1177000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1181145546161485\n",
      "[[ 0.93151942  0.75310493 -1.68475401]\n",
      " [ 2.15894798 -0.17628779 -1.98300237]\n",
      " [-2.94855675 -0.15357726  3.10255034]\n",
      " [-1.37486222 -1.24148631  2.61649321]]\n",
      "1178000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11807229033985399\n",
      "[[ 0.93180309  0.75326641 -1.68519916]\n",
      " [ 2.15952742 -0.17614297 -1.98372664]\n",
      " [-2.94932798 -0.15369188  3.1034362 ]\n",
      " [-1.3752381  -1.24198923  2.61737202]]\n",
      "1179000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11803008602445819\n",
      "[[ 0.93208656  0.75342769 -1.6856439 ]\n",
      " [ 2.16010642 -0.1759982  -1.98445041]\n",
      " [-2.95009863 -0.15380637  3.10432134]\n",
      " [-1.37561371 -1.24249181  2.61825021]]\n",
      "1180000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11798794153631123\n",
      "[[ 0.93236982  0.75358877 -1.68608824]\n",
      " [ 2.16068498 -0.17585348 -1.98517368]\n",
      " [-2.95086871 -0.15392073  3.10520578]\n",
      " [-1.37598906 -1.24299405  2.61912779]]\n",
      "1181000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11794585674216758\n",
      "[[ 0.93265288  0.75374965 -1.68653218]\n",
      " [ 2.16126311 -0.17570882 -1.98589646]\n",
      " [-2.95163821 -0.15403496  3.1060895 ]\n",
      " [-1.37636413 -1.24349594  2.62000476]]\n",
      "1182000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11790383150918307\n",
      "[[ 0.93293574  0.75391033 -1.68697572]\n",
      " [ 2.16184079 -0.17556422 -1.98661875]\n",
      " [-2.95240714 -0.15414905  3.10697253]\n",
      " [-1.37673894 -1.2439975   2.62088112]]\n",
      "1183000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1178618657049151\n",
      "[[ 0.93321839  0.75407082 -1.68741886]\n",
      " [ 2.16241803 -0.17541966 -1.98734055]\n",
      " [-2.95317549 -0.15426302  3.10785484]\n",
      " [-1.37711348 -1.24449871  2.62175687]]\n",
      "1184000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11781995919731988\n",
      "[[ 0.93350084  0.75423111 -1.6878616 ]\n",
      " [ 2.16299484 -0.17527517 -1.98806185]\n",
      " [-2.95394327 -0.15437685  3.10873646]\n",
      " [-1.37748776 -1.24499958  2.62263202]]\n",
      "1185000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11777811185475137\n",
      "[[ 0.93378308  0.7543912  -1.68830394]\n",
      " [ 2.16357121 -0.17513072 -1.98878266]\n",
      " [-2.95471048 -0.15449055  3.10961737]\n",
      " [-1.37786176 -1.2455001   2.62350655]]\n",
      "1186000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11773632354595985\n",
      "[[ 0.93406513  0.7545511  -1.68874588]\n",
      " [ 2.16414714 -0.17498634 -1.98950299]\n",
      " [-2.95547712 -0.15460413  3.11049758]\n",
      " [-1.37823551 -1.24600029  2.62438049]]\n",
      "1187000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11769459414009023\n",
      "[[ 0.93434697  0.7547108  -1.68918742]\n",
      " [ 2.16472264 -0.174842   -1.99022282]\n",
      " [-2.95624318 -0.15471757  3.11137709]\n",
      " [-1.37860898 -1.24650014  2.62525381]]\n",
      "1188000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11765292350668025\n",
      "[[ 0.93462861  0.7548703  -1.68962857]\n",
      " [ 2.1652977  -0.17469772 -1.99094216]\n",
      " [-2.95700868 -0.15483088  3.1122559 ]\n",
      " [-1.37898219 -1.24699965  2.62612653]]\n",
      "1189000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1176113115156601\n",
      "[[ 0.93491005  0.75502961 -1.69006932]\n",
      " [ 2.16587233 -0.1745535  -1.99166101]\n",
      " [-2.95777361 -0.15494407  3.11313401]\n",
      " [-1.37935514 -1.24749882  2.62699865]]\n",
      "1190000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11756975803734931\n",
      "[[ 0.93519129  0.75518873 -1.69050967]\n",
      " [ 2.16644653 -0.17440933 -1.99237938]\n",
      " [-2.95853797 -0.15505712  3.11401143]\n",
      " [-1.37972782 -1.24799766  2.62787016]]\n",
      "1191000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11752826294245702\n",
      "[[ 0.93547232  0.75534765 -1.69094963]\n",
      " [ 2.16702029 -0.17426521 -1.99309726]\n",
      " [-2.95930176 -0.15517005  3.11488815]\n",
      " [-1.38010024 -1.24849615  2.62874108]]\n",
      "1192000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11748682610207906\n",
      "[[ 0.93575316  0.75550638 -1.69138919]\n",
      " [ 2.16759362 -0.17412115 -1.99381465]\n",
      " [-2.96006499 -0.15528285  3.11576417]\n",
      " [-1.38047239 -1.24899431  2.62961139]]\n",
      "1193000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11744544738769733\n",
      "[[ 0.93603379  0.75566491 -1.69182836]\n",
      " [ 2.16816652 -0.17397715 -1.99453155]\n",
      " [-2.96082765 -0.15539551  3.1166395 ]\n",
      " [-1.38084428 -1.24949214  2.6304811 ]]\n",
      "1194000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11740412667117804\n",
      "[[ 0.93631423  0.75582325 -1.69226713]\n",
      " [ 2.16873899 -0.1738332  -1.99524797]\n",
      " [-2.96158975 -0.15550805  3.11751414]\n",
      " [-1.38121591 -1.24998962  2.63135022]]\n",
      "1195000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1173628638247704\n",
      "[[ 0.93659447  0.7559814  -1.69270552]\n",
      " [ 2.16931103 -0.1736893  -1.99596391]\n",
      " [-2.96235129 -0.15562046  3.11838808]\n",
      " [-1.38158727 -1.25048677  2.63221873]]\n",
      "1196000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11732165872110471\n",
      "[[ 0.9368745   0.75613935 -1.69314351]\n",
      " [ 2.16988264 -0.17354546 -1.99667936]\n",
      " [-2.96311226 -0.15573275  3.11926134]\n",
      " [-1.38195837 -1.25098359  2.63308665]]\n",
      "1197000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.117280511233192\n",
      "[[ 0.93715434  0.75629711 -1.69358111]\n",
      " [ 2.17045382 -0.17340167 -1.99739433]\n",
      " [-2.96387267 -0.1558449   3.12013391]\n",
      " [-1.38232921 -1.25148007  2.63395397]]\n",
      "1198000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11723942123442134\n",
      "[[ 0.93743398  0.75645468 -1.69401831]\n",
      " [ 2.17102457 -0.17325794 -1.99810881]\n",
      " [-2.96463252 -0.15595693  3.12100578]\n",
      " [-1.38269979 -1.25197622  2.6348207 ]]\n",
      "1199000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11719838859855924\n",
      "[[ 0.93771342  0.75661206 -1.69445513]\n",
      " [ 2.17159489 -0.17311426 -1.99882281]\n",
      " [-2.96539181 -0.15606883  3.12187697]\n",
      " [-1.38307011 -1.25247203  2.63568683]]\n",
      "1200000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11715741319974785\n",
      "[[ 0.93799266  0.75676925 -1.69489156]\n",
      " [ 2.17216479 -0.17297064 -1.99953633]\n",
      " [-2.96615054 -0.15618061  3.12274748]\n",
      " [-1.38344017 -1.25296751  2.63655237]]\n",
      "1201000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11711649491250381\n",
      "[[ 0.9382717   0.75692624 -1.6953276 ]\n",
      " [ 2.17273426 -0.17282707 -2.00024937]\n",
      " [-2.96690871 -0.15629226  3.1236173 ]\n",
      " [-1.38380996 -1.25346266  2.63741731]]\n",
      "1202000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11707563361171677\n",
      "[[ 0.93855055  0.75708305 -1.69576325]\n",
      " [ 2.1733033  -0.17268356 -2.00096193]\n",
      " [-2.96766632 -0.15640378  3.12448643]\n",
      " [-1.3841795  -1.25395748  2.63828166]]\n",
      "1203000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11703482917264789\n",
      "[[ 0.9388292   0.75723966 -1.69619852]\n",
      " [ 2.17387192 -0.1725401  -2.00167401]\n",
      " [-2.96842338 -0.15651517  3.12535488]\n",
      " [-1.38454878 -1.25445196  2.63914543]]\n",
      "1204000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11699408147092842\n",
      "[[ 0.93910765  0.75739609 -1.6966334 ]\n",
      " [ 2.17444012 -0.17239669 -2.00238561]\n",
      " [-2.96917988 -0.15662644  3.12622265]\n",
      " [-1.3849178  -1.25494612  2.6400086 ]]\n",
      "1205000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11695339038255834\n",
      "[[ 0.93938591  0.75755233 -1.69706789]\n",
      " [ 2.17500789 -0.17225335 -2.00309673]\n",
      " [-2.96993582 -0.15673758  3.12708974]\n",
      " [-1.38528656 -1.25543994  2.64087118]]\n",
      "1206000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11691275578390545\n",
      "[[ 0.93966397  0.75770837 -1.69750199]\n",
      " [ 2.17557524 -0.17211005 -2.00380737]\n",
      " [-2.97069122 -0.1568486   3.12795615]\n",
      " [-1.38565506 -1.25593343  2.64173317]]\n",
      "1207000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11687217755170334\n",
      "[[ 0.93994183  0.75786423 -1.69793571]\n",
      " [ 2.17614217 -0.17196681 -2.00451754]\n",
      " [-2.97144605 -0.15695949  3.12882188]\n",
      " [-1.3860233  -1.25642659  2.64259458]]\n",
      "1208000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11683165556304999\n",
      "[[ 0.94021949  0.7580199  -1.69836905]\n",
      " [ 2.17670867 -0.17182363 -2.00522722]\n",
      " [-2.97220034 -0.15707025  3.12968693]\n",
      " [-1.38639128 -1.25691943  2.6434554 ]]\n",
      "1209000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11679118969540724\n",
      "[[ 0.94049696  0.75817539 -1.698802  ]\n",
      " [ 2.17727476 -0.1716805  -2.00593644]\n",
      " [-2.97295407 -0.15718089  3.1305513 ]\n",
      " [-1.38675901 -1.25741193  2.64431563]]\n",
      "1210000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1167507798265986\n",
      "[[ 0.94077424  0.75833068 -1.69923458]\n",
      " [ 2.17784042 -0.17153742 -2.00664518]\n",
      " [-2.97370726 -0.15729141  3.131415  ]\n",
      " [-1.38712648 -1.25790411  2.64517528]]\n",
      "1211000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11671042583480812\n",
      "[[ 0.94105132  0.75848579 -1.69966676]\n",
      " [ 2.17840566 -0.1713944  -2.00735344]\n",
      " [-2.97445989 -0.1574018   3.13227802]\n",
      " [-1.3874937  -1.25839596  2.64603434]]\n",
      "1212000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11667012759857932\n",
      "[[ 0.94132821  0.75864071 -1.70009857]\n",
      " [ 2.17897049 -0.17125144 -2.00806123]\n",
      " [-2.97521197 -0.15751207  3.13314037]\n",
      " [-1.38786066 -1.25888748  2.64689282]]\n",
      "1213000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11662988499681369\n",
      "[[ 0.9416049   0.75879544 -1.70052999]\n",
      " [ 2.17953489 -0.17110853 -2.00876854]\n",
      " [-2.97596351 -0.15762221  3.13400205]\n",
      " [-1.38822736 -1.25937867  2.64775072]]\n",
      "1214000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11658969790876923\n",
      "[[ 0.94188139  0.75894999 -1.70096104]\n",
      " [ 2.18009888 -0.17096567 -2.00947538]\n",
      " [-2.97671449 -0.15773223  3.13486306]\n",
      " [-1.38859381 -1.25986954  2.64860803]]\n",
      "1215000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11654956621405925\n",
      "[[ 0.94215769  0.75910435 -1.7013917 ]\n",
      " [ 2.18066245 -0.17082287 -2.01018175]\n",
      " [-2.97746493 -0.15784212  3.13572339]\n",
      " [-1.38896    -1.26036008  2.64946477]]\n",
      "1216000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11650948979265115\n",
      "[[ 0.9424338   0.75925853 -1.70182199]\n",
      " [ 2.1812256  -0.17068013 -2.01088765]\n",
      " [-2.97821483 -0.15795189  3.13658306]\n",
      " [-1.38932594 -1.2608503   2.65032092]]\n",
      "1217000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11646946852486491\n",
      "[[ 0.94270972  0.75941252 -1.70225189]\n",
      " [ 2.18178834 -0.17053744 -2.01159308]\n",
      " [-2.97896417 -0.15806154  3.13744205]\n",
      " [-1.38969162 -1.26134019  2.65117649]]\n",
      "1218000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11642950229137192\n",
      "[[ 0.94298544  0.75956633 -1.70268142]\n",
      " [ 2.18235066 -0.1703948  -2.01229803]\n",
      " [-2.97971298 -0.15817107  3.13830038]\n",
      " [-1.39005705 -1.26182976  2.65203149]]\n",
      "1219000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11638959097319342\n",
      "[[ 0.94326097  0.75971995 -1.70311057]\n",
      " [ 2.18291256 -0.17025222 -2.01300252]\n",
      " [-2.98046124 -0.15828047  3.13915804]\n",
      " [-1.39042222 -1.262319    2.65288591]]\n",
      "1220000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11634973445169973\n",
      "[[ 0.94353631  0.75987339 -1.70353935]\n",
      " [ 2.18347405 -0.1701097  -2.01370654]\n",
      " [-2.98120896 -0.15838975  3.14001504]\n",
      " [-1.39078715 -1.26280792  2.65373975]]\n",
      "1221000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11630993260860843\n",
      "[[ 0.94381145  0.76002664 -1.70396775]\n",
      " [ 2.18403513 -0.16996723 -2.01441008]\n",
      " [-2.98195613 -0.15849891  3.14087137]\n",
      " [-1.39115182 -1.26329651  2.65459302]]\n",
      "1222000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11627018532598346\n",
      "[[ 0.9440864   0.76017971 -1.70439577]\n",
      " [ 2.1845958  -0.16982481 -2.01511316]\n",
      " [-2.98270277 -0.15860794  3.14172704]\n",
      " [-1.39151623 -1.26378479  2.65544571]]\n",
      "1223000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11623049248623336\n",
      "[[ 0.94436116  0.7603326  -1.70482342]\n",
      " [ 2.18515605 -0.16968245 -2.01581578]\n",
      " [-2.98344886 -0.15871685  3.14258204]\n",
      " [-1.3918804  -1.26427274  2.65629782]]\n",
      "1224000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11619085397211099\n",
      "[[ 0.94463573  0.76048531 -1.70525069]\n",
      " [ 2.18571589 -0.16954015 -2.01651792]\n",
      " [-2.98419441 -0.15882564  3.14343639]\n",
      " [-1.39224431 -1.26476037  2.65714937]]\n",
      "1225000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11615126966671104\n",
      "[[ 0.94491011  0.76063783 -1.70567759]\n",
      " [ 2.18627532 -0.1693979  -2.0172196 ]\n",
      " [-2.98493943 -0.15893431  3.14429007]\n",
      " [-1.39260797 -1.26524768  2.65800034]]\n",
      "1226000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1161117394534694\n",
      "[[ 0.9451843   0.76079017 -1.70610412]\n",
      " [ 2.18683434 -0.1692557  -2.01792082]\n",
      " [-2.9856839  -0.15904286  3.1451431 ]\n",
      " [-1.39297139 -1.26573466  2.65885074]]\n",
      "1227000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11607226321616199\n",
      "[[ 0.94545829  0.76094233 -1.70653027]\n",
      " [ 2.18739295 -0.16911356 -2.01862156]\n",
      " [-2.98642784 -0.15915129  3.14599546]\n",
      " [-1.39333455 -1.26622133  2.65970056]]\n",
      "1228000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11603284083890313\n",
      "[[ 0.9457321   0.7610943  -1.70695606]\n",
      " [ 2.18795114 -0.16897148 -2.01932185]\n",
      " [-2.98717124 -0.15925959  3.14684717]\n",
      " [-1.39369746 -1.26670768  2.66054982]]\n",
      "1229000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11599347220614491\n",
      "[[ 0.94600571  0.7612461  -1.70738147]\n",
      " [ 2.18850894 -0.16882945 -2.02002167]\n",
      " [-2.98791411 -0.15936778  3.14769822]\n",
      " [-1.39406012 -1.26719371  2.66139851]]\n",
      "1230000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11595415720267516\n",
      "[[ 0.94627914  0.76139771 -1.70780651]\n",
      " [ 2.18906632 -0.16868747 -2.02072102]\n",
      " [-2.98865644 -0.15947584  3.14854862]\n",
      " [-1.39442253 -1.26767942  2.66224663]]\n",
      "1231000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11591489571361668\n",
      "[[ 0.94655238  0.76154915 -1.70823118]\n",
      " [ 2.18962329 -0.16854555 -2.02141992]\n",
      " [-2.98939824 -0.15958378  3.14939836]\n",
      " [-1.39478469 -1.26816481  2.66309418]]\n",
      "1232000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11587568762442634\n",
      "[[ 0.94682542  0.7617004  -1.70865548]\n",
      " [ 2.19017986 -0.16840369 -2.02211835]\n",
      " [-2.99013951 -0.15969161  3.15024745]\n",
      " [-1.3951466  -1.26864988  2.66394117]]\n",
      "1233000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11583653282089301\n",
      "[[ 0.94709828  0.76185148 -1.70907941]\n",
      " [ 2.19073602 -0.16826188 -2.02281632]\n",
      " [-2.99088024 -0.15979931  3.15109588]\n",
      " [-1.39550827 -1.26913463  2.66478758]]\n",
      "1234000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11579743118913721\n",
      "[[ 0.94737095  0.76200237 -1.70950298]\n",
      " [ 2.19129177 -0.16812012 -2.02351383]\n",
      " [-2.99162044 -0.15990689  3.15194366]\n",
      " [-1.39586968 -1.26961907  2.66563344]]\n",
      "1235000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11575838261560922\n",
      "[[ 0.94764343  0.76215309 -1.70992617]\n",
      " [ 2.19184712 -0.16797842 -2.02421088]\n",
      " [-2.9923601  -0.16001436  3.1527908 ]\n",
      " [-1.39623085 -1.27010319  2.66647873]]\n",
      "1236000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11571938698708796\n",
      "[[ 0.94791572  0.76230363 -1.710349  ]\n",
      " [ 2.19240207 -0.16783678 -2.02490747]\n",
      " [-2.99309924 -0.1601217   3.15363728]\n",
      " [-1.39659177 -1.27058699  2.66732345]]\n",
      "1237000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11568044419068073\n",
      "[[ 0.94818783  0.76245399 -1.71077147]\n",
      " [ 2.19295661 -0.16769519 -2.0256036 ]\n",
      " [-2.99383785 -0.16022893  3.15448311]\n",
      " [-1.39695245 -1.27107048  2.66816761]]\n",
      "1238000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11564155411382046\n",
      "[[ 0.94845974  0.76260417 -1.71119356]\n",
      " [ 2.19351075 -0.16755366 -2.02629927]\n",
      " [-2.99457593 -0.16033603  3.1553283 ]\n",
      " [-1.39731287 -1.27155366  2.66901121]]\n",
      "1239000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11560271664426594\n",
      "[[ 0.94873147  0.76275417 -1.7116153 ]\n",
      " [ 2.19406448 -0.16741218 -2.02699449]\n",
      " [-2.99531348 -0.16044302  3.15617284]\n",
      " [-1.39767305 -1.27203651  2.66985425]]\n",
      "1240000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11556393167009955\n",
      "[[ 0.94900301  0.762904   -1.71203666]\n",
      " [ 2.19461782 -0.16727075 -2.02768924]\n",
      " [-2.99605051 -0.16054989  3.15701673]\n",
      " [-1.39803299 -1.27251906  2.67069673]]\n",
      "1241000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11552519907972694\n",
      "[[ 0.94927437  0.76305364 -1.71245767]\n",
      " [ 2.19517075 -0.16712938 -2.02838354]\n",
      " [-2.99678701 -0.16065664  3.15785998]\n",
      " [-1.39839268 -1.27300129  2.67153865]]\n",
      "1242000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11548651876187518\n",
      "[[ 0.94954553  0.76320312 -1.7128783 ]\n",
      " [ 2.19572328 -0.16698807 -2.02907738]\n",
      " [-2.99752298 -0.16076328  3.15870259]\n",
      " [-1.39875212 -1.2734832   2.67238001]]\n",
      "1243000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11544789060559203\n",
      "[[ 0.94981652  0.76335241 -1.71329858]\n",
      " [ 2.1962754  -0.16684681 -2.02977077]\n",
      " [-2.99825843 -0.16086979  3.15954455]\n",
      " [-1.39911132 -1.2739648   2.67322081]]\n",
      "1244000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11540931450024473\n",
      "[[ 0.95008731  0.76350153 -1.7137185 ]\n",
      " [ 2.19682713 -0.16670561 -2.0304637 ]\n",
      " [-2.99899335 -0.16097619  3.16038587]\n",
      " [-1.39947027 -1.27444609  2.67406105]]\n",
      "1245000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1153707903355186\n",
      "[[ 0.95035792  0.76365047 -1.71413805]\n",
      " [ 2.19737846 -0.16656446 -2.03115618]\n",
      " [-2.99972775 -0.16108247  3.16122655]\n",
      " [-1.39982898 -1.27492707  2.67490074]]\n",
      "1246000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11533231800141606\n",
      "[[ 0.95062834  0.76379924 -1.71455724]\n",
      " [ 2.1979294  -0.16642337 -2.03184821]\n",
      " [-3.00046163 -0.16118863  3.16206659]\n",
      " [-1.40018745 -1.27540774  2.67573987]]\n",
      "1247000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11529389738825534\n",
      "[[ 0.95089858  0.76394783 -1.71497607]\n",
      " [ 2.19847993 -0.16628233 -2.03253978]\n",
      " [-3.00119498 -0.16129467  3.16290599]\n",
      " [-1.40054567 -1.27588809  2.67657845]]\n",
      "1248000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11525552838666984\n",
      "[[ 0.95116864  0.76409625 -1.71539454]\n",
      " [ 2.19903006 -0.16614135 -2.0332309 ]\n",
      " [-3.00192782 -0.1614006   3.16374475]\n",
      " [-1.40090365 -1.27636814  2.67741647]]\n",
      "1249000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11521721088760618\n",
      "[[ 0.9514385   0.76424449 -1.71581265]\n",
      " [ 2.1995798  -0.16600042 -2.03392156]\n",
      " [-3.00266013 -0.16150641  3.16458288]\n",
      " [-1.40126139 -1.27684787  2.67825394]]\n",
      "1250000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11517894478232364\n",
      "[[ 0.95170819  0.76439256 -1.71623041]\n",
      " [ 2.20012914 -0.16585955 -2.03461178]\n",
      " [-3.00339192 -0.16161211  3.16542036]\n",
      " [-1.40161888 -1.27732729  2.67909086]]\n",
      "1251000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.115140729962393\n",
      "[[ 0.95197769  0.76454046 -1.7166478 ]\n",
      " [ 2.20067809 -0.16571873 -2.03530154]\n",
      " [-3.0041232  -0.16171769  3.16625722]\n",
      " [-1.40197613 -1.2778064   2.67992722]]\n",
      "1252000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11510256631969512\n",
      "[[ 0.952247    0.76468818 -1.71706484]\n",
      " [ 2.20122664 -0.16557797 -2.03599085]\n",
      " [-3.00485395 -0.16182315  3.16709344]\n",
      " [-1.40233314 -1.27828521  2.68076304]]\n",
      "1253000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11506445374642008\n",
      "[[ 0.95251614  0.76483573 -1.71748152]\n",
      " [ 2.2017748  -0.16543726 -2.03667971]\n",
      " [-3.00558419 -0.1619285   3.16792902]\n",
      " [-1.40268991 -1.2787637   2.6815983 ]]\n",
      "1254000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11502639213506614\n",
      "[[ 0.95278508  0.7649831  -1.71789784]\n",
      " [ 2.20232256 -0.16529661 -2.03736813]\n",
      " [-3.00631392 -0.16203373  3.16876398]\n",
      " [-1.40304644 -1.27924189  2.68243301]]\n",
      "1255000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11498838137843807\n",
      "[[ 0.95305385  0.7651303  -1.7183138 ]\n",
      " [ 2.20286993 -0.16515602 -2.03805609]\n",
      " [-3.00704312 -0.16213884  3.1695983 ]\n",
      " [-1.40340272 -1.27971977  2.68326718]]\n",
      "1256000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11495042136964687\n",
      "[[ 0.95332243  0.76527733 -1.71872942]\n",
      " [ 2.2034169  -0.16501548 -2.03874361]\n",
      " [-3.00777181 -0.16224384  3.17043199]\n",
      " [-1.40375877 -1.28019734  2.68410079]]\n",
      "1257000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11491251200210802\n",
      "[[ 0.95359083  0.76542419 -1.71914467]\n",
      " [ 2.20396349 -0.16487499 -2.03943068]\n",
      " [-3.00849999 -0.16234873  3.17126505]\n",
      " [-1.40411458 -1.2806746   2.68493386]]\n",
      "1258000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11487465316954072\n",
      "[[ 0.95385905  0.76557087 -1.71955957]\n",
      " [ 2.20450968 -0.16473456 -2.0401173 ]\n",
      " [-3.00922765 -0.1624535   3.17209748]\n",
      " [-1.40447014 -1.28115156  2.68576639]]\n",
      "1259000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11483684476596662\n",
      "[[ 0.95412708  0.76571739 -1.71997412]\n",
      " [ 2.20505548 -0.16459418 -2.04080347]\n",
      " [-3.0099548  -0.16255815  3.17292929]\n",
      " [-1.40482547 -1.28162821  2.68659836]]\n",
      "1260000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11479908668570897\n",
      "[[ 0.95439493  0.76586373 -1.72038832]\n",
      " [ 2.20560088 -0.16445386 -2.0414892 ]\n",
      " [-3.01068144 -0.16266269  3.17376047]\n",
      " [-1.40518056 -1.28210456  2.6874298 ]]\n",
      "1261000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11476137882339114\n",
      "[[ 0.9546626   0.7660099  -1.72080216]\n",
      " [ 2.2061459  -0.1643136  -2.04217448]\n",
      " [-3.01140757 -0.16276712  3.17459102]\n",
      " [-1.4055354  -1.2825806   2.68826068]]\n",
      "1262000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11472372107393601\n",
      "[[ 0.95493009  0.76615591 -1.72121565]\n",
      " [ 2.20669053 -0.16417339 -2.04285932]\n",
      " [-3.01213318 -0.16287143  3.17542095]\n",
      " [-1.40589001 -1.28305633  2.68909103]]\n",
      "1263000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11468611333256472\n",
      "[[ 0.9551974   0.76630174 -1.72162879]\n",
      " [ 2.20723477 -0.16403324 -2.04354372]\n",
      " [-3.01285829 -0.16297563  3.17625025]\n",
      " [-1.40624438 -1.28353176  2.68992083]]\n",
      "1264000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11464855549479526\n",
      "[[ 0.95546452  0.7664474  -1.72204158]\n",
      " [ 2.20777862 -0.16389314 -2.04422767]\n",
      " [-3.01358289 -0.16307971  3.17707893]\n",
      " [-1.40659852 -1.28400689  2.69075009]]\n",
      "1265000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11461104745644178\n",
      "[[ 0.95573147  0.76659289 -1.72245402]\n",
      " [ 2.20832209 -0.16375309 -2.04491118]\n",
      " [-3.01430697 -0.16318368  3.17790699]\n",
      " [-1.40695242 -1.28448171  2.69157881]]\n",
      "1266000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11457358911361384\n",
      "[[ 0.95599824  0.76673822 -1.72286611]\n",
      " [ 2.20886516 -0.1636131  -2.04559424]\n",
      " [-3.01503055 -0.16328754  3.17873442]\n",
      " [-1.40730607 -1.28495623  2.69240699]]\n",
      "1267000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11453618036271446\n",
      "[[ 0.95626482  0.76688337 -1.72327784]\n",
      " [ 2.20940785 -0.16347317 -2.04627686]\n",
      " [-3.01575363 -0.16339128  3.17956124]\n",
      " [-1.4076595  -1.28543044  2.69323463]]\n",
      "1268000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11449882110043999\n",
      "[[ 0.95653123  0.76702835 -1.72368923]\n",
      " [ 2.20995016 -0.16333329 -2.04695904]\n",
      " [-3.01647619 -0.16349491  3.18038744]\n",
      " [-1.40801268 -1.28590436  2.69406173]]\n",
      "1269000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11446151122377854\n",
      "[[ 0.95679745  0.76717317 -1.72410028]\n",
      " [ 2.21049208 -0.16319347 -2.04764079]\n",
      " [-3.01719825 -0.16359843  3.18121302]\n",
      " [-1.40836563 -1.28637797  2.69488829]]\n",
      "1270000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11442425063000883\n",
      "[[ 0.9570635   0.76731782 -1.72451097]\n",
      " [ 2.21103361 -0.1630537  -2.04832208]\n",
      " [-3.01791981 -0.16370183  3.18203798]\n",
      " [-1.40871835 -1.28685128  2.69571431]]\n",
      "1271000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11438703921669974\n",
      "[[ 0.95732936  0.7674623  -1.72492132]\n",
      " [ 2.21157476 -0.16291399 -2.04900294]\n",
      " [-3.01864086 -0.16380513  3.18286232]\n",
      " [-1.40907083 -1.28732429  2.6965398 ]]\n",
      "1272000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11434987688170888\n",
      "[[ 0.95759505  0.76760661 -1.72533132]\n",
      " [ 2.21211552 -0.16277433 -2.04968337]\n",
      " [-3.01936141 -0.16390831  3.18368605]\n",
      " [-1.40942307 -1.287797    2.69736475]]\n",
      "1273000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11431276352318145\n",
      "[[ 0.95786056  0.76775076 -1.72574097]\n",
      " [ 2.2126559  -0.16263473 -2.05036335]\n",
      " [-3.02008145 -0.16401137  3.18450916]\n",
      " [-1.40977508 -1.28826941  2.69818917]]\n",
      "1274000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11427569903954954\n",
      "[[ 0.95812589  0.76789474 -1.72615028]\n",
      " [ 2.2131959  -0.16249519 -2.05104289]\n",
      " [-3.02080099 -0.16411433  3.18533166]\n",
      " [-1.41012685 -1.28874151  2.69901305]]\n",
      "1275000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11423868332953073\n",
      "[[ 0.95839104  0.76803855 -1.72655925]\n",
      " [ 2.21373551 -0.16235569 -2.051722  ]\n",
      " [-3.02152004 -0.16421717  3.18615354]\n",
      " [-1.41047839 -1.28921332  2.6998364 ]]\n",
      "1276000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1142017162921276\n",
      "[[ 0.95865601  0.7681822  -1.72696787]\n",
      " [ 2.21427474 -0.16221626 -2.05240067]\n",
      " [-3.02223858 -0.16431991  3.18697482]\n",
      " [-1.4108297  -1.28968483  2.70065921]]\n",
      "1277000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1141647978266263\n",
      "[[ 0.95892081  0.76832568 -1.72737614]\n",
      " [ 2.2148136  -0.16207688 -2.0530789 ]\n",
      " [-3.02295662 -0.16442253  3.18779548]\n",
      " [-1.41118077 -1.29015604  2.7014815 ]]\n",
      "1278000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11412792783259562\n",
      "[[ 0.95918543  0.768469   -1.72778408]\n",
      " [ 2.21535207 -0.16193755 -2.05375669]\n",
      " [-3.02367416 -0.16452504  3.18861553]\n",
      " [-1.41153161 -1.29062695  2.70230325]]\n",
      "1279000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11409110620988604\n",
      "[[ 0.95944987  0.76861215 -1.72819167]\n",
      " [ 2.21589016 -0.16179828 -2.05443406]\n",
      " [-3.0243912  -0.16462744  3.18943497]\n",
      " [-1.41188222 -1.29109757  2.70312447]]\n",
      "1280000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11405433285862894\n",
      "[[ 0.95971413  0.76875513 -1.72859892]\n",
      " [ 2.21642787 -0.16165907 -2.05511098]\n",
      " [-3.02510774 -0.16472973  3.1902538 ]\n",
      " [-1.41223259 -1.29156788  2.70394516]]\n",
      "1281000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11401760767923504\n",
      "[[ 0.95997822  0.76889795 -1.72900582]\n",
      " [ 2.2169652  -0.16151991 -2.05578747]\n",
      " [-3.02582379 -0.1648319   3.19107203]\n",
      " [-1.41258273 -1.2920379   2.70476532]]\n",
      "1282000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11398093057239427\n",
      "[[ 0.96024213  0.76904061 -1.72941239]\n",
      " [ 2.21750215 -0.1613808  -2.05646353]\n",
      " [-3.02653934 -0.16493397  3.19188965]\n",
      " [-1.41293264 -1.29250763  2.70558495]]\n",
      "1283000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1139443014390737\n",
      "[[ 0.96050586  0.7691831  -1.72981861]\n",
      " [ 2.21803873 -0.16124176 -2.05713915]\n",
      " [-3.0272544  -0.16503593  3.19270666]\n",
      " [-1.41328232 -1.29297705  2.70640406]]\n",
      "1284000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11390772018051767\n",
      "[[ 0.96076942  0.76932542 -1.7302245 ]\n",
      " [ 2.21857493 -0.16110276 -2.05781435]\n",
      " [-3.02796896 -0.16513778  3.19352307]\n",
      " [-1.41363177 -1.29344618  2.70722264]]\n",
      "1285000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11387118669824618\n",
      "[[ 0.9610328   0.76946759 -1.73063004]\n",
      " [ 2.21911075 -0.16096382 -2.0584891 ]\n",
      " [-3.02868302 -0.16523951  3.19433887]\n",
      " [-1.41398098 -1.29391502  2.70804069]]\n",
      "1286000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11383470089405383\n",
      "[[ 0.96129601  0.76960959 -1.73103525]\n",
      " [ 2.21964619 -0.16082494 -2.05916343]\n",
      " [-3.02939659 -0.16534114  3.19515407]\n",
      " [-1.41432997 -1.29438356  2.70885821]]\n",
      "1287000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11379826267000927\n",
      "[[ 0.96155904  0.76975142 -1.73144012]\n",
      " [ 2.22018126 -0.16068611 -2.05983733]\n",
      " [-3.03010967 -0.16544266  3.19596866]\n",
      " [-1.41467872 -1.29485181  2.70967521]]\n",
      "1288000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11376187192845393\n",
      "[[ 0.9618219   0.7698931  -1.73184465]\n",
      " [ 2.22071595 -0.16054734 -2.06051079]\n",
      " [-3.03082226 -0.16554407  3.19678266]\n",
      " [-1.41502725 -1.29531976  2.71049169]]\n",
      "1289000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11372552857200129\n",
      "[[ 0.96208458  0.77003461 -1.73224884]\n",
      " [ 2.22125027 -0.16040862 -2.06118383]\n",
      " [-3.03153435 -0.16564536  3.19759605]\n",
      " [-1.41537554 -1.29578741  2.71130764]]\n",
      "1290000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11368923250353553\n",
      "[[ 0.96234708  0.77017596 -1.7326527 ]\n",
      " [ 2.22178421 -0.16026996 -2.06185643]\n",
      " [-3.03224596 -0.16574656  3.19840885]\n",
      " [-1.41572361 -1.29625478  2.71212307]]\n",
      "1291000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11365298362621108\n",
      "[[ 0.96260942  0.77031715 -1.73305622]\n",
      " [ 2.22231778 -0.16013136 -2.06252861]\n",
      " [-3.03295707 -0.16584764  3.19922104]\n",
      " [-1.41607144 -1.29672185  2.71293798]]\n",
      "1292000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11361678184345157\n",
      "[[ 0.96287157  0.77045817 -1.7334594 ]\n",
      " [ 2.22285098 -0.1599928  -2.06320036]\n",
      " [-3.0336677  -0.16594861  3.20003264]\n",
      " [-1.41641905 -1.29718863  2.71375237]]\n",
      "1293000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11358062705894838\n",
      "[[ 0.96313356  0.77059904 -1.73386225]\n",
      " [ 2.2233838  -0.15985431 -2.06387168]\n",
      " [-3.03437783 -0.16604947  3.20084364]\n",
      " [-1.41676643 -1.29765511  2.71456623]]\n",
      "1294000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11354451917666045\n",
      "[[ 0.96339537  0.77073974 -1.73426476]\n",
      " [ 2.22391626 -0.15971587 -2.06454257]\n",
      " [-3.03508748 -0.16615023  3.20165404]\n",
      " [-1.41711358 -1.29812131  2.71537958]]\n",
      "1295000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11350845810081273\n",
      "[[ 0.963657    0.77088029 -1.73466694]\n",
      " [ 2.22444834 -0.15957748 -2.06521304]\n",
      " [-3.03579664 -0.16625088  3.20246385]\n",
      " [-1.41746051 -1.29858721  2.7161924 ]]\n",
      "1296000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11347244373589555\n",
      "[[ 0.96391847  0.77102067 -1.73506879]\n",
      " [ 2.22498004 -0.15943915 -2.06588307]\n",
      " [-3.03650531 -0.16635142  3.20327306]\n",
      " [-1.4178072  -1.29905282  2.71700471]]\n",
      "1297000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11343647598666377\n",
      "[[ 0.96417976  0.77116089 -1.7354703 ]\n",
      " [ 2.22551138 -0.15930088 -2.06655269]\n",
      " [-3.0372135  -0.16645185  3.20408168]\n",
      " [-1.41815367 -1.29951814  2.7178165 ]]\n",
      "1298000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11340055475813561\n",
      "[[ 0.96444087  0.77130095 -1.73587148]\n",
      " [ 2.22604235 -0.15916266 -2.06722187]\n",
      " [-3.0379212  -0.16655218  3.20488971]\n",
      " [-1.41849991 -1.29998317  2.71862777]]\n",
      "1299000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11336467995559182\n",
      "[[ 0.96470182  0.77144086 -1.73627233]\n",
      " [ 2.22657295 -0.15902449 -2.06789064]\n",
      " [-3.03862841 -0.16665239  3.20569714]\n",
      " [-1.41884593 -1.30044791  2.71943853]]\n",
      "1300000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11332885148457503\n",
      "[[ 0.96496259  0.7715806  -1.73667285]\n",
      " [ 2.22710318 -0.15888638 -2.06855898]\n",
      " [-3.03933514 -0.1667525   3.20650398]\n",
      " [-1.41919172 -1.30091236  2.72024877]]\n",
      "1301000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11329306925088839\n",
      "[[ 0.96522319  0.77172018 -1.73707303]\n",
      " [ 2.22763304 -0.15874833 -2.06922689]\n",
      " [-3.04004139 -0.16685251  3.20731023]\n",
      " [-1.41953728 -1.30137653  2.72105849]]\n",
      "1302000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11325733316059484\n",
      "[[ 0.96548362  0.77185961 -1.73747289]\n",
      " [ 2.22816253 -0.15861033 -2.06989438]\n",
      " [-3.04074716 -0.1669524   3.20811589]\n",
      " [-1.41988262 -1.3018404   2.72186771]]\n",
      "1303000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11322164312001633\n",
      "[[ 0.96574388  0.77199888 -1.73787241]\n",
      " [ 2.22869166 -0.15847239 -2.07056145]\n",
      " [-3.04145244 -0.16705219  3.20892097]\n",
      " [-1.42022773 -1.30230398  2.7226764 ]]\n",
      "1304000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11318599903573291\n",
      "[[ 0.96600396  0.77213799 -1.7382716 ]\n",
      " [ 2.22922041 -0.1583345  -2.07122809]\n",
      " [-3.04215724 -0.16715187  3.20972545]\n",
      " [-1.42057262 -1.30276728  2.72348459]]\n",
      "1305000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11315040081458166\n",
      "[[ 0.96626388  0.77227694 -1.73867047]\n",
      " [ 2.2297488  -0.15819667 -2.07189432]\n",
      " [-3.04286156 -0.16725145  3.21052935]\n",
      " [-1.42091728 -1.30323029  2.72429226]]\n",
      "1306000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11311484836365598\n",
      "[[ 0.96652362  0.77241573 -1.73906901]\n",
      " [ 2.23027683 -0.15805889 -2.07256012]\n",
      " [-3.0435654  -0.16735092  3.21133266]\n",
      " [-1.42126172 -1.30369301  2.72509942]]\n",
      "1307000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11307934159030462\n",
      "[[ 0.96678319  0.77255437 -1.73946722]\n",
      " [ 2.23080449 -0.15792117 -2.0732255 ]\n",
      " [-3.04426877 -0.16745029  3.21213539]\n",
      " [-1.42160594 -1.30415545  2.72590607]]\n",
      "1308000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11304388040213051\n",
      "[[ 0.9670426   0.77269285 -1.7398651 ]\n",
      " [ 2.23133178 -0.1577835  -2.07389047]\n",
      " [-3.04497165 -0.16754955  3.21293753]\n",
      " [-1.42194993 -1.3046176   2.72671221]]\n",
      "1309000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1130084647069907\n",
      "[[ 0.96730183  0.77283117 -1.74026265]\n",
      " [ 2.23185871 -0.15764589 -2.07455501]\n",
      " [-3.04567405 -0.1676487   3.21373909]\n",
      " [-1.42229369 -1.30507946  2.72751784]]\n",
      "1310000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11297309441299444\n",
      "[[ 0.96756089  0.77296933 -1.74065988]\n",
      " [ 2.23238528 -0.15750833 -2.07521913]\n",
      " [-3.04637598 -0.16774775  3.21454006]\n",
      " [-1.42263724 -1.30554104  2.72832296]]\n",
      "1311000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11293776942850305\n",
      "[[ 0.96781978  0.77310734 -1.74105678]\n",
      " [ 2.23291148 -0.15737083 -2.07588283]\n",
      " [-3.04707743 -0.16784669  3.21534045]\n",
      " [-1.42298056 -1.30600233  2.72912757]]\n",
      "1312000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11290248966212874\n",
      "[[ 0.96807851  0.7732452  -1.74145336]\n",
      " [ 2.23343732 -0.15723338 -2.07654612]\n",
      " [-3.0477784  -0.16794553  3.21614026]\n",
      " [-1.42332366 -1.30646333  2.72993168]]\n",
      "1313000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11286725502273404\n",
      "[[ 0.96833706  0.77338289 -1.74184961]\n",
      " [ 2.2339628  -0.15709599 -2.07720899]\n",
      " [-3.0484789  -0.16804426  3.21693949]\n",
      " [-1.42366653 -1.30692406  2.73073527]]\n",
      "1314000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1128320654194305\n",
      "[[ 0.96859544  0.77352043 -1.74224553]\n",
      " [ 2.23448792 -0.15695866 -2.07787144]\n",
      " [-3.04917893 -0.16814288  3.21773815]\n",
      " [-1.42400919 -1.30738449  2.73153837]]\n",
      "1315000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11279692076157787\n",
      "[[ 0.96885366  0.77365782 -1.74264113]\n",
      " [ 2.23501267 -0.15682138 -2.07853347]\n",
      " [-3.04987848 -0.16824141  3.21853622]\n",
      " [-1.42435162 -1.30784465  2.73234095]]\n",
      "1316000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1127618209587838\n",
      "[[ 0.96911171  0.77379505 -1.74303641]\n",
      " [ 2.23553706 -0.15668415 -2.07919509]\n",
      " [-3.05057755 -0.16833983  3.21933371]\n",
      " [-1.42469383 -1.30830452  2.73314303]]\n",
      "1317000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11272676592090254\n",
      "[[ 0.96936958  0.77393213 -1.74343137]\n",
      " [ 2.2360611  -0.15654698 -2.07985629]\n",
      " [-3.05127616 -0.16843814  3.22013063]\n",
      " [-1.42503582 -1.30876411  2.73394461]]\n",
      "1318000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11269175555803405\n",
      "[[ 0.96962729  0.77406905 -1.743826  ]\n",
      " [ 2.23658477 -0.15640987 -2.08051708]\n",
      " [-3.05197429 -0.16853635  3.22092697]\n",
      " [-1.42537759 -1.30922341  2.73474569]]\n",
      "1319000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11265678978052317\n",
      "[[ 0.96988484  0.77420582 -1.74422031]\n",
      " [ 2.23710808 -0.15627281 -2.08117745]\n",
      " [-3.05267195 -0.16863446  3.22172274]\n",
      " [-1.42571914 -1.30968244  2.73554626]]\n",
      "1320000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11262186849895904\n",
      "[[ 0.97014221  0.77434244 -1.7446143 ]\n",
      " [ 2.23763104 -0.1561358  -2.08183741]\n",
      " [-3.05336913 -0.16873246  3.22251793]\n",
      " [-1.42606046 -1.31014118  2.73634633]]\n",
      "1321000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11258699162417406\n",
      "[[ 0.97039942  0.7744789  -1.74500797]\n",
      " [ 2.23815363 -0.15599885 -2.08249696]\n",
      " [-3.05406585 -0.16883036  3.22331254]\n",
      " [-1.42640157 -1.31059964  2.7371459 ]]\n",
      "1322000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11255215906724288\n",
      "[[ 0.97065646  0.7746152  -1.74540132]\n",
      " [ 2.23867587 -0.15586196 -2.08315609]\n",
      " [-3.0547621  -0.16892815  3.22410659]\n",
      " [-1.42674246 -1.31105782  2.73794496]]\n",
      "1323000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11251737073948223\n",
      "[[ 0.97091333  0.77475136 -1.74579434]\n",
      " [ 2.23919775 -0.15572512 -2.08381481]\n",
      " [-3.05545788 -0.16902584  3.22490006]\n",
      " [-1.42708313 -1.31151571  2.73874353]]\n",
      "1324000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11248262655244931\n",
      "[[ 0.97117004  0.77488736 -1.74618705]\n",
      " [ 2.23971927 -0.15558834 -2.08447311]\n",
      " [-3.05615319 -0.16912343  3.22569296]\n",
      " [-1.42742358 -1.31197333  2.7395416 ]]\n",
      "1325000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11244792641794132\n",
      "[[ 0.97142658  0.77502321 -1.74657944]\n",
      " [ 2.24024044 -0.15545161 -2.08513101]\n",
      " [-3.05684803 -0.16922092  3.22648529]\n",
      " [-1.42776381 -1.31243067  2.74033917]]\n",
      "1326000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11241327024799465\n",
      "[[ 0.97168295  0.77515891 -1.74697151]\n",
      " [ 2.24076125 -0.15531494 -2.08578849]\n",
      " [-3.05754241 -0.1693183   3.22727704]\n",
      " [-1.42810383 -1.31288773  2.74113624]]\n",
      "1327000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11237865795488408\n",
      "[[ 0.97193915  0.77529445 -1.74736326]\n",
      " [ 2.2412817  -0.15517832 -2.08644557]\n",
      " [-3.05823632 -0.16941558  3.22806823]\n",
      " [-1.42844362 -1.3133445   2.74193281]]\n",
      "1328000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11234408945112186\n",
      "[[ 0.9721952   0.77542985 -1.7477547 ]\n",
      " [ 2.24180181 -0.15504176 -2.08710223]\n",
      " [-3.05892976 -0.16951276  3.22885886]\n",
      " [-1.4287832  -1.313801    2.74272889]]\n",
      "1329000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1123095646494571\n",
      "[[ 0.97245107  0.77556509 -1.74814581]\n",
      " [ 2.24232155 -0.15490525 -2.08775848]\n",
      " [-3.05962274 -0.16960984  3.22964891]\n",
      " [-1.42912256 -1.31425722  2.74352447]]\n",
      "1330000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11227508346287446\n",
      "[[ 0.97270678  0.77570018 -1.74853661]\n",
      " [ 2.24284094 -0.1547688  -2.08841433]\n",
      " [-3.06031525 -0.16970681  3.2304384 ]\n",
      " [-1.4294617  -1.31471317  2.74431955]]\n",
      "1331000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11224064580459436\n",
      "[[ 0.97296232  0.77583512 -1.7489271 ]\n",
      " [ 2.24335998 -0.1546324  -2.08906976]\n",
      " [-3.0610073  -0.16980368  3.23122732]\n",
      " [-1.42980063 -1.31516883  2.74511414]]\n",
      "1332000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11220625158807072\n",
      "[[ 0.9732177   0.77596991 -1.74931726]\n",
      " [ 2.24387867 -0.15449606 -2.08972479]\n",
      " [-3.06169889 -0.16990045  3.23201568]\n",
      " [-1.43013934 -1.31562422  2.74590824]]\n",
      "1333000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11217190072699161\n",
      "[[ 0.97347292  0.77610455 -1.74970712]\n",
      " [ 2.244397   -0.15435977 -2.09037941]\n",
      " [-3.06239001 -0.16999712  3.23280347]\n",
      " [-1.43047783 -1.31607933  2.74670184]]\n",
      "1334000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11213759313527755\n",
      "[[ 0.97372796  0.77623903 -1.75009665]\n",
      " [ 2.24491498 -0.15422354 -2.09103362]\n",
      " [-3.06308068 -0.17009369  3.2335907 ]\n",
      " [-1.4308161  -1.31653416  2.74749495]]\n",
      "1335000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11210332872708084\n",
      "[[ 0.97398285  0.77637337 -1.75048588]\n",
      " [ 2.24543261 -0.15408736 -2.09168742]\n",
      " [-3.06377088 -0.17019015  3.23437736]\n",
      " [-1.43115417 -1.31698872  2.74828757]]\n",
      "1336000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11206910741678498\n",
      "[[ 0.97423757  0.77650756 -1.75087479]\n",
      " [ 2.24594988 -0.15395124 -2.09234082]\n",
      " [-3.06446062 -0.17028652  3.23516347]\n",
      " [-1.43149201 -1.317443    2.7490797 ]]\n",
      "1337000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11203492911900424\n",
      "[[ 0.97449213  0.7766416  -1.75126338]\n",
      " [ 2.24646681 -0.15381518 -2.09299382]\n",
      " [-3.0651499  -0.17038278  3.23594901]\n",
      " [-1.43182964 -1.31789701  2.74987133]]\n",
      "1338000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11200079374858182\n",
      "[[ 0.97474652  0.77677549 -1.75165166]\n",
      " [ 2.24698339 -0.15367917 -2.0936464 ]\n",
      " [-3.06583872 -0.17047894  3.23673399]\n",
      " [-1.43216705 -1.31835074  2.75066248]]\n",
      "1339000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11196670122059009\n",
      "[[ 0.97500075  0.77690923 -1.75203964]\n",
      " [ 2.24749961 -0.15354321 -2.09429859]\n",
      " [-3.06652708 -0.17057501  3.23751842]\n",
      " [-1.43250426 -1.31880419  2.75145313]]\n",
      "1340000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11193265145032946\n",
      "[[ 0.97525481  0.77704283 -1.75242729]\n",
      " [ 2.24801549 -0.15340731 -2.09495036]\n",
      " [-3.06721498 -0.17067097  3.23830228]\n",
      " [-1.43284124 -1.31925737  2.7522433 ]]\n",
      "1341000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11189864435332723\n",
      "[[ 0.97550872  0.77717627 -1.75281464]\n",
      " [ 2.24853102 -0.15327146 -2.09560174]\n",
      " [-3.06790242 -0.17076683  3.23908559]\n",
      " [-1.43317801 -1.31971028  2.75303298]]\n",
      "1342000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11186467984533761\n",
      "[[ 0.97576246  0.77730957 -1.75320168]\n",
      " [ 2.2490462  -0.15313567 -2.09625271]\n",
      " [-3.06858941 -0.17086259  3.23986834]\n",
      " [-1.43351457 -1.32016291  2.75382217]]\n",
      "1343000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11183075784234035\n",
      "[[ 0.97601603  0.77744271 -1.7535884 ]\n",
      " [ 2.24956103 -0.15299994 -2.09690328]\n",
      " [-3.06927594 -0.17095825  3.24065053]\n",
      " [-1.43385091 -1.32061527  2.75461087]]\n",
      "1344000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11179687826054005\n",
      "[[ 0.97626945  0.77757571 -1.75397482]\n",
      " [ 2.25007552 -0.15286426 -2.09755344]\n",
      " [-3.06996202 -0.17105381  3.24143216]\n",
      " [-1.43418705 -1.32106736  2.75539909]]\n",
      "1345000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11176304101636568\n",
      "[[ 0.9765227   0.77770857 -1.75436092]\n",
      " [ 2.25058966 -0.15272863 -2.09820321]\n",
      " [-3.07064764 -0.17114927  3.24221325]\n",
      " [-1.43452296 -1.32151917  2.75618682]]\n",
      "1346000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1117292460264693\n",
      "[[ 0.97677579  0.77784127 -1.75474672]\n",
      " [ 2.25110345 -0.15259306 -2.09885257]\n",
      " [-3.07133281 -0.17124463  3.24299377]\n",
      " [-1.43485867 -1.32197071  2.75697407]]\n",
      "1347000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11169549320772608\n",
      "[[ 0.97702872  0.77797383 -1.75513221]\n",
      " [ 2.2516169  -0.15245755 -2.09950153]\n",
      " [-3.07201752 -0.1713399   3.24377375]\n",
      " [-1.43519416 -1.32242198  2.75776083]]\n",
      "1348000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11166178247723278\n",
      "[[ 0.97728148  0.77810625 -1.75551739]\n",
      " [ 2.25213    -0.15232209 -2.10015009]\n",
      " [-3.07270178 -0.17143506  3.24455317]\n",
      " [-1.43552944 -1.32287298  2.75854711]]\n",
      "1349000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11162811375230779\n",
      "[[ 0.97753409  0.77823851 -1.75590226]\n",
      " [ 2.25264275 -0.15218668 -2.10079825]\n",
      " [-3.07338558 -0.17153013  3.24533204]\n",
      " [-1.43586451 -1.3233237   2.7593329 ]]\n",
      "1350000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11159448695048928\n",
      "[[ 0.97778653  0.77837063 -1.75628682]\n",
      " [ 2.25315516 -0.15205133 -2.10144601]\n",
      " [-3.07406894 -0.17162509  3.24611036]\n",
      " [-1.43619937 -1.32377416  2.76011822]]\n",
      "1351000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11156090198953567\n",
      "[[ 0.97803882  0.77850261 -1.75667108]\n",
      " [ 2.25366723 -0.15191604 -2.10209338]\n",
      " [-3.07475184 -0.17171996  3.24688813]\n",
      " [-1.43653402 -1.32422434  2.76090305]]\n",
      "1352000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11152735878742408\n",
      "[[ 0.97829094  0.77863444 -1.75705503]\n",
      " [ 2.25417896 -0.1517808  -2.10274034]\n",
      " [-3.07543429 -0.17181473  3.24766535]\n",
      " [-1.43686845 -1.32467426  2.76168739]]\n",
      "1353000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11149385726234975\n",
      "[[ 0.9785429   0.77876612 -1.75743867]\n",
      " [ 2.25469034 -0.15164561 -2.10338691]\n",
      " [-3.07611629 -0.1719094   3.24844202]\n",
      " [-1.43720268 -1.3251239   2.76247126]]\n",
      "1354000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11146039733272582\n",
      "[[ 0.9787947   0.77889766 -1.75782201]\n",
      " [ 2.25520137 -0.15151048 -2.10403307]\n",
      " [-3.07679784 -0.17200397  3.24921814]\n",
      " [-1.43753669 -1.32557328  2.76325465]]\n",
      "1355000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11142697891718185\n",
      "[[ 0.97904634  0.77902905 -1.75820505]\n",
      " [ 2.25571207 -0.15137541 -2.10467884]\n",
      " [-3.07747894 -0.17209844  3.24999372]\n",
      " [-1.43787049 -1.32602238  2.76403756]]\n",
      "1356000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11139360193456364\n",
      "[[ 0.97929782  0.7791603  -1.75858778]\n",
      " [ 2.25622242 -0.15124039 -2.10532422]\n",
      " [-3.07815959 -0.17219282  3.25076874]\n",
      " [-1.43820409 -1.32647122  2.76481999]]\n",
      "1357000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11136026630393193\n",
      "[[ 0.97954914  0.7792914  -1.7589702 ]\n",
      " [ 2.25673244 -0.15110542 -2.10596919]\n",
      " [-3.0788398  -0.17228709  3.25154323]\n",
      " [-1.43853747 -1.32691978  2.76560194]]\n",
      "1358000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1113269719445624\n",
      "[[ 0.97980031  0.77942236 -1.75935232]\n",
      " [ 2.25724211 -0.15097051 -2.10661378]\n",
      " [-3.07951956 -0.17238127  3.25231716]\n",
      " [-1.43887065 -1.32736808  2.76638342]]\n",
      "1359000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11129371877594446\n",
      "[[ 0.98005131  0.77955318 -1.75973414]\n",
      " [ 2.25775144 -0.15083566 -2.10725796]\n",
      " [-3.08019887 -0.17247535  3.25309056]\n",
      " [-1.43920361 -1.32781612  2.76716441]]\n",
      "1360000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.111260506717781\n",
      "[[ 0.98030215  0.77968385 -1.76011566]\n",
      " [ 2.25826043 -0.15070086 -2.10790175]\n",
      " [-3.08087773 -0.17256934  3.25386341]\n",
      " [-1.43953637 -1.32826388  2.76794493]]\n",
      "1361000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11122733568998697\n",
      "[[ 0.98055283  0.77981438 -1.76049687]\n",
      " [ 2.25876908 -0.15056612 -2.10854515]\n",
      " [-3.08155615 -0.17266323  3.25463572]\n",
      " [-1.43986892 -1.32871138  2.76872498]]\n",
      "1362000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11119420561268915\n",
      "[[ 0.98080336  0.77994477 -1.76087778]\n",
      " [ 2.2592774  -0.15043143 -2.10918815]\n",
      " [-3.08223413 -0.17275702  3.25540748]\n",
      " [-1.44020126 -1.32915861  2.76950455]]\n",
      "1363000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11116111640622539\n",
      "[[ 0.98105373  0.78007501 -1.76125839]\n",
      " [ 2.25978537 -0.15029679 -2.10983076]\n",
      " [-3.08291166 -0.17285071  3.25617871]\n",
      " [-1.44053339 -1.32960557  2.77028364]]\n",
      "1364000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11112806799114386\n",
      "[[ 0.98130393  0.78020511 -1.7616387 ]\n",
      " [ 2.26029301 -0.15016221 -2.11047298]\n",
      " [-3.08358874 -0.17294431  3.25694939]\n",
      " [-1.44086531 -1.33005227  2.77106227]]\n",
      "1365000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11109506028820255\n",
      "[[ 0.98155399  0.78033507 -1.76201871]\n",
      " [ 2.26080031 -0.15002769 -2.1111148 ]\n",
      " [-3.08426539 -0.17303781  3.25771953]\n",
      " [-1.44119703 -1.3304987   2.77184041]]\n",
      "1366000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11106209321836798\n",
      "[[ 0.98180388  0.78046489 -1.76239842]\n",
      " [ 2.26130727 -0.14989322 -2.11175623]\n",
      " [-3.08494159 -0.17313121  3.25848914]\n",
      " [-1.44152854 -1.33094486  2.77261809]]\n",
      "1367000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11102916670281528\n",
      "[[ 0.98205361  0.78059456 -1.76277783]\n",
      " [ 2.26181389 -0.1497588  -2.11239727]\n",
      " [-3.08561735 -0.17322452  3.2592582 ]\n",
      " [-1.44185984 -1.33139076  2.77339529]]\n",
      "1368000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11099628066292695\n",
      "[[ 0.98230319  0.78072409 -1.76315693]\n",
      " [ 2.26232018 -0.14962444 -2.11303792]\n",
      " [-3.08629266 -0.17331773  3.26002673]\n",
      " [-1.44219094 -1.3318364   2.77417203]]\n",
      "1369000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11096343502029242\n",
      "[[ 0.98255261  0.78085348 -1.76353575]\n",
      " [ 2.26282614 -0.14949014 -2.11367818]\n",
      " [-3.08696754 -0.17341085  3.26079472]\n",
      " [-1.44252183 -1.33228177  2.77494829]]\n",
      "1370000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11093062969670728\n",
      "[[ 0.98280187  0.78098273 -1.76391426]\n",
      " [ 2.26333175 -0.14935589 -2.11431805]\n",
      " [-3.08764198 -0.17350387  3.26156218]\n",
      " [-1.44285251 -1.33272688  2.77572408]]\n",
      "1371000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11089786461417271\n",
      "[[ 0.98305098  0.78111184 -1.76429247]\n",
      " [ 2.26383704 -0.14922169 -2.11495753]\n",
      " [-3.08831597 -0.17359679  3.2623291 ]\n",
      " [-1.44318299 -1.33317172  2.7764994 ]]\n",
      "1372000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11086513969489448\n",
      "[[ 0.98329993  0.78124081 -1.76467039]\n",
      " [ 2.26434199 -0.14908755 -2.11559661]\n",
      " [-3.08898953 -0.17368962  3.26309549]\n",
      " [-1.44351326 -1.3336163   2.77727425]]\n",
      "1373000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11083245486128253\n",
      "[[ 0.98354872  0.78136963 -1.76504801]\n",
      " [ 2.2648466  -0.14895347 -2.11623531]\n",
      " [-3.08966265 -0.17378236  3.26386134]\n",
      " [-1.44384333 -1.33406062  2.77804864]]\n",
      "1374000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11079981003595046\n",
      "[[ 0.98379736  0.78149832 -1.76542533]\n",
      " [ 2.26535088 -0.14881944 -2.11687362]\n",
      " [-3.09033533 -0.173875    3.26462666]\n",
      " [-1.44417319 -1.33450467  2.77882255]]\n",
      "1375000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11076720514171441\n",
      "[[ 0.98404584  0.78162687 -1.76580236]\n",
      " [ 2.26585483 -0.14868546 -2.11751155]\n",
      " [-3.09100757 -0.17396754  3.26539145]\n",
      " [-1.44450285 -1.33494847  2.779596  ]]\n",
      "1376000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11073464010159266\n",
      "[[ 0.98429416  0.78175527 -1.76617909]\n",
      " [ 2.26635844 -0.14855154 -2.11814908]\n",
      " [-3.09167938 -0.17405999  3.2661557 ]\n",
      " [-1.4448323  -1.335392    2.78036899]]\n",
      "1377000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11070211483880515\n",
      "[[ 0.98454233  0.78188354 -1.76655552]\n",
      " [ 2.26686172 -0.14841767 -2.11878623]\n",
      " [-3.09235075 -0.17415234  3.26691942]\n",
      " [-1.44516155 -1.33583526  2.7811415 ]]\n",
      "1378000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11066962927677247\n",
      "[[ 0.98479034  0.78201167 -1.76693167]\n",
      " [ 2.26736468 -0.14828386 -2.11942299]\n",
      " [-3.09302168 -0.1742446   3.26768262]\n",
      " [-1.4454906  -1.33627827  2.78191355]]\n",
      "1379000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11063718333911533\n",
      "[[ 0.9850382   0.78213966 -1.76730751]\n",
      " [ 2.2678673  -0.14815011 -2.12005937]\n",
      " [-3.09369218 -0.17433676  3.26844528]\n",
      " [-1.44581944 -1.33672102  2.78268514]]\n",
      "1380000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11060477694965379\n",
      "[[ 0.9852859   0.78226751 -1.76768306]\n",
      " [ 2.26836958 -0.14801641 -2.12069536]\n",
      " [-3.09436225 -0.17442883  3.26920742]\n",
      " [-1.44614808 -1.3371635   2.78345626]]\n",
      "1381000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11057241003240703\n",
      "[[ 0.98553345  0.78239522 -1.76805832]\n",
      " [ 2.26887154 -0.14788276 -2.12133096]\n",
      " [-3.09503188 -0.17452081  3.26996902]\n",
      " [-1.44647651 -1.33760573  2.78422692]]\n",
      "1382000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11054008251159196\n",
      "[[ 0.98578084  0.78252279 -1.76843329]\n",
      " [ 2.26937317 -0.14774917 -2.12196618]\n",
      " [-3.09570108 -0.17461269  3.2707301 ]\n",
      " [-1.44680474 -1.33804769  2.78499712]]\n",
      "1383000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11050779431162323\n",
      "[[ 0.98602808  0.78265023 -1.76880796]\n",
      " [ 2.26987447 -0.14761563 -2.12260102]\n",
      " [-3.09636984 -0.17470448  3.27149066]\n",
      " [-1.44713277 -1.33848939  2.78576685]]\n",
      "1384000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11047554535711233\n",
      "[[ 0.98627517  0.78277752 -1.76918234]\n",
      " [ 2.27037544 -0.14748215 -2.12323547]\n",
      " [-3.09703818 -0.17479617  3.27225069]\n",
      " [-1.4474606  -1.33893084  2.78653612]]\n",
      "1385000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11044333557286681\n",
      "[[ 0.9865221   0.78290468 -1.76955643]\n",
      " [ 2.27087608 -0.14734872 -2.12386954]\n",
      " [-3.09770608 -0.17488777  3.27301019]\n",
      " [-1.44778822 -1.33937202  2.78730493]]\n",
      "1386000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11041116488388994\n",
      "[[ 0.98676887  0.7830317  -1.76993023]\n",
      " [ 2.27137639 -0.14721535 -2.12450322]\n",
      " [-3.09837355 -0.17497928  3.27376916]\n",
      " [-1.44811564 -1.33981295  2.78807328]]\n",
      "1387000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1103790332153801\n",
      "[[ 0.9870155   0.78315859 -1.77030374]\n",
      " [ 2.27187637 -0.14708203 -2.12513652]\n",
      " [-3.09904059 -0.1750707   3.27452762]\n",
      " [-1.44844286 -1.34025362  2.78884117]]\n",
      "1388000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1103469404927294\n",
      "[[ 0.98726196  0.78328533 -1.77067695]\n",
      " [ 2.27237603 -0.14694877 -2.12576944]\n",
      " [-3.0997072  -0.17516202  3.27528555]\n",
      " [-1.44876988 -1.34069403  2.7896086 ]]\n",
      "1389000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11031488664152393\n",
      "[[ 0.98750828  0.78341194 -1.77104988]\n",
      " [ 2.27287536 -0.14681556 -2.12640198]\n",
      " [-3.10037338 -0.17525324  3.27604296]\n",
      " [-1.4490967  -1.34113418  2.79037557]]\n",
      "1390000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11028287158754271\n",
      "[[ 0.98775444  0.78353842 -1.77142251]\n",
      " [ 2.27337436 -0.14668241 -2.12703414]\n",
      " [-3.10103913 -0.17534438  3.27679984]\n",
      " [-1.44942332 -1.34157408  2.79114208]]\n",
      "1391000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11025089525675758\n",
      "[[ 0.98800045  0.78366475 -1.77179486]\n",
      " [ 2.27387304 -0.14654931 -2.12766591]\n",
      " [-3.10170445 -0.17543542  3.27755621]\n",
      " [-1.44974974 -1.34201372  2.79190814]]\n",
      "1392000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1102189575753312\n",
      "[[ 0.98824631  0.78379095 -1.77216692]\n",
      " [ 2.27437139 -0.14641626 -2.12829731]\n",
      " [-3.10236935 -0.17552637  3.27831205]\n",
      " [-1.45007595 -1.3424531   2.79267373]]\n",
      "1393000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11018705846961808\n",
      "[[ 0.98849201  0.78391702 -1.77253869]\n",
      " [ 2.27486942 -0.14628327 -2.12892832]\n",
      " [-3.10303382 -0.17561723  3.27906738]\n",
      " [-1.45040197 -1.34289222  2.79343888]]\n",
      "1394000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11015519786616326\n",
      "[[ 0.98873757  0.78404295 -1.77291017]\n",
      " [ 2.27536712 -0.14615034 -2.12955896]\n",
      " [-3.10369786 -0.17570799  3.27982219]\n",
      " [-1.45072779 -1.34333109  2.79420356]]\n",
      "1395000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11012337569170105\n",
      "[[ 0.98898297  0.78416874 -1.77328136]\n",
      " [ 2.27586449 -0.14601746 -2.13018922]\n",
      " [-3.10436148 -0.17579866  3.28057647]\n",
      " [-1.4510534  -1.3437697   2.79496779]]\n",
      "1396000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1100915918731557\n",
      "[[ 0.98922821  0.7842944  -1.77365227]\n",
      " [ 2.27636155 -0.14588463 -2.1308191 ]\n",
      " [-3.10502467 -0.17588924  3.28133025]\n",
      " [-1.45137882 -1.34420806  2.79573156]]\n",
      "1397000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11005984633763945\n",
      "[[ 0.98947331  0.78441993 -1.77402289]\n",
      " [ 2.27685828 -0.14575186 -2.13144859]\n",
      " [-3.10568743 -0.17597973  3.2820835 ]\n",
      " [-1.45170404 -1.34464616  2.79649488]]\n",
      "1398000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.11002813901245317\n",
      "[[ 0.98971825  0.78454531 -1.77439322]\n",
      " [ 2.27735468 -0.14561915 -2.13207772]\n",
      " [-3.10634977 -0.17607013  3.28283624]\n",
      " [-1.45202906 -1.34508401  2.79725775]]\n",
      "1399000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10999646982508468\n",
      "[[ 0.98996305  0.78467057 -1.77476327]\n",
      " [ 2.27785077 -0.14548648 -2.13270646]\n",
      " [-3.10701169 -0.17616044  3.28358846]\n",
      " [-1.45235388 -1.3455216   2.79802016]]\n",
      "1400000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10996483870320885\n",
      "[[ 0.99020769  0.78479569 -1.77513303]\n",
      " [ 2.27834653 -0.14535388 -2.13333483]\n",
      " [-3.10767319 -0.17625065  3.28434017]\n",
      " [-1.4526785  -1.34595894  2.79878213]]\n",
      "1401000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10993324557468692\n",
      "[[ 0.99045218  0.78492067 -1.77550251]\n",
      " [ 2.27884197 -0.14522133 -2.13396282]\n",
      " [-3.10833426 -0.17634077  3.28509136]\n",
      " [-1.45300293 -1.34639602  2.79954363]]\n",
      "1402000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10990169036756522\n",
      "[[ 0.99069652  0.78504553 -1.7758717 ]\n",
      " [ 2.27933708 -0.14508883 -2.13459043]\n",
      " [-3.10899491 -0.1764308   3.28584204]\n",
      " [-1.45332716 -1.34683285  2.80030469]]\n",
      "1403000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10987017301007555\n",
      "[[ 0.99094071  0.78517024 -1.77624061]\n",
      " [ 2.27983188 -0.14495639 -2.13521767]\n",
      " [-3.10965513 -0.17652074  3.28659221]\n",
      " [-1.45365119 -1.34726943  2.8010653 ]]\n",
      "1404000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10983869343063399\n",
      "[[ 0.99118475  0.78529483 -1.77660923]\n",
      " [ 2.28032635 -0.144824   -2.13584454]\n",
      " [-3.11031494 -0.17661059  3.28734187]\n",
      " [-1.45397502 -1.34770575  2.80182545]]\n",
      "1405000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10980725155784021\n",
      "[[ 0.99142864  0.78541928 -1.77697757]\n",
      " [ 2.28082051 -0.14469166 -2.13647103]\n",
      " [-3.11097433 -0.17670035  3.28809101]\n",
      " [-1.45429865 -1.34814182  2.80258516]]\n",
      "1406000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10977584732047713\n",
      "[[ 0.99167237  0.7855436  -1.77734563]\n",
      " [ 2.28131435 -0.14455938 -2.13709714]\n",
      " [-3.11163329 -0.17679002  3.28883965]\n",
      " [-1.45462209 -1.34857764  2.80334442]]\n",
      "1407000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1097444806475104\n",
      "[[ 0.99191596  0.78566778 -1.7777134 ]\n",
      " [ 2.28180786 -0.14442716 -2.13772288]\n",
      " [-3.11229184 -0.1768796   3.28958777]\n",
      " [-1.45494533 -1.34901321  2.80410323]]\n",
      "1408000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10971315146808767\n",
      "[[ 0.9921594   0.78579184 -1.77808089]\n",
      " [ 2.28230106 -0.14429499 -2.13834825]\n",
      " [-3.11294997 -0.17696908  3.29033538]\n",
      " [-1.45526838 -1.34944852  2.80486159]]\n",
      "1409000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10968185971153815\n",
      "[[ 0.99240269  0.78591576 -1.7784481 ]\n",
      " [ 2.28279394 -0.14416287 -2.13897324]\n",
      " [-3.11360768 -0.17705848  3.29108249]\n",
      " [-1.45559123 -1.34988358  2.8056195 ]]\n",
      "1410000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10965060530737153\n",
      "[[ 0.99264583  0.78603955 -1.77881503]\n",
      " [ 2.2832865  -0.14403081 -2.13959787]\n",
      " [-3.11426497 -0.17714779  3.29182909]\n",
      " [-1.45591388 -1.3503184   2.80637697]]\n",
      "1411000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10961938818527803\n",
      "[[ 0.99288882  0.7861632  -1.77918168]\n",
      " [ 2.28377874 -0.14389881 -2.14022212]\n",
      " [-3.11492184 -0.17723701  3.29257518]\n",
      " [-1.45623634 -1.35075296  2.80713399]]\n",
      "1412000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10958820827512734\n",
      "[[ 0.99313167  0.78628673 -1.77954805]\n",
      " [ 2.28427067 -0.14376686 -2.14084599]\n",
      " [-3.1155783  -0.17732613  3.29332077]\n",
      " [-1.45655861 -1.35118727  2.80789056]]\n",
      "1413000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10955706550696857\n",
      "[[ 0.99337436  0.78641012 -1.77991413]\n",
      " [ 2.28476228 -0.14363496 -2.1414695 ]\n",
      " [-3.11623434 -0.17741517  3.29406584]\n",
      " [-1.45688067 -1.35162133  2.80864669]]\n",
      "1414000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10952595981102903\n",
      "[[ 0.9936169   0.78653338 -1.78027994]\n",
      " [ 2.28525357 -0.14350311 -2.14209264]\n",
      " [-3.11688996 -0.17750412  3.29481042]\n",
      " [-1.45720255 -1.35205514  2.80940237]]\n",
      "1415000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10949489111771418\n",
      "[[ 0.9938593   0.78665651 -1.78064547]\n",
      " [ 2.28574455 -0.14337133 -2.1427154 ]\n",
      " [-3.11754518 -0.17759298  3.29555449]\n",
      " [-1.45752423 -1.3524887   2.81015761]]\n",
      "1416000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10946385935760664\n",
      "[[ 0.99410155  0.78677951 -1.78101072]\n",
      " [ 2.28623521 -0.14323959 -2.14333779]\n",
      " [-3.11819997 -0.17768175  3.29629805]\n",
      " [-1.45784571 -1.35292201  2.81091241]]\n",
      "1417000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10943286446146627\n",
      "[[ 0.99434365  0.78690238 -1.78137569]\n",
      " [ 2.28672555 -0.14310791 -2.14395982]\n",
      " [-3.11885435 -0.17777043  3.29704111]\n",
      " [-1.458167   -1.35335508  2.81166676]]\n",
      "1418000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1094019063602286\n",
      "[[ 0.9945856   0.78702512 -1.78174038]\n",
      " [ 2.28721558 -0.14297629 -2.14458147]\n",
      " [-3.11950832 -0.17785902  3.29778367]\n",
      " [-1.4584881  -1.35378789  2.81242067]]\n",
      "1419000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10937098498500532\n",
      "[[ 0.99482741  0.78714773 -1.78210479]\n",
      " [ 2.2877053  -0.14284472 -2.14520276]\n",
      " [-3.12016188 -0.17794752  3.29852573]\n",
      " [-1.458809   -1.35422046  2.81317414]]\n",
      "1420000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10934010026708303\n",
      "[[ 0.99506906  0.78727021 -1.78246893]\n",
      " [ 2.2881947  -0.1427132  -2.14582368]\n",
      " [-3.12081502 -0.17803594  3.29926729]\n",
      " [-1.45912971 -1.35465277  2.81392717]]\n",
      "1421000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10930925213792274\n",
      "[[ 0.99531057  0.78739256 -1.78283279]\n",
      " [ 2.28868379 -0.14258174 -2.14644423]\n",
      " [-3.12146775 -0.17812426  3.30000834]\n",
      " [-1.45945023 -1.35508484  2.81467976]]\n",
      "1422000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10927844052915955\n",
      "[[ 0.99555194  0.78751478 -1.78319637]\n",
      " [ 2.28917256 -0.14245033 -2.14706441]\n",
      " [-3.12212007 -0.1782125   3.3007489 ]\n",
      " [-1.45977055 -1.35551667  2.8154319 ]]\n",
      "1423000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10924766537260217\n",
      "[[ 0.99579315  0.78763687 -1.78355967]\n",
      " [ 2.28966103 -0.14231898 -2.14768423]\n",
      " [-3.12277198 -0.17830065  3.30148896]\n",
      " [-1.46009068 -1.35594824  2.81618361]]\n",
      "1424000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10921692660023183\n",
      "[[ 0.99603422  0.78775883 -1.7839227 ]\n",
      " [ 2.29014918 -0.14218768 -2.14830368]\n",
      " [-3.12342347 -0.17838871  3.30222852]\n",
      " [-1.46041062 -1.35637957  2.81693488]]\n",
      "1425000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10918622414420251\n",
      "[[ 0.99627514  0.78788066 -1.78428546]\n",
      " [ 2.29063701 -0.14205644 -2.14892276]\n",
      " [-3.12407456 -0.17847668  3.30296758]\n",
      " [-1.46073037 -1.35681065  2.81768571]]\n",
      "1426000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1091555579368395\n",
      "[[ 0.99651592  0.78800236 -1.78464794]\n",
      " [ 2.29112454 -0.14192525 -2.14954147]\n",
      " [-3.12472524 -0.17856457  3.30370614]\n",
      " [-1.46104992 -1.35724149  2.8184361 ]]\n",
      "1427000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10912492791063978\n",
      "[[ 0.99675655  0.78812394 -1.78501014]\n",
      " [ 2.29161175 -0.14179411 -2.15015983]\n",
      " [-3.12537551 -0.17865236  3.30444421]\n",
      " [-1.46136929 -1.35767208  2.81918605]]\n",
      "1428000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10909433399827047\n",
      "[[ 0.99699704  0.78824538 -1.78537207]\n",
      " [ 2.29209866 -0.14166303 -2.15077781]\n",
      " [-3.12602537 -0.17874007  3.30518178]\n",
      " [-1.46168846 -1.35810242  2.81993557]]\n",
      "1429000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10906377613256936\n",
      "[[ 0.99723737  0.7883667  -1.78573373]\n",
      " [ 2.29258525 -0.141532   -2.15139543]\n",
      " [-3.12667483 -0.17882769  3.30591885]\n",
      " [-1.46200744 -1.35853252  2.82068465]]\n",
      "1430000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1090332542465436\n",
      "[[ 0.99747757  0.78848789 -1.78609511]\n",
      " [ 2.29307154 -0.14140103 -2.15201269]\n",
      " [-3.12732387 -0.17891523  3.30665544]\n",
      " [-1.46232623 -1.35896238  2.82143329]]\n",
      "1431000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10900276827336942\n",
      "[[ 0.99771761  0.78860895 -1.78645622]\n",
      " [ 2.29355751 -0.14127011 -2.15262958]\n",
      " [-3.12797251 -0.17900268  3.30739152]\n",
      " [-1.46264483 -1.35939199  2.8221815 ]]\n",
      "1432000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10897231814639137\n",
      "[[ 0.99795752  0.78872989 -1.78681706]\n",
      " [ 2.29404318 -0.14113925 -2.15324611]\n",
      " [-3.12862075 -0.17909004  3.30812712]\n",
      " [-1.46296324 -1.35982135  2.82292927]]\n",
      "1433000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10894190379912222\n",
      "[[ 0.99819727  0.7888507  -1.78717762]\n",
      " [ 2.29452853 -0.14100844 -2.15386228]\n",
      " [-3.12926858 -0.17917731  3.30886222]\n",
      " [-1.46328145 -1.36025047  2.82367661]]\n",
      "1434000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1089115251652421\n",
      "[[ 0.99843689  0.78897138 -1.78753792]\n",
      " [ 2.29501358 -0.14087768 -2.15447808]\n",
      " [-3.129916   -0.17926449  3.30959683]\n",
      " [-1.46359948 -1.36067935  2.82442352]]\n",
      "1435000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10888118217859794\n",
      "[[ 0.99867635  0.78909193 -1.78789794]\n",
      " [ 2.29549832 -0.14074698 -2.15509352]\n",
      " [-3.13056302 -0.17935159  3.31033095]\n",
      " [-1.46391732 -1.36110798  2.82516999]]\n",
      "1436000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10885087477320327\n",
      "[[ 0.99891568  0.78921236 -1.78825769]\n",
      " [ 2.29598275 -0.14061633 -2.1557086 ]\n",
      " [-3.13120963 -0.17943861  3.31106457]\n",
      " [-1.46423497 -1.36153637  2.82591603]]\n",
      "1437000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10882060288323729\n",
      "[[ 0.99915485  0.78933266 -1.78861717]\n",
      " [ 2.29646688 -0.14048574 -2.15632332]\n",
      " [-3.13185584 -0.17952553  3.31179771]\n",
      " [-1.46455243 -1.36196452  2.82666164]]\n",
      "1438000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10879036644304482\n",
      "[[ 0.99939389  0.78945283 -1.78897637]\n",
      " [ 2.29695069 -0.1403552  -2.15693768]\n",
      " [-3.13250165 -0.17961237  3.31253036]\n",
      " [-1.4648697  -1.36239243  2.82740681]]\n",
      "1439000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10876016538713491\n",
      "[[ 0.99963278  0.78957288 -1.78933531]\n",
      " [ 2.29743421 -0.14022471 -2.15755167]\n",
      " [-3.13314705 -0.17969913  3.31326252]\n",
      " [-1.46518678 -1.36282009  2.82815156]]\n",
      "1440000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10872999965018139\n",
      "[[ 0.99987152  0.7896928  -1.78969398]\n",
      " [ 2.29791741 -0.14009428 -2.15816531]\n",
      " [-3.13379206 -0.1797858   3.31399419]\n",
      " [-1.46550368 -1.36324751  2.82889587]]\n",
      "1441000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10869986916702189\n",
      "[[ 1.00011013  0.7898126  -1.79005238]\n",
      " [ 2.29840031 -0.13996391 -2.15877858]\n",
      " [-3.13443666 -0.17987238  3.31472537]\n",
      " [-1.46582038 -1.36367469  2.82963975]]\n",
      "1442000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10866977387265697\n",
      "[[ 1.00034859  0.78993227 -1.79041051]\n",
      " [ 2.2988829  -0.13983359 -2.1593915 ]\n",
      " [-3.13508086 -0.17995888  3.31545607]\n",
      " [-1.4661369  -1.36410162  2.83038321]]\n",
      "1443000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10863971370224988\n",
      "[[ 1.0005869   0.79005182 -1.79076837]\n",
      " [ 2.29936519 -0.13970332 -2.16000406]\n",
      " [-3.13572466 -0.18004529  3.31618628]\n",
      " [-1.46645323 -1.36452832  2.83112623]]\n",
      "1444000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10860968859112646\n",
      "[[ 1.00082507  0.79017124 -1.79112597]\n",
      " [ 2.29984718 -0.1395731  -2.16061626]\n",
      " [-3.13636805 -0.18013161  3.316916  ]\n",
      " [-1.46676937 -1.36495478  2.83186883]]\n",
      "1445000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10857969847477394\n",
      "[[ 1.0010631   0.79029053 -1.79148329]\n",
      " [ 2.30032886 -0.13944294 -2.1612281 ]\n",
      " [-3.13701105 -0.18021785  3.31764524]\n",
      " [-1.46708532 -1.36538099  2.832611  ]]\n",
      "1446000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10854974328884087\n",
      "[[ 1.00130099  0.7904097  -1.79184035]\n",
      " [ 2.30081024 -0.13931284 -2.16183958]\n",
      " [-3.13765365 -0.18030401  3.31837399]\n",
      " [-1.46740109 -1.36580696  2.83335274]]\n",
      "1447000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10851982296913656\n",
      "[[ 1.00153874  0.79052875 -1.79219714]\n",
      " [ 2.30129131 -0.13918279 -2.16245071]\n",
      " [-3.13829586 -0.18039008  3.31910227]\n",
      " [-1.46771667 -1.3662327   2.83409406]]\n",
      "1448000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10848993745163026\n",
      "[[ 1.00177634  0.79064767 -1.79255367]\n",
      " [ 2.30177208 -0.13905279 -2.16306147]\n",
      " [-3.13893766 -0.18047606  3.31983005]\n",
      " [-1.46803206 -1.36665819  2.83483494]]\n",
      "1449000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10846008667245116\n",
      "[[ 1.0020138   0.79076647 -1.79290992]\n",
      " [ 2.30225255 -0.13892284 -2.16367189]\n",
      " [-3.13957907 -0.18056196  3.32055736]\n",
      " [-1.46834727 -1.36708345  2.83557541]]\n",
      "1450000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10843027056788741\n",
      "[[ 1.00225112  0.79088515 -1.79326592]\n",
      " [ 2.30273272 -0.13879296 -2.16428194]\n",
      " [-3.14022008 -0.18064777  3.32128418]\n",
      " [-1.46866229 -1.36750846  2.83631544]]\n",
      "1451000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10840048907438596\n",
      "[[ 1.00248829  0.7910037  -1.79362164]\n",
      " [ 2.30321258 -0.13866312 -2.16489164]\n",
      " [-3.14086069 -0.1807335   3.32201053]\n",
      " [-1.46897713 -1.36793324  2.83705505]]\n",
      "1452000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10837074212855195\n",
      "[[ 1.00272532  0.79112213 -1.79397711]\n",
      " [ 2.30369214 -0.13853334 -2.16550098]\n",
      " [-3.14150091 -0.18081915  3.32273639]\n",
      " [-1.46929178 -1.36835778  2.83779424]]\n",
      "1453000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10834102966714805\n",
      "[[ 1.00296222  0.79124043 -1.7943323 ]\n",
      " [ 2.3041714  -0.13840361 -2.16610997]\n",
      " [-3.14214073 -0.18090471  3.32346177]\n",
      " [-1.46960624 -1.36878208  2.83853301]]\n",
      "1454000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10831135162709411\n",
      "[[ 1.00319897  0.79135861 -1.79468723]\n",
      " [ 2.30465037 -0.13827394 -2.16671861]\n",
      " [-3.14278015 -0.18099019  3.32418667]\n",
      " [-1.46992052 -1.36920614  2.83927135]]\n",
      "1455000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10828170794546713\n",
      "[[ 1.00343558  0.79147667 -1.7950419 ]\n",
      " [ 2.30512903 -0.13814432 -2.16732689]\n",
      " [-3.14341918 -0.18107558  3.3249111 ]\n",
      " [-1.47023461 -1.36962997  2.84000926]]\n",
      "1456000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10825209855949962\n",
      "[[ 1.00367205  0.79159461 -1.79539631]\n",
      " [ 2.30560739 -0.13801475 -2.16793482]\n",
      " [-3.14405782 -0.18116089  3.32563504]\n",
      " [-1.47054852 -1.37005355  2.84074676]]\n",
      "1457000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1082225234065801\n",
      "[[ 1.00390837  0.79171242 -1.79575045]\n",
      " [ 2.30608545 -0.13788524 -2.16854239]\n",
      " [-3.14469606 -0.18124611  3.32635851]\n",
      " [-1.47086224 -1.3704769   2.84148383]]\n",
      "1458000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1081929824242525\n",
      "[[ 1.00414456  0.79183011 -1.79610433]\n",
      " [ 2.30656321 -0.13775578 -2.16914961]\n",
      " [-3.14533392 -0.18133126  3.3270815 ]\n",
      " [-1.47117578 -1.37090002  2.84222048]]\n",
      "1459000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10816347555021523\n",
      "[[ 1.00438061  0.79194768 -1.79645794]\n",
      " [ 2.30704067 -0.13762638 -2.16975647]\n",
      " [-3.14597137 -0.18141631  3.32780402]\n",
      " [-1.47148914 -1.37132289  2.84295672]]\n",
      "1460000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10813400272232104\n",
      "[[ 1.00461651  0.79206513 -1.79681129]\n",
      " [ 2.30751784 -0.13749703 -2.17036299]\n",
      " [-3.14660844 -0.18150129  3.32852606]\n",
      " [-1.47180231 -1.37174553  2.84369253]]\n",
      "1461000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10810456387857634\n",
      "[[ 1.00485228  0.79218245 -1.79716439]\n",
      " [ 2.30799471 -0.13736773 -2.17096915]\n",
      " [-3.14724511 -0.18158618  3.32924762]\n",
      " [-1.47211529 -1.37216794  2.84442792]]\n",
      "1462000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1080751589571411\n",
      "[[ 1.00508791  0.79229966 -1.79751722]\n",
      " [ 2.30847127 -0.13723849 -2.17157496]\n",
      " [-3.1478814  -0.18167099  3.32996872]\n",
      " [-1.4724281  -1.37259011  2.84516289]]\n",
      "1463000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10804578789632799\n",
      "[[ 1.00532339  0.79241674 -1.79786978]\n",
      " [ 2.30894755 -0.1371093  -2.17218042]\n",
      " [-3.14851729 -0.18175571  3.33068933]\n",
      " [-1.47274072 -1.37301204  2.84589744]]\n",
      "1464000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10801645063460186\n",
      "[[ 1.00555874  0.7925337  -1.79822209]\n",
      " [ 2.30942352 -0.13698017 -2.17278553]\n",
      " [-3.14915279 -0.18184035  3.33140947]\n",
      " [-1.47305316 -1.37343374  2.84663158]]\n",
      "1465000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10798714711057954\n",
      "[[ 1.00579394  0.79265054 -1.79857414]\n",
      " [ 2.3098992  -0.13685109 -2.17339029]\n",
      " [-3.1497879  -0.18192491  3.33212915]\n",
      " [-1.47336541 -1.3738552   2.8473653 ]]\n",
      "1466000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10795787726302922\n",
      "[[ 1.00602901  0.79276726 -1.79892593]\n",
      " [ 2.31037458 -0.13672206 -2.1739947 ]\n",
      " [-3.15042263 -0.18200938  3.33284834]\n",
      " [-1.47367748 -1.37427643  2.8480986 ]]\n",
      "1467000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10792864103087005\n",
      "[[ 1.00626394  0.79288386 -1.79927745]\n",
      " [ 2.31084967 -0.13659309 -2.17459876]\n",
      " [-3.15105696 -0.18209378  3.33356707]\n",
      " [-1.47398937 -1.37469742  2.84883148]]\n",
      "1468000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10789943835317174\n",
      "[[ 1.00649873  0.79300034 -1.79962872]\n",
      " [ 2.31132446 -0.13646417 -2.17520247]\n",
      " [-3.15169091 -0.18217809  3.33428533]\n",
      " [-1.47430108 -1.37511818  2.84956395]]\n",
      "1469000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1078702691691538\n",
      "[[ 1.00673338  0.7931167  -1.79997973]\n",
      " [ 2.31179896 -0.1363353  -2.17580583]\n",
      " [-3.15232447 -0.18226232  3.33500312]\n",
      " [-1.4746126  -1.37553871  2.850296  ]]\n",
      "1470000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10784113341818519\n",
      "[[ 1.00696789  0.79323294 -1.80033048]\n",
      " [ 2.31227316 -0.13620649 -2.17640885]\n",
      " [-3.15295764 -0.18234646  3.33572043]\n",
      " [-1.47492395 -1.375959    2.85102764]]\n",
      "1471000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10781203103978428\n",
      "[[ 1.00720227  0.79334905 -1.80068097]\n",
      " [ 2.31274706 -0.13607773 -2.17701151]\n",
      " [-3.15359042 -0.18243052  3.33643728]\n",
      " [-1.47523511 -1.37637906  2.85175886]]\n",
      "1472000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1077829619736176\n",
      "[[ 1.0074365   0.79346505 -1.80103121]\n",
      " [ 2.31322068 -0.13594903 -2.17761383]\n",
      " [-3.15422282 -0.18251451  3.33715366]\n",
      " [-1.47554609 -1.37679889  2.85248967]]\n",
      "1473000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10775392615949997\n",
      "[[ 1.0076706   0.79358093 -1.80138119]\n",
      " [ 2.313694   -0.13582038 -2.1782158 ]\n",
      " [-3.15485483 -0.18259841  3.33786957]\n",
      " [-1.47585689 -1.37721849  2.85322006]]\n",
      "1474000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10772492353739409\n",
      "[[ 1.00790456  0.79369669 -1.80173091]\n",
      " [ 2.31416702 -0.13569178 -2.17881742]\n",
      " [-3.15548646 -0.18268222  3.33858502]\n",
      " [-1.47616751 -1.37763785  2.85395004]]\n",
      "1475000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10769595404740955\n",
      "[[ 1.00813838  0.79381234 -1.80208037]\n",
      " [ 2.31463976 -0.13556324 -2.1794187 ]\n",
      " [-3.1561177  -0.18276596  3.3393    ]\n",
      " [-1.47647795 -1.37805698  2.85467961]]\n",
      "1476000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10766701762980266\n",
      "[[ 1.00837206  0.79392786 -1.80242957]\n",
      " [ 2.3151122  -0.13543475 -2.18001963]\n",
      " [-3.15674856 -0.18284961  3.34001451]\n",
      " [-1.47678821 -1.37847588  2.85540877]]\n",
      "1477000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10763811422497672\n",
      "[[ 1.00860561  0.79404326 -1.80277852]\n",
      " [ 2.31558435 -0.13530631 -2.18062021]\n",
      " [-3.15737903 -0.18293319  3.34072855]\n",
      " [-1.47709828 -1.37889454  2.85613751]]\n",
      "1478000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10760924377347997\n",
      "[[ 1.00883901  0.79415855 -1.80312722]\n",
      " [ 2.3160562  -0.13517793 -2.18122045]\n",
      " [-3.15800912 -0.18301668  3.34144214]\n",
      " [-1.47740818 -1.37931298  2.85686585]]\n",
      "1479000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10758040621600676\n",
      "[[ 1.00907229  0.79427372 -1.80347566]\n",
      " [ 2.31652777 -0.1350496  -2.18182035]\n",
      " [-3.15863883 -0.18310009  3.34215525]\n",
      " [-1.4777179  -1.37973118  2.85759377]]\n",
      "1480000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10755160149339578\n",
      "[[ 1.00930542  0.79438877 -1.80382384]\n",
      " [ 2.31699904 -0.13492133 -2.1824199 ]\n",
      " [-3.15926816 -0.18318342  3.34286791]\n",
      " [-1.47802744 -1.38014916  2.85832128]]\n",
      "1481000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10752282954663088\n",
      "[[ 1.00953842  0.7945037  -1.80417177]\n",
      " [ 2.31747003 -0.13479311 -2.1830191 ]\n",
      " [-3.1598971  -0.18326667  3.3435801 ]\n",
      " [-1.4783368  -1.3805669   2.85904838]]\n",
      "1482000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10749409031683935\n",
      "[[ 1.00977128  0.79461851 -1.80451944]\n",
      " [ 2.31794072 -0.13466494 -2.18361796]\n",
      " [-3.16052566 -0.18334984  3.34429183]\n",
      " [-1.47864598 -1.38098441  2.85977508]]\n",
      "1483000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1074653837452926\n",
      "[[ 1.010004    0.79473321 -1.80486686]\n",
      " [ 2.31841112 -0.13453683 -2.18421648]\n",
      " [-3.16115384 -0.18343292  3.3450031 ]\n",
      " [-1.47895498 -1.3814017   2.86050136]]\n",
      "1484000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10743670977340476\n",
      "[[ 1.01023659  0.79484779 -1.80521403]\n",
      " [ 2.31888124 -0.13440876 -2.18481465]\n",
      " [-3.16178164 -0.18351593  3.3457139 ]\n",
      " [-1.4792638  -1.38181875  2.86122724]]\n",
      "1485000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1074080683427331\n",
      "[[ 1.01046904  0.79496225 -1.80556094]\n",
      " [ 2.31935106 -0.13428076 -2.18541249]\n",
      " [-3.16240906 -0.18359885  3.34642425]\n",
      " [-1.47957245 -1.38223557  2.86195271]]\n",
      "1486000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10737945939497702\n",
      "[[ 1.01070136  0.79507659 -1.80590761]\n",
      " [ 2.3198206  -0.1341528  -2.18600998]\n",
      " [-3.1630361  -0.1836817   3.34713413]\n",
      " [-1.47988091 -1.38265217  2.86267777]]\n",
      "1487000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10735088287197787\n",
      "[[ 1.01093354  0.79519082 -1.80625401]\n",
      " [ 2.32028985 -0.1340249  -2.18660712]\n",
      " [-3.16366276 -0.18376447  3.34784356]\n",
      " [-1.4801892  -1.38306854  2.86340242]]\n",
      "1488000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10732233871571814\n",
      "[[ 1.01116558  0.79530493 -1.80660017]\n",
      " [ 2.32075881 -0.13389706 -2.18720393]\n",
      " [-3.16428904 -0.18384715  3.34855253]\n",
      " [-1.48049731 -1.38348467  2.86412667]]\n",
      "1489000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10729382686832163\n",
      "[[ 1.01139749  0.79541893 -1.80694607]\n",
      " [ 2.32122748 -0.13376926 -2.18780039]\n",
      " [-3.16491494 -0.18392976  3.34926103]\n",
      " [-1.48080524 -1.38390058  2.86485051]]\n",
      "1490000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10726534727205253\n",
      "[[ 1.01162926  0.79553281 -1.80729172]\n",
      " [ 2.32169586 -0.13364152 -2.18839652]\n",
      " [-3.16554047 -0.18401228  3.34996908]\n",
      " [-1.481113   -1.38431626  2.86557395]]\n",
      "1491000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10723689986931523\n",
      "[[ 1.0118609   0.79564657 -1.80763712]\n",
      " [ 2.32216396 -0.13351384 -2.1889923 ]\n",
      " [-3.16616562 -0.18409473  3.35067668]\n",
      " [-1.48142057 -1.38473172  2.86629698]]\n",
      "1492000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10720848460265382\n",
      "[[ 1.0120924   0.79576022 -1.80798227]\n",
      " [ 2.32263177 -0.13338621 -2.18958774]\n",
      " [-3.16679039 -0.18417709  3.35138382]\n",
      " [-1.48172798 -1.38514694  2.86701961]]\n",
      "1493000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10718010141475148\n",
      "[[ 1.01232377  0.79587375 -1.80832717]\n",
      " [ 2.32309929 -0.13325863 -2.19018285]\n",
      " [-3.16741478 -0.18425938  3.3520905 ]\n",
      " [-1.4820352  -1.38556194  2.86774183]]\n",
      "1494000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10715175024843059\n",
      "[[ 1.012555    0.79598716 -1.80867182]\n",
      " [ 2.32356653 -0.1331311  -2.19077761]\n",
      " [-3.1680388  -0.18434159  3.35279672]\n",
      " [-1.48234225 -1.38597672  2.86846365]]\n",
      "1495000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10712343104665156\n",
      "[[ 1.0127861   0.79610046 -1.80901622]\n",
      " [ 2.32403348 -0.13300363 -2.19137203]\n",
      " [-3.16866245 -0.18442371  3.35350249]\n",
      " [-1.48264912 -1.38639126  2.86918507]]\n",
      "1496000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1070951437525132\n",
      "[[ 1.01301707  0.79621365 -1.80936037]\n",
      " [ 2.32450015 -0.13287621 -2.19196612]\n",
      " [-3.16928571 -0.18450576  3.35420781]\n",
      " [-1.48295581 -1.38680558  2.86990608]]\n",
      "1497000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10706688830925157\n",
      "[[ 1.0132479   0.79632672 -1.80970427]\n",
      " [ 2.32496653 -0.13274884 -2.19255987]\n",
      " [-3.16990861 -0.18458773  3.35491267]\n",
      " [-1.48326233 -1.38721967  2.87062669]]\n",
      "1498000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10703866466024005\n",
      "[[ 1.01347859  0.79643967 -1.81004792]\n",
      " [ 2.32543263 -0.13262153 -2.19315328]\n",
      " [-3.17053113 -0.18466962  3.35561708]\n",
      " [-1.48356868 -1.38763354  2.8713469 ]]\n",
      "1499000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10701047274898852\n",
      "[[ 1.01370915  0.79655251 -1.81039132]\n",
      " [ 2.32589844 -0.13249427 -2.19374635]\n",
      " [-3.17115327 -0.18475143  3.35632104]\n",
      " [-1.48387484 -1.38804718  2.87206671]]\n",
      "1500000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10698231251914353\n",
      "[[ 1.01393958  0.79666524 -1.81073448]\n",
      " [ 2.32636397 -0.13236707 -2.19433908]\n",
      " [-3.17177505 -0.18483317  3.35702454]\n",
      " [-1.48418084 -1.3884606   2.87278612]]\n",
      "1501000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10695418391448729\n",
      "[[ 1.01416988  0.79677785 -1.81107738]\n",
      " [ 2.32682922 -0.13223991 -2.19493148]\n",
      " [-3.17239645 -0.18491482  3.3577276 ]\n",
      " [-1.48448666 -1.38887379  2.87350513]]\n",
      "1502000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10692608687893781\n",
      "[[ 1.01440004  0.79689035 -1.81142004]\n",
      " [ 2.32729418 -0.13211281 -2.19552354]\n",
      " [-3.17301747 -0.18499639  3.3584302 ]\n",
      " [-1.4847923  -1.38928675  2.87422374]]\n",
      "1503000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1068980213565477\n",
      "[[ 1.01463006  0.79700273 -1.81176245]\n",
      " [ 2.32775886 -0.13198577 -2.19611527]\n",
      " [-3.17363813 -0.18507789  3.35913235]\n",
      " [-1.48509777 -1.3896995   2.87494195]]\n",
      "1504000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10686998729150453\n",
      "[[ 1.01485996  0.797115   -1.81210462]\n",
      " [ 2.32822325 -0.13185877 -2.19670666]\n",
      " [-3.17425841 -0.18515931  3.35983406]\n",
      " [-1.48540306 -1.39011201  2.87565976]]\n",
      "1505000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1068419846281302\n",
      "[[ 1.01508972  0.79722716 -1.81244654]\n",
      " [ 2.32868737 -0.13173184 -2.19729771]\n",
      " [-3.17487833 -0.18524065  3.36053531]\n",
      " [-1.48570818 -1.39052431  2.87637717]]\n",
      "1506000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1068140133108804\n",
      "[[ 1.01531935  0.7973392  -1.81278821]\n",
      " [ 2.3291512  -0.13160495 -2.19788843]\n",
      " [-3.17549787 -0.18532191  3.36123612]\n",
      " [-1.48601313 -1.39093638  2.87709419]]\n",
      "1507000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1067860732843442\n",
      "[[ 1.01554885  0.79745113 -1.81312963]\n",
      " [ 2.32961475 -0.13147812 -2.19847882]\n",
      " [-3.17611704 -0.1854031   3.36193647]\n",
      " [-1.4863179  -1.39134822  2.87781081]]\n",
      "1508000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1067581644932438\n",
      "[[ 1.01577821  0.79756295 -1.81347081]\n",
      " [ 2.33007802 -0.13135134 -2.19906887]\n",
      " [-3.17673584 -0.18548421  3.36263638]\n",
      " [-1.4866225  -1.39175984  2.87852703]]\n",
      "1509000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10673028688243398\n",
      "[[ 1.01600744  0.79767466 -1.81381175]\n",
      " [ 2.33054101 -0.13122461 -2.19965858]\n",
      " [-3.17735428 -0.18556523  3.36333584]\n",
      " [-1.48692692 -1.39217124  2.87924285]]\n",
      "1510000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10670244039690177\n",
      "[[ 1.01623654  0.79778625 -1.81415244]\n",
      " [ 2.33100372 -0.13109794 -2.20024797]\n",
      " [-3.17797234 -0.18564619  3.36403486]\n",
      " [-1.48723117 -1.39258242  2.87995828]]\n",
      "1511000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10667462498176611\n",
      "[[ 1.01646551  0.79789773 -1.81449289]\n",
      " [ 2.33146615 -0.13097132 -2.20083701]\n",
      " [-3.17859004 -0.18572706  3.36473343]\n",
      " [-1.48753525 -1.39299338  2.88067331]]\n",
      "1512000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10664684058227711\n",
      "[[ 1.01669434  0.79800909 -1.81483309]\n",
      " [ 2.3319283  -0.13084475 -2.20142573]\n",
      " [-3.17920737 -0.18580786  3.36543156]\n",
      " [-1.48783916 -1.39340411  2.88138795]]\n",
      "1513000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1066190871438162\n",
      "[[ 1.01692304  0.79812035 -1.81517304]\n",
      " [ 2.33239017 -0.13071823 -2.20201411]\n",
      " [-3.17982433 -0.18588858  3.36612924]\n",
      " [-1.48814289 -1.39381462  2.88210219]]\n",
      "1514000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10659136461189554\n",
      "[[ 1.01715162  0.79823149 -1.81551276]\n",
      " [ 2.33285176 -0.13059177 -2.20260217]\n",
      " [-3.18044092 -0.18596922  3.36682647]\n",
      " [-1.48844645 -1.39422491  2.88281604]]\n",
      "1515000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10656367293215736\n",
      "[[ 1.01738006  0.79834252 -1.81585223]\n",
      " [ 2.33331307 -0.13046536 -2.20318989]\n",
      " [-3.18105715 -0.18604978  3.36752327]\n",
      " [-1.48874984 -1.39463497  2.8835295 ]]\n",
      "1516000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10653601205037369\n",
      "[[ 1.01760836  0.79845344 -1.81619146]\n",
      " [ 2.3337741  -0.13033901 -2.20377727]\n",
      " [-3.18167301 -0.18613027  3.36821962]\n",
      " [-1.48905306 -1.39504482  2.88424256]]\n",
      "1517000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1065083819124461\n",
      "[[ 1.01783654  0.79856425 -1.81653044]\n",
      " [ 2.33423486 -0.13021271 -2.20436433]\n",
      " [-3.18228851 -0.18621068  3.36891553]\n",
      " [-1.4893561  -1.39545444  2.88495523]]\n",
      "1518000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10648078246440515\n",
      "[[ 1.01806459  0.79867494 -1.81686919]\n",
      " [ 2.33469533 -0.13008646 -2.20495106]\n",
      " [-3.18290364 -0.18629102  3.36961099]\n",
      " [-1.48965898 -1.39586385  2.88566751]]\n",
      "1519000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10645321365241055\n",
      "[[ 1.0182925   0.79878553 -1.81720769]\n",
      " [ 2.33515553 -0.12996026 -2.20553745]\n",
      " [-3.18351841 -0.18637128  3.37030601]\n",
      " [-1.48996168 -1.39627303  2.8863794 ]]\n",
      "1520000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10642567542274986\n",
      "[[ 1.01852029  0.798896   -1.81754595]\n",
      " [ 2.33561546 -0.12983412 -2.20612352]\n",
      " [-3.18413281 -0.18645146  3.3710006 ]\n",
      " [-1.49026421 -1.396682    2.88709089]]\n",
      "1521000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10639816772183859\n",
      "[[ 1.01874794  0.79900637 -1.81788396]\n",
      " [ 2.3360751  -0.12970803 -2.20670926]\n",
      " [-3.18474685 -0.18653156  3.37169474]\n",
      " [-1.49056657 -1.39709074  2.88780199]]\n",
      "1522000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1063706904962199\n",
      "[[ 1.01897547  0.79911662 -1.81822174]\n",
      " [ 2.33653447 -0.12958199 -2.20729466]\n",
      " [-3.18536052 -0.18661159  3.37238844]\n",
      " [-1.49086876 -1.39749926  2.88851271]]\n",
      "1523000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10634324369256393\n",
      "[[ 1.01920286  0.79922676 -1.81855928]\n",
      " [ 2.33699357 -0.12945601 -2.20787974]\n",
      " [-3.18597383 -0.18669154  3.37308171]\n",
      " [-1.49117078 -1.39790757  2.88922303]]\n",
      "1524000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10631582725766785\n",
      "[[ 1.01943013  0.79933679 -1.81889657]\n",
      " [ 2.33745238 -0.12933008 -2.20846449]\n",
      " [-3.18658678 -0.18677142  3.37377453]\n",
      " [-1.49147262 -1.39831565  2.88993296]]\n",
      "1525000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10628844113845505\n",
      "[[ 1.01965726  0.79944671 -1.81923363]\n",
      " [ 2.33791093 -0.1292042  -2.20904891]\n",
      " [-3.18719937 -0.18685122  3.37446692]\n",
      " [-1.4917743  -1.39872352  2.89064251]]\n",
      "1526000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10626108528197506\n",
      "[[ 1.01988427  0.79955653 -1.81957045]\n",
      " [ 2.33836919 -0.12907837 -2.209633  ]\n",
      " [-3.18781159 -0.18693095  3.37515887]\n",
      " [-1.49207581 -1.39913117  2.89135167]]\n",
      "1527000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10623375963540276\n",
      "[[ 1.02011114  0.79966623 -1.81990702]\n",
      " [ 2.33882719 -0.1289526  -2.21021677]\n",
      " [-3.18842346 -0.18701059  3.37585039]\n",
      " [-1.49237715 -1.3995386   2.89206043]]\n",
      "1528000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10620646414603857\n",
      "[[ 1.02033789  0.79977582 -1.82024336]\n",
      " [ 2.3392849  -0.12882688 -2.21080021]\n",
      " [-3.18903496 -0.18709017  3.37654146]\n",
      " [-1.49267832 -1.39994581  2.89276881]]\n",
      "1529000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10617919876130773\n",
      "[[ 1.0205645   0.7998853  -1.82057946]\n",
      " [ 2.33974235 -0.12870121 -2.21138332]\n",
      " [-3.1896461  -0.18716967  3.3772321 ]\n",
      " [-1.49297932 -1.4003528   2.89347681]]\n",
      "1530000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10615196342875997\n",
      "[[ 1.02079099  0.79999468 -1.82091532]\n",
      " [ 2.34019952 -0.1285756  -2.2119661 ]\n",
      " [-3.19025689 -0.18724909  3.37792231]\n",
      " [-1.49328015 -1.40075958  2.89418441]]\n",
      "1531000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10612475809606887\n",
      "[[ 1.02101735  0.80010394 -1.82125095]\n",
      " [ 2.34065642 -0.12845004 -2.21254856]\n",
      " [-3.19086731 -0.18732844  3.37861208]\n",
      " [-1.49358081 -1.40116614  2.89489163]]\n",
      "1532000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1060975827110325\n",
      "[[ 1.02124358  0.8002131  -1.82158633]\n",
      " [ 2.34111304 -0.12832453 -2.21313069]\n",
      " [-3.19147737 -0.18740771  3.37930141]\n",
      " [-1.4938813  -1.40157248  2.89559847]]\n",
      "1533000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10607043722157157\n",
      "[[ 1.02146968  0.80032215 -1.82192148]\n",
      " [ 2.34156939 -0.12819907 -2.2137125 ]\n",
      " [-3.19208708 -0.18748691  3.37999032]\n",
      " [-1.49418163 -1.4019786   2.89630491]]\n",
      "1534000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10604332157573022\n",
      "[[ 1.02169565  0.80043108 -1.82225639]\n",
      " [ 2.34202547 -0.12807367 -2.21429398]\n",
      " [-3.19269642 -0.18756603  3.38067879]\n",
      " [-1.49448178 -1.40238451  2.89701098]]\n",
      "1535000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10601623572167504\n",
      "[[ 1.02192149  0.80053991 -1.82259106]\n",
      " [ 2.34248128 -0.12794832 -2.21487514]\n",
      " [-3.19330541 -0.18764507  3.38136682]\n",
      " [-1.49478177 -1.4027902   2.89771666]]\n",
      "1536000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10598917960769517\n",
      "[[ 1.02214721  0.80064864 -1.8229255 ]\n",
      " [ 2.34293681 -0.12782302 -2.21545597]\n",
      " [-3.19391405 -0.18772405  3.38205443]\n",
      " [-1.49508159 -1.40319567  2.89842195]]\n",
      "1537000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10596215318220148\n",
      "[[ 1.02237279  0.80075725 -1.8232597 ]\n",
      " [ 2.34339207 -0.12769778 -2.21603648]\n",
      " [-3.19452232 -0.18780294  3.3827416 ]\n",
      " [-1.49538124 -1.40360093  2.89912686]]\n",
      "1538000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1059351563937263\n",
      "[[ 1.02259825  0.80086576 -1.82359366]\n",
      " [ 2.34384707 -0.12757258 -2.21661666]\n",
      " [-3.19513024 -0.18788177  3.38342834]\n",
      " [-1.49568073 -1.40400598  2.89983139]]\n",
      "1539000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10590818919092353\n",
      "[[ 1.02282359  0.80097415 -1.82392739]\n",
      " [ 2.34430179 -0.12744744 -2.21719652]\n",
      " [-3.1957378  -0.18796052  3.38411465]\n",
      " [-1.49598004 -1.4044108   2.90053553]]\n",
      "1540000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10588125152256767\n",
      "[[ 1.02304879  0.80108244 -1.82426089]\n",
      " [ 2.34475624 -0.12732236 -2.21777606]\n",
      " [-3.19634501 -0.18803919  3.38480053]\n",
      " [-1.49627919 -1.40481542  2.9012393 ]]\n",
      "1541000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10585434333755372\n",
      "[[ 1.02327387  0.80119063 -1.82459415]\n",
      " [ 2.34521042 -0.12719732 -2.21835528]\n",
      " [-3.19695186 -0.18811779  3.38548598]\n",
      " [-1.49657818 -1.40521981  2.90194268]]\n",
      "1542000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10582746458489713\n",
      "[[ 1.02349881  0.8012987  -1.82492717]\n",
      " [ 2.34566433 -0.12707234 -2.21893417]\n",
      " [-3.19755836 -0.18819632  3.38617101]\n",
      " [-1.49687699 -1.405624    2.90264567]]\n",
      "1543000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10580061521373246\n",
      "[[ 1.02372364  0.80140667 -1.82525996]\n",
      " [ 2.34611797 -0.12694741 -2.21951274]\n",
      " [-3.1981645  -0.18827477  3.3868556 ]\n",
      " [-1.49717564 -1.40602796  2.90334829]]\n",
      "1544000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10577379517331437\n",
      "[[ 1.02394833  0.80151453 -1.82559252]\n",
      " [ 2.34657134 -0.12682254 -2.22009099]\n",
      " [-3.19877029 -0.18835315  3.38753977]\n",
      " [-1.49747413 -1.40643172  2.90405053]]\n",
      "1545000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10574700441301604\n",
      "[[ 1.0241729   0.80162229 -1.82592484]\n",
      " [ 2.34702445 -0.12669771 -2.22066892]\n",
      " [-3.19937572 -0.18843145  3.3882235 ]\n",
      " [-1.49777244 -1.40683526  2.90475239]]\n",
      "1546000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10572024288232974\n",
      "[[ 1.02439734  0.80172994 -1.82625693]\n",
      " [ 2.34747728 -0.12657294 -2.22124652]\n",
      " [-3.1999808  -0.18850968  3.38890682]\n",
      " [-1.49807059 -1.40723858  2.90545386]]\n",
      "1547000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10569351053086595\n",
      "[[ 1.02462165  0.80183748 -1.82658878]\n",
      " [ 2.34792985 -0.12644822 -2.22182381]\n",
      " [-3.20058553 -0.18858784  3.3895897 ]\n",
      " [-1.49836858 -1.4076417   2.90615496]]\n",
      "1548000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10566680730835323\n",
      "[[ 1.02484584  0.80194491 -1.82692041]\n",
      " [ 2.34838215 -0.12632356 -2.22240077]\n",
      " [-3.2011899  -0.18866592  3.39027216]\n",
      " [-1.4986664  -1.4080446   2.90685568]]\n",
      "1549000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10564013316463772\n",
      "[[ 1.0250699   0.80205224 -1.8272518 ]\n",
      " [ 2.34883418 -0.12619894 -2.22297742]\n",
      " [-3.20179393 -0.18874393  3.39095419]\n",
      " [-1.49896405 -1.40844728  2.90755602]]\n",
      "1550000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.105613488049683\n",
      "[[ 1.02529384  0.80215947 -1.82758296]\n",
      " [ 2.34928594 -0.12607438 -2.22355374]\n",
      " [-3.2023976  -0.18882187  3.3916358 ]\n",
      " [-1.49926154 -1.40884976  2.90825598]]\n",
      "1551000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10558687191356939\n",
      "[[ 1.02551765  0.80226658 -1.82791388]\n",
      " [ 2.34973744 -0.12594987 -2.22412975]\n",
      " [-3.20300092 -0.18889973  3.39231699]\n",
      " [-1.49955886 -1.40925202  2.90895557]]\n",
      "1552000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10556028470649424\n",
      "[[ 1.02574133  0.80237359 -1.82824458]\n",
      " [ 2.35018867 -0.12582541 -2.22470543]\n",
      " [-3.20360389 -0.18897752  3.39299775]\n",
      " [-1.49985602 -1.40965407  2.90965478]]\n",
      "1553000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10553372637877063\n",
      "[[ 1.02596489  0.8024805  -1.82857504]\n",
      " [ 2.35063963 -0.12570101 -2.2252808 ]\n",
      " [-3.20420651 -0.18905524  3.39367809]\n",
      " [-1.50015302 -1.4100559   2.91035361]]\n",
      "1554000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10550719688082795\n",
      "[[ 1.02618832  0.8025873  -1.82890527]\n",
      " [ 2.35109033 -0.12557666 -2.22585585]\n",
      " [-3.20480878 -0.18913288  3.394358  ]\n",
      " [-1.50044985 -1.41045753  2.91105206]]\n",
      "1555000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10548069616321115\n",
      "[[ 1.02641163  0.802694   -1.82923528]\n",
      " [ 2.35154076 -0.12545236 -2.22643058]\n",
      " [-3.20541071 -0.18921046  3.3950375 ]\n",
      " [-1.50074651 -1.41085894  2.91175014]]\n",
      "1556000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10545422417658026\n",
      "[[ 1.02663481  0.80280059 -1.82956505]\n",
      " [ 2.35199093 -0.12532811 -2.227005  ]\n",
      " [-3.20601228 -0.18928795  3.39571657]\n",
      " [-1.50104301 -1.41126014  2.91244784]]\n",
      "1557000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10542778087171055\n",
      "[[ 1.02685786  0.80290707 -1.82989459]\n",
      " [ 2.35244083 -0.12520392 -2.22757909]\n",
      " [-3.2066135  -0.18936538  3.39639522]\n",
      " [-1.50133935 -1.41166114  2.91314517]]\n",
      "1558000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10540136619949143\n",
      "[[ 1.02708079  0.80301345 -1.8302239 ]\n",
      " [ 2.35289047 -0.12507978 -2.22815287]\n",
      " [-3.20721438 -0.18944274  3.39707345]\n",
      " [-1.50163552 -1.41206192  2.91384212]]\n",
      "1559000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10537498011092698\n",
      "[[ 1.0273036   0.80311973 -1.83055298]\n",
      " [ 2.35333984 -0.12495569 -2.22872634]\n",
      " [-3.2078149  -0.18952002  3.39775126]\n",
      " [-1.50193153 -1.41246248  2.9145387 ]]\n",
      "1560000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.105348622557135\n",
      "[[ 1.02752628  0.8032259  -1.83088184]\n",
      " [ 2.35378895 -0.12483165 -2.22929948]\n",
      " [-3.20841508 -0.18959723  3.39842864]\n",
      " [-1.50222738 -1.41286284  2.91523491]]\n",
      "1561000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10532229348934673\n",
      "[[ 1.02774884  0.80333197 -1.83121046]\n",
      " [ 2.35423779 -0.12470766 -2.22987231]\n",
      " [-3.20901492 -0.18967436  3.39910561]\n",
      " [-1.50252306 -1.41326299  2.91593074]]\n",
      "1562000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10529599285890696\n",
      "[[ 1.02797127  0.80343793 -1.83153886]\n",
      " [ 2.35468637 -0.12458373 -2.23044483]\n",
      " [-3.2096144  -0.18975143  3.39978217]\n",
      " [-1.50281858 -1.41366293  2.9166262 ]]\n",
      "1563000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10526972061727319\n",
      "[[ 1.02819358  0.80354379 -1.83186703]\n",
      " [ 2.35513469 -0.12445985 -2.23101703]\n",
      " [-3.21021354 -0.18982842  3.4004583 ]\n",
      " [-1.50311394 -1.41406266  2.91732129]]\n",
      "1564000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10524347671601537\n",
      "[[ 1.02841576  0.80364955 -1.83219497]\n",
      " [ 2.35558275 -0.12433602 -2.23158891]\n",
      " [-3.21081234 -0.18990534  3.40113402]\n",
      " [-1.50340914 -1.41446218  2.918016  ]]\n",
      "1565000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10521726110681603\n",
      "[[ 1.02863782  0.8037552  -1.83252268]\n",
      " [ 2.35603054 -0.12421224 -2.23216048]\n",
      " [-3.21141079 -0.18998219  3.40180931]\n",
      " [-1.50370417 -1.41486149  2.91871035]]\n",
      "1566000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10519107374146931\n",
      "[[ 1.02885976  0.80386075 -1.83285016]\n",
      " [ 2.35647807 -0.12408852 -2.23273173]\n",
      " [-3.21200889 -0.19005897  3.4024842 ]\n",
      " [-1.50399904 -1.41526059  2.91940432]]\n",
      "1567000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10516491457188122\n",
      "[[ 1.02908157  0.8039662  -1.83317742]\n",
      " [ 2.35692534 -0.12396485 -2.23330267]\n",
      " [-3.21260665 -0.19013568  3.40315866]\n",
      " [-1.50429375 -1.41565949  2.92009792]]\n",
      "1568000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10513878355006884\n",
      "[[ 1.02930326  0.80407154 -1.83350445]\n",
      " [ 2.35737235 -0.12384123 -2.2338733 ]\n",
      " [-3.21320407 -0.19021231  3.40383271]\n",
      " [-1.5045883  -1.41605817  2.92079115]]\n",
      "1569000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10511268062816025\n",
      "[[ 1.02952482  0.80417678 -1.83383125]\n",
      " [ 2.35781909 -0.12371766 -2.23444361]\n",
      " [-3.21380114 -0.19028887  3.40450635]\n",
      " [-1.50488268 -1.41645665  2.92148401]]\n",
      "1570000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10508660575839396\n",
      "[[ 1.02974626  0.80428191 -1.83415783]\n",
      " [ 2.35826558 -0.12359414 -2.23501361]\n",
      " [-3.21439787 -0.19036537  3.40517957]\n",
      " [-1.5051769  -1.41685491  2.9221765 ]]\n",
      "1571000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10506055889311905\n",
      "[[ 1.02996758  0.80438695 -1.83448418]\n",
      " [ 2.3587118  -0.12347068 -2.2355833 ]\n",
      " [-3.21499425 -0.19044179  3.40585238]\n",
      " [-1.50547097 -1.41725297  2.92286863]]\n",
      "1572000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10503453998479452\n",
      "[[ 1.03018878  0.80449188 -1.83481031]\n",
      " [ 2.35915776 -0.12334727 -2.23615268]\n",
      " [-3.2155903  -0.19051814  3.40652477]\n",
      " [-1.50576487 -1.41765083  2.92356038]]\n",
      "1573000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10500854898598919\n",
      "[[ 1.03040985  0.80459671 -1.83513621]\n",
      " [ 2.35960347 -0.12322391 -2.23672174]\n",
      " [-3.216186   -0.19059442  3.40719675]\n",
      " [-1.50605861 -1.41804847  2.92425176]]\n",
      "1574000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10498258584938078\n",
      "[[ 1.0306308   0.80470144 -1.83546189]\n",
      " [ 2.36004891 -0.1231006  -2.23729049]\n",
      " [-3.21678136 -0.19067062  3.40786832]\n",
      " [-1.50635219 -1.41844591  2.92494278]]\n",
      "1575000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10495665052775635\n",
      "[[ 1.03085163  0.80480606 -1.83578734]\n",
      " [ 2.36049409 -0.12297735 -2.23785893]\n",
      " [-3.21737637 -0.19074676  3.40853947]\n",
      " [-1.5066456  -1.41884314  2.92563343]]\n",
      "1576000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10493074297401153\n",
      "[[ 1.03107233  0.80491058 -1.83611257]\n",
      " [ 2.36093902 -0.12285414 -2.23842706]\n",
      " [-3.21797105 -0.19082283  3.40921021]\n",
      " [-1.50693886 -1.41924016  2.92632371]]\n",
      "1577000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10490486314115041\n",
      "[[ 1.03129291  0.805015   -1.83643757]\n",
      " [ 2.36138368 -0.12273099 -2.23899487]\n",
      " [-3.21856539 -0.19089883  3.40988055]\n",
      " [-1.50723196 -1.41963698  2.92701363]]\n",
      "1578000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10487901098228508\n",
      "[[ 1.03151337  0.80511932 -1.83676235]\n",
      " [ 2.36182809 -0.12260789 -2.23956238]\n",
      " [-3.21915938 -0.19097475  3.41055047]\n",
      " [-1.5075249  -1.42003359  2.92770318]]\n",
      "1579000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1048531864506354\n",
      "[[ 1.03173371  0.80522354 -1.83708691]\n",
      " [ 2.36227224 -0.12248484 -2.24012958]\n",
      " [-3.21975304 -0.19105061  3.41121998]\n",
      " [-1.50781768 -1.42043     2.92839236]]\n",
      "1580000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1048273894995286\n",
      "[[ 1.03195393  0.80532766 -1.83741124]\n",
      " [ 2.36271613 -0.12236185 -2.24069646]\n",
      " [-3.22034636 -0.19112639  3.41188908]\n",
      " [-1.5081103  -1.4208262   2.92908118]]\n",
      "1581000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10480162008239935\n",
      "[[ 1.03217402  0.80543167 -1.83773535]\n",
      " [ 2.36315977 -0.12223891 -2.24126304]\n",
      " [-3.22093933 -0.19120211  3.41255777]\n",
      " [-1.50840276 -1.42122219  2.92976964]]\n",
      "1582000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10477587815278867\n",
      "[[ 1.03239399  0.80553559 -1.83805923]\n",
      " [ 2.36360314 -0.12211601 -2.24182931]\n",
      " [-3.22153197 -0.19127775  3.41322606]\n",
      " [-1.50869506 -1.42161798  2.93045773]]\n",
      "1583000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10475016366434442\n",
      "[[ 1.03261384  0.8056394  -1.8383829 ]\n",
      " [ 2.36404626 -0.12199317 -2.24239527]\n",
      " [-3.22212427 -0.19135333  3.41389393]\n",
      " [-1.5089872  -1.42201357  2.93114545]]\n",
      "1584000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10472447657082068\n",
      "[[ 1.03283357  0.80574311 -1.83870634]\n",
      " [ 2.36448912 -0.12187039 -2.24296092]\n",
      " [-3.22271624 -0.19142883  3.4145614 ]\n",
      " [-1.50927918 -1.42240895  2.93183281]]\n",
      "1585000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10469881682607729\n",
      "[[ 1.03305318  0.80584673 -1.83902956]\n",
      " [ 2.36493173 -0.12174765 -2.24352626]\n",
      " [-3.22330786 -0.19150426  3.41522846]\n",
      " [-1.509571   -1.42280412  2.93251981]]\n",
      "1586000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10467318438407976\n",
      "[[ 1.03327267  0.80595024 -1.83935256]\n",
      " [ 2.36537408 -0.12162497 -2.24409129]\n",
      " [-3.22389915 -0.19157963  3.41589512]\n",
      " [-1.50986267 -1.42319909  2.93320644]]\n",
      "1587000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10464757919889876\n",
      "[[ 1.03349203  0.80605365 -1.83967534]\n",
      " [ 2.36581617 -0.12150233 -2.24465602]\n",
      " [-3.2244901  -0.19165493  3.41656136]\n",
      " [-1.51015417 -1.42359386  2.93389272]]\n",
      "1588000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10462200122470998\n",
      "[[ 1.03371128  0.80615696 -1.83999789]\n",
      " [ 2.36625801 -0.12137975 -2.24522044]\n",
      " [-3.22508072 -0.19173015  3.41722721]\n",
      " [-1.51044552 -1.42398842  2.93457863]]\n",
      "1589000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10459645041579405\n",
      "[[ 1.0339304   0.80626017 -1.84032023]\n",
      " [ 2.36669959 -0.12125722 -2.24578455]\n",
      " [-3.225671   -0.19180531  3.41789264]\n",
      " [-1.51073671 -1.42438278  2.93526417]]\n",
      "1590000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10457092672653562\n",
      "[[ 1.03414941  0.80636328 -1.84064234]\n",
      " [ 2.36714092 -0.12113475 -2.24634836]\n",
      " [-3.22626094 -0.1918804   3.41855767]\n",
      " [-1.51102774 -1.42477693  2.93594936]]\n",
      "1591000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10454543011142366\n",
      "[[ 1.03436829  0.80646629 -1.84096424]\n",
      " [ 2.36758199 -0.12101232 -2.24691185]\n",
      " [-3.22685055 -0.19195541  3.4192223 ]\n",
      " [-1.51131862 -1.42517088  2.93663419]]\n",
      "1592000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10451996052505076\n",
      "[[ 1.03458705  0.80656921 -1.84128591]\n",
      " [ 2.36802281 -0.12088995 -2.24747505]\n",
      " [-3.22743983 -0.19203036  3.41988653]\n",
      " [-1.51160933 -1.42556463  2.93731865]]\n",
      "1593000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.104494517922113\n",
      "[[ 1.0348057   0.80667202 -1.84160737]\n",
      " [ 2.36846338 -0.12076762 -2.24803793]\n",
      " [-3.22802877 -0.19210524  3.42055035]\n",
      " [-1.51189989 -1.42595818  2.93800276]]\n",
      "1594000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10446910225740964\n",
      "[[ 1.03502422  0.80677473 -1.84192861]\n",
      " [ 2.36890369 -0.12064535 -2.24860051]\n",
      " [-3.22861737 -0.19218006  3.42121376]\n",
      " [-1.51219029 -1.42635152  2.9386865 ]]\n",
      "1595000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10444371348584316\n",
      "[[ 1.03524262  0.80687735 -1.84224962]\n",
      " [ 2.36934375 -0.12052314 -2.24916279]\n",
      " [-3.22920565 -0.1922548   3.42187678]\n",
      " [-1.51248054 -1.42674466  2.93936989]]\n",
      "1596000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10441835156241823\n",
      "[[ 1.03546091  0.80697986 -1.84257042]\n",
      " [ 2.36978355 -0.12040097 -2.24972476]\n",
      " [-3.22979359 -0.19232947  3.42253939]\n",
      " [-1.51277063 -1.4271376   2.94005292]]\n",
      "1597000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1043930164422418\n",
      "[[ 1.03567907  0.80708228 -1.842891  ]\n",
      " [ 2.3702231  -0.12027885 -2.25028643]\n",
      " [-3.23038119 -0.19240408  3.4232016 ]\n",
      " [-1.51306056 -1.42753034  2.94073558]]\n",
      "1598000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10436770808052297\n",
      "[[ 1.03589711  0.8071846  -1.84321137]\n",
      " [ 2.3706624  -0.12015679 -2.25084779]\n",
      " [-3.23096847 -0.19247861  3.42386341]\n",
      " [-1.51335034 -1.42792287  2.94141789]]\n",
      "1599000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10434242643257247\n",
      "[[ 1.03611504  0.80728682 -1.84353151]\n",
      " [ 2.37110145 -0.12003478 -2.25140885]\n",
      " [-3.23155541 -0.19255308  3.42452483]\n",
      " [-1.51363996 -1.42831521  2.94209985]]\n",
      "1600000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10431717145380268\n",
      "[[ 1.03633284  0.80738894 -1.84385144]\n",
      " [ 2.37154024 -0.11991282 -2.2519696 ]\n",
      " [-3.23214202 -0.19262748  3.42518584]\n",
      " [-1.51392942 -1.42870734  2.94278144]]\n",
      "1601000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10429194309972686\n",
      "[[ 1.03655053  0.80749096 -1.84417115]\n",
      " [ 2.37197878 -0.11979091 -2.25253006]\n",
      " [-3.2327283  -0.19270181  3.42584645]\n",
      " [-1.51421873 -1.42909927  2.94346268]]\n",
      "1602000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10426674132595894\n",
      "[[ 1.0367681   0.80759289 -1.84449064]\n",
      " [ 2.37241707 -0.11966905 -2.25309021]\n",
      " [-3.23331425 -0.19277607  3.42650666]\n",
      " [-1.51450788 -1.429491    2.94414356]]\n",
      "1603000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1042415660882139\n",
      "[[ 1.03698555  0.80769471 -1.84480991]\n",
      " [ 2.37285511 -0.11954724 -2.25365005]\n",
      " [-3.23389987 -0.19285027  3.42716647]\n",
      " [-1.51479687 -1.42988253  2.94482409]]\n",
      "1604000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10421641734230669\n",
      "[[ 1.03720288  0.80779644 -1.84512897]\n",
      " [ 2.3732929  -0.11942549 -2.25420959]\n",
      " [-3.23448516 -0.1929244   3.42782589]\n",
      " [-1.51508572 -1.43027386  2.94550426]]\n",
      "1605000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1041912950441522\n",
      "[[ 1.03742009  0.80789807 -1.84544782]\n",
      " [ 2.37373044 -0.11930379 -2.25476884]\n",
      " [-3.23507011 -0.19299846  3.4284849 ]\n",
      " [-1.5153744  -1.43066499  2.94618407]]\n",
      "1606000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10416619914976498\n",
      "[[ 1.03763718  0.80799961 -1.84576644]\n",
      " [ 2.37416773 -0.11918213 -2.25532778]\n",
      " [-3.23565474 -0.19307245  3.42914352]\n",
      " [-1.51566293 -1.43105591  2.94686353]]\n",
      "1607000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1041411296152591\n",
      "[[ 1.03785416  0.80810104 -1.84608485]\n",
      " [ 2.37460477 -0.11906053 -2.25588641]\n",
      " [-3.23623904 -0.19314637  3.42980175]\n",
      " [-1.51595131 -1.43144664  2.94754264]]\n",
      "1608000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10411608639684784\n",
      "[[ 1.03807101  0.80820238 -1.84640305]\n",
      " [ 2.37504156 -0.11893899 -2.25644475]\n",
      " [-3.23682302 -0.19322023  3.43045958]\n",
      " [-1.51623953 -1.43183717  2.94822139]]\n",
      "1609000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10409106945084314\n",
      "[[ 1.03828775  0.80830363 -1.84672103]\n",
      " [ 2.3754781  -0.11881749 -2.25700279]\n",
      " [-3.23740666 -0.19329402  3.43111701]\n",
      " [-1.51652759 -1.4322275   2.94889978]]\n",
      "1610000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10406607873365543\n",
      "[[ 1.03850437  0.80840477 -1.8470388 ]\n",
      " [ 2.37591439 -0.11869604 -2.25756052]\n",
      " [-3.23798997 -0.19336774  3.43177404]\n",
      " [-1.51681551 -1.43261764  2.94957783]]\n",
      "1611000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10404111420179354\n",
      "[[ 1.03872087  0.80850582 -1.84735635]\n",
      " [ 2.37635043 -0.11857465 -2.25811796]\n",
      " [-3.23857296 -0.19344139  3.43243069]\n",
      " [-1.51710326 -1.43300757  2.95025552]]\n",
      "1612000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10401617581186431\n",
      "[[ 1.03893726  0.80860677 -1.84767368]\n",
      " [ 2.37678622 -0.1184533  -2.2586751 ]\n",
      " [-3.23915562 -0.19351498  3.43308693]\n",
      " [-1.51739087 -1.4333973   2.95093285]]\n",
      "1613000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10399126352057247\n",
      "[[ 1.03915353  0.80870763 -1.84799081]\n",
      " [ 2.37722176 -0.11833201 -2.25923193]\n",
      " [-3.23973796 -0.1935885   3.43374279]\n",
      " [-1.51767832 -1.43378684  2.95160984]]\n",
      "1614000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10396637728471991\n",
      "[[ 1.03936968  0.80880839 -1.84830772]\n",
      " [ 2.37765706 -0.11821077 -2.25978847]\n",
      " [-3.24031996 -0.19366195  3.43439825]\n",
      " [-1.51796561 -1.43417617  2.95228647]]\n",
      "1615000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10394151706120552\n",
      "[[ 1.03958571  0.80890905 -1.84862441]\n",
      " [ 2.37809211 -0.11808958 -2.26034471]\n",
      " [-3.24090164 -0.19373533  3.43505331]\n",
      " [-1.51825276 -1.43456531  2.95296276]]\n",
      "1616000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10391668280702548\n",
      "[[ 1.03980162  0.80900962 -1.84894089]\n",
      " [ 2.37852691 -0.11796844 -2.26090065]\n",
      " [-3.241483   -0.19380865  3.43570799]\n",
      " [-1.51853975 -1.43495425  2.95363869]]\n",
      "1617000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10389187447927259\n",
      "[[ 1.04001742  0.80911009 -1.84925716]\n",
      " [ 2.37896146 -0.11784736 -2.26145629]\n",
      " [-3.24206403 -0.1938819   3.43636227]\n",
      " [-1.51882658 -1.435343    2.95431427]]\n",
      "1618000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10386709203513567\n",
      "[[ 1.0402331   0.80921046 -1.84957322]\n",
      " [ 2.37939577 -0.11772632 -2.26201163]\n",
      " [-3.24264474 -0.19395509  3.43701616]\n",
      " [-1.51911327 -1.43573154  2.9549895 ]]\n",
      "1619000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1038423354318997\n",
      "[[ 1.04044867  0.80931074 -1.84988906]\n",
      " [ 2.37982983 -0.11760534 -2.26256667]\n",
      " [-3.24322512 -0.19402821  3.43766966]\n",
      " [-1.5193998  -1.43611989  2.95566438]]\n",
      "1620000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10381760462694559\n",
      "[[ 1.04066412  0.80941092 -1.8502047 ]\n",
      " [ 2.38026364 -0.1174844  -2.26312142]\n",
      " [-3.24380517 -0.19410126  3.43832277]\n",
      " [-1.51968618 -1.43650804  2.95633891]]\n",
      "1621000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10379289957774994\n",
      "[[ 1.04087945  0.80951101 -1.85052012]\n",
      " [ 2.38069721 -0.11736352 -2.26367587]\n",
      " [-3.24438491 -0.19417424  3.43897549]\n",
      " [-1.5199724  -1.436896    2.95701309]]\n",
      "1622000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1037682202418838\n",
      "[[ 1.04109467  0.80961101 -1.85083533]\n",
      " [ 2.38113053 -0.11724269 -2.26423002]\n",
      " [-3.24496432 -0.19424716  3.43962782]\n",
      " [-1.52025847 -1.43728376  2.95768692]]\n",
      "1623000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10374356657701424\n",
      "[[ 1.04130977  0.8097109  -1.85115032]\n",
      " [ 2.38156361 -0.11712191 -2.26478388]\n",
      " [-3.2455434  -0.19432002  3.44027975]\n",
      " [-1.5205444  -1.43767132  2.9583604 ]]\n",
      "1624000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10371893854090239\n",
      "[[ 1.04152475  0.80981071 -1.85146511]\n",
      " [ 2.38199644 -0.11700118 -2.26533744]\n",
      " [-3.24612217 -0.1943928   3.44093131]\n",
      " [-1.52083017 -1.43805869  2.95903354]]\n",
      "1625000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10369433609140385\n",
      "[[ 1.04173962  0.80991041 -1.85177969]\n",
      " [ 2.38242903 -0.1168805  -2.26589071]\n",
      " [-3.24670061 -0.19446552  3.44158247]\n",
      " [-1.52111578 -1.43844586  2.95970633]]\n",
      "1626000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10366975918646866\n",
      "[[ 1.04195437  0.81001003 -1.85209405]\n",
      " [ 2.38286137 -0.11675988 -2.26644367]\n",
      " [-3.24727873 -0.19453818  3.44223324]\n",
      " [-1.52140125 -1.43883283  2.96037877]]\n",
      "1627000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10364520778414076\n",
      "[[ 1.042169    0.81010955 -1.8524082 ]\n",
      " [ 2.38329347 -0.1166393  -2.26699635]\n",
      " [-3.24785653 -0.19461077  3.44288363]\n",
      " [-1.52168656 -1.43921961  2.96105086]]\n",
      "1628000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10362068184255759\n",
      "[[ 1.04238352  0.81020897 -1.85272215]\n",
      " [ 2.38372532 -0.11651878 -2.26754873]\n",
      " [-3.248434   -0.19468329  3.44353363]\n",
      " [-1.52197173 -1.4396062   2.96172261]]\n",
      "1629000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10359618131994992\n",
      "[[ 1.04259793  0.8103083  -1.85303588]\n",
      " [ 2.38415693 -0.1163983  -2.26810081]\n",
      " [-3.24901116 -0.19475575  3.44418324]\n",
      " [-1.52225674 -1.43999258  2.96239401]]\n",
      "1630000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10357170617464177\n",
      "[[ 1.04281222  0.81040754 -1.85334941]\n",
      " [ 2.3845883  -0.11627788 -2.2686526 ]\n",
      " [-3.249588   -0.19482814  3.44483247]\n",
      " [-1.5225416  -1.44037878  2.96306506]]\n",
      "1631000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10354725636505\n",
      "[[ 1.04302639  0.81050668 -1.85366273]\n",
      " [ 2.38501942 -0.11615751 -2.26920409]\n",
      " [-3.25016451 -0.19490046  3.44548131]\n",
      " [-1.52282631 -1.44076478  2.96373577]]\n",
      "1632000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10352283184968411\n",
      "[[ 1.04324045  0.81060573 -1.85397583]\n",
      " [ 2.3854503  -0.11603719 -2.26975529]\n",
      " [-3.25074071 -0.19497273  3.44612977]\n",
      " [-1.52311087 -1.44115058  2.96440614]]\n",
      "1633000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10349843258714579\n",
      "[[ 1.0434544   0.81070468 -1.85428873]\n",
      " [ 2.38588094 -0.11591692 -2.2703062 ]\n",
      " [-3.25131658 -0.19504492  3.44677784]\n",
      " [-1.52339528 -1.44153619  2.96507616]]\n",
      "1634000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1034740585361292\n",
      "[[ 1.04366822  0.81080354 -1.85460142]\n",
      " [ 2.38631133 -0.1157967  -2.27085681]\n",
      " [-3.25189214 -0.19511705  3.44742552]\n",
      " [-1.52367954 -1.44192161  2.96574583]]\n",
      "1635000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10344970965541969\n",
      "[[ 1.04388194  0.81090231 -1.8549139 ]\n",
      " [ 2.38674148 -0.11567653 -2.27140713]\n",
      " [-3.25246738 -0.19518911  3.44807283]\n",
      " [-1.52396365 -1.44230683  2.96641516]]\n",
      "1636000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10342538590389463\n",
      "[[ 1.04409554  0.81100098 -1.85522618]\n",
      " [ 2.38717139 -0.11555641 -2.27195716]\n",
      " [-3.2530423  -0.19526111  3.44871975]\n",
      " [-1.52424761 -1.44269186  2.96708415]]\n",
      "1637000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10340108724052274\n",
      "[[ 1.04430902  0.81109956 -1.85553824]\n",
      " [ 2.38760106 -0.11543635 -2.2725069 ]\n",
      " [-3.2536169  -0.19533305  3.44936628]\n",
      " [-1.52453141 -1.4430767   2.9677528 ]]\n",
      "1638000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10337681362436332\n",
      "[[ 1.0445224   0.81119805 -1.8558501 ]\n",
      " [ 2.38803049 -0.11531633 -2.27305634]\n",
      " [-3.25419118 -0.19540492  3.45001244]\n",
      " [-1.52481507 -1.44346134  2.9684211 ]]\n",
      "1639000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10335256501456704\n",
      "[[ 1.04473565  0.81129645 -1.85616175]\n",
      " [ 2.38845968 -0.11519637 -2.27360549]\n",
      " [-3.25476515 -0.19547672  3.45065821]\n",
      " [-1.52509858 -1.44384579  2.96908906]]\n",
      "1640000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10332834137037475\n",
      "[[ 1.0449488   0.81139475 -1.8564732 ]\n",
      " [ 2.38888862 -0.11507645 -2.27415435]\n",
      " [-3.2553388  -0.19554846  3.4513036 ]\n",
      " [-1.52538194 -1.44423005  2.96975668]]\n",
      "1641000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10330414265111777\n",
      "[[ 1.04516182  0.81149296 -1.85678444]\n",
      " [ 2.38931733 -0.11495659 -2.27470292]\n",
      " [-3.25591213 -0.19562014  3.45194861]\n",
      " [-1.52566516 -1.44461411  2.97042395]]\n",
      "1642000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10327996881621722\n",
      "[[ 1.04537474  0.81159107 -1.85709547]\n",
      " [ 2.3897458  -0.11483678 -2.2752512 ]\n",
      " [-3.25648515 -0.19569175  3.45259324]\n",
      " [-1.52594822 -1.44499798  2.97109089]]\n",
      "1643000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10325581982518425\n",
      "[[ 1.04558754  0.8116891  -1.85740629]\n",
      " [ 2.39017402 -0.11471702 -2.27579919]\n",
      " [-3.25705785 -0.1957633   3.45323748]\n",
      " [-1.52623113 -1.44538166  2.97175748]]\n",
      "1644000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10323169563761946\n",
      "[[ 1.04580023  0.81178703 -1.85771691]\n",
      " [ 2.39060201 -0.11459731 -2.27634688]\n",
      " [-3.25763024 -0.19583478  3.45388135]\n",
      " [-1.5265139  -1.44576515  2.97242374]]\n",
      "1645000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1032075962132127\n",
      "[[ 1.0460128   0.81188487 -1.85802733]\n",
      " [ 2.39102975 -0.11447765 -2.27689429]\n",
      " [-3.25820231 -0.1959062   3.45452484]\n",
      " [-1.52679651 -1.44614845  2.97308965]]\n",
      "1646000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10318352151174294\n",
      "[[ 1.04622526  0.81198262 -1.85833754]\n",
      " [ 2.39145726 -0.11435804 -2.2774414 ]\n",
      " [-3.25877407 -0.19597755  3.45516795]\n",
      " [-1.52707898 -1.44653155  2.97375522]]\n",
      "1647000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10315947149307786\n",
      "[[ 1.04643761  0.81208027 -1.85864754]\n",
      " [ 2.39188453 -0.11423848 -2.27798823]\n",
      " [-3.25934551 -0.19604884  3.45581068]\n",
      " [-1.5273613  -1.44691447  2.97442046]]\n",
      "1648000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1031354461171735\n",
      "[[ 1.04664985  0.81217784 -1.85895734]\n",
      " [ 2.39231156 -0.11411897 -2.27853477]\n",
      " [-3.25991663 -0.19612007  3.45645303]\n",
      " [-1.52764348 -1.44729719  2.97508535]]\n",
      "1649000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10311144534407457\n",
      "[[ 1.04686197  0.81227531 -1.85926694]\n",
      " [ 2.39273835 -0.11399951 -2.27908102]\n",
      " [-3.26048745 -0.19619123  3.45709501]\n",
      " [-1.5279255  -1.44767972  2.97574991]]\n",
      "1650000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10308746913391365\n",
      "[[ 1.04707398  0.81237269 -1.85957633]\n",
      " [ 2.3931649  -0.1138801  -2.27962698]\n",
      " [-3.26105795 -0.19626232  3.45773661]\n",
      " [-1.52820738 -1.44806206  2.97641412]]\n",
      "1651000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.103063517446911\n",
      "[[ 1.04728587  0.81246998 -1.85988551]\n",
      " [ 2.39359122 -0.11376075 -2.28017265]\n",
      " [-3.26162813 -0.19633336  3.45837783]\n",
      " [-1.52848911 -1.44844421  2.977078  ]]\n",
      "1652000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10303959024337463\n",
      "[[ 1.04749766  0.81256718 -1.86019449]\n",
      " [ 2.39401729 -0.11364144 -2.28071803]\n",
      " [-3.26219801 -0.19640433  3.45901867]\n",
      " [-1.52877069 -1.44882617  2.97774154]]\n",
      "1653000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10301568748369974\n",
      "[[ 1.04770933  0.81266429 -1.86050327]\n",
      " [ 2.39444314 -0.11352219 -2.28126313]\n",
      " [-3.26276757 -0.19647523  3.45965914]\n",
      " [-1.52905212 -1.44920794  2.97840475]]\n",
      "1654000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10299180912836868\n",
      "[[ 1.04792089  0.81276131 -1.86081185]\n",
      " [ 2.39486874 -0.11340298 -2.28180794]\n",
      " [-3.26333682 -0.19654608  3.46029923]\n",
      " [-1.52933341 -1.44958952  2.97906762]]\n",
      "1655000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1029679551379505\n",
      "[[ 1.04813233  0.81285823 -1.86112022]\n",
      " [ 2.39529411 -0.11328383 -2.28235246]\n",
      " [-3.26390576 -0.19661686  3.46093895]\n",
      " [-1.52961455 -1.44997091  2.97973015]]\n",
      "1656000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10294412547310096\n",
      "[[ 1.04834367  0.81295507 -1.86142839]\n",
      " [ 2.39571924 -0.11316472 -2.28289669]\n",
      " [-3.26447439 -0.19668757  3.46157829]\n",
      " [-1.52989555 -1.45035211  2.98039234]]\n",
      "1657000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10292032009456212\n",
      "[[ 1.04855489  0.81305181 -1.86173636]\n",
      " [ 2.39614413 -0.11304567 -2.28344064]\n",
      " [-3.2650427  -0.19675823  3.46221726]\n",
      " [-1.53017639 -1.45073312  2.9810542 ]]\n",
      "1658000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10289653896316238\n",
      "[[ 1.048766    0.81314846 -1.86204412]\n",
      " [ 2.39656879 -0.11292667 -2.2839843 ]\n",
      " [-3.26561071 -0.19682881  3.46285585]\n",
      " [-1.53045709 -1.45111394  2.98171572]]\n",
      "1659000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10287278203981552\n",
      "[[ 1.048977    0.81324503 -1.86235168]\n",
      " [ 2.39699321 -0.11280772 -2.28452767]\n",
      " [-3.2661784  -0.19689934  3.46349408]\n",
      " [-1.53073765 -1.45149458  2.98237691]]\n",
      "1660000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10284904928552142\n",
      "[[ 1.04918789  0.8133415  -1.86265904]\n",
      " [ 2.3974174  -0.11268881 -2.28507076]\n",
      " [-3.26674579 -0.1969698   3.46413192]\n",
      " [-1.53101806 -1.45187502  2.98303776]]\n",
      "1661000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10282534066136519\n",
      "[[ 1.04939866  0.81343788 -1.8629662 ]\n",
      " [ 2.39784135 -0.11256996 -2.28561357]\n",
      " [-3.26731286 -0.1970402   3.4647694 ]\n",
      " [-1.53129832 -1.45225528  2.98369828]]\n",
      "1662000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10280165612851691\n",
      "[[ 1.04960933  0.81353418 -1.86327316]\n",
      " [ 2.39826506 -0.11245116 -2.28615608]\n",
      " [-3.26787963 -0.19711054  3.4654065 ]\n",
      " [-1.53157844 -1.45263534  2.98435847]]\n",
      "1663000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10277799564823177\n",
      "[[ 1.04981988  0.81363038 -1.86357992]\n",
      " [ 2.39868855 -0.11233241 -2.28669832]\n",
      " [-3.26844608 -0.19718082  3.46604324]\n",
      " [-1.53185841 -1.45301522  2.98501832]]\n",
      "1664000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10275435918184977\n",
      "[[ 1.05003032  0.8137265  -1.86388647]\n",
      " [ 2.39911179 -0.11221371 -2.28724027]\n",
      " [-3.26901223 -0.19725103  3.4666796 ]\n",
      " [-1.53213824 -1.45339491  2.98567784]]\n",
      "1665000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10273074669079503\n",
      "[[ 1.05024065  0.81382252 -1.86419283]\n",
      " [ 2.39953481 -0.11209506 -2.28778193]\n",
      " [-3.26957807 -0.19732118  3.46731559]\n",
      " [-1.53241792 -1.45377442  2.98633702]]\n",
      "1666000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10270715813657647\n",
      "[[ 1.05045087  0.81391846 -1.86449898]\n",
      " [ 2.39995759 -0.11197646 -2.28832331]\n",
      " [-3.27014361 -0.19739127  3.46795121]\n",
      " [-1.53269745 -1.45415373  2.98699587]]\n",
      "1667000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10268359348078619\n",
      "[[ 1.05066098  0.8140143  -1.86480494]\n",
      " [ 2.40038013 -0.11185791 -2.2888644 ]\n",
      " [-3.27070883 -0.19746129  3.46858646]\n",
      " [-1.53297684 -1.45453286  2.98765439]]\n",
      "1668000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10266005268510076\n",
      "[[ 1.05087098  0.81411006 -1.86511069]\n",
      " [ 2.40080245 -0.11173941 -2.28940522]\n",
      " [-3.27127375 -0.19753125  3.46922133]\n",
      " [-1.53325609 -1.4549118   2.98831258]]\n",
      "1669000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10263653571127998\n",
      "[[ 1.05108087  0.81420573 -1.86541625]\n",
      " [ 2.40122453 -0.11162096 -2.28994575]\n",
      " [-3.27183836 -0.19760115  3.46985585]\n",
      " [-1.53353519 -1.45529056  2.98897044]]\n",
      "1670000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10261304252116682\n",
      "[[ 1.05129065  0.8143013  -1.86572161]\n",
      " [ 2.40164637 -0.11150256 -2.29048599]\n",
      " [-3.27240266 -0.19767099  3.47048999]\n",
      " [-1.53381415 -1.45566913  2.98962796]]\n",
      "1671000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10258957307668773\n",
      "[[ 1.05150031  0.81439679 -1.86602676]\n",
      " [ 2.40206799 -0.11138421 -2.29102595]\n",
      " [-3.27296666 -0.19774077  3.47112376]\n",
      " [-1.53409296 -1.45604751  2.99028515]]\n",
      "1672000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10256612733985153\n",
      "[[ 1.05170987  0.8144922  -1.86633172]\n",
      " [ 2.40248937 -0.11126591 -2.29156564]\n",
      " [-3.27353035 -0.19781048  3.47175717]\n",
      " [-1.53437163 -1.4564257   2.99094202]]\n",
      "1673000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10254270527275007\n",
      "[[ 1.05191932  0.81458751 -1.86663648]\n",
      " [ 2.40291052 -0.11114767 -2.29210503]\n",
      " [-3.27409374 -0.19788013  3.4723902 ]\n",
      " [-1.53465015 -1.45680371  2.99159855]]\n",
      "1674000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1025193068375572\n",
      "[[ 1.05212866  0.81468273 -1.86694104]\n",
      " [ 2.40333144 -0.11102947 -2.29264415]\n",
      " [-3.27465682 -0.19794972  3.47302288]\n",
      " [-1.53492853 -1.45718153  2.99225475]]\n",
      "1675000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10249593199652927\n",
      "[[ 1.05233788  0.81477787 -1.8672454 ]\n",
      " [ 2.40375212 -0.11091132 -2.29318299]\n",
      " [-3.2752196  -0.19801925  3.47365518]\n",
      " [-1.53520677 -1.45755917  2.99291063]]\n",
      "1676000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10247258071200449\n",
      "[[ 1.052547    0.81487292 -1.86754957]\n",
      " [ 2.40417258 -0.11079322 -2.29372154]\n",
      " [-3.27578207 -0.19808871  3.47428712]\n",
      " [-1.53548486 -1.45793662  2.99356617]]\n",
      "1677000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10244925294640267\n",
      "[[ 1.05275601  0.81496788 -1.86785354]\n",
      " [ 2.4045928  -0.11067517 -2.29425981]\n",
      " [-3.27634424 -0.19815812  3.47491869]\n",
      " [-1.53576281 -1.45831389  2.99422139]]\n",
      "1678000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10242594866222501\n",
      "[[ 1.05296491  0.81506275 -1.86815731]\n",
      " [ 2.4050128  -0.11055717 -2.2947978 ]\n",
      " [-3.2769061  -0.19822746  3.4755499 ]\n",
      " [-1.53604062 -1.45869097  2.99487627]]\n",
      "1679000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10240266782205433\n",
      "[[ 1.05317369  0.81515753 -1.86846088]\n",
      " [ 2.40543256 -0.11043923 -2.29533551]\n",
      " [-3.27746766 -0.19829674  3.47618074]\n",
      " [-1.53631828 -1.45906786  2.99553083]]\n",
      "1680000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10237941038855422\n",
      "[[ 1.05338237  0.81525223 -1.86876426]\n",
      " [ 2.40585209 -0.11032133 -2.29587295]\n",
      " [-3.27802892 -0.19836596  3.47681122]\n",
      " [-1.53659581 -1.45944457  2.99618507]]\n",
      "1681000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10235617632446903\n",
      "[[ 1.05359094  0.81534684 -1.86906744]\n",
      " [ 2.4062714  -0.11020348 -2.2964101 ]\n",
      " [-3.27858987 -0.19843512  3.47744133]\n",
      " [-1.53687318 -1.4598211   2.99683897]]\n",
      "1682000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10233296559262385\n",
      "[[ 1.05379941  0.81544136 -1.86937042]\n",
      " [ 2.40669047 -0.11008568 -2.29694697]\n",
      " [-3.27915053 -0.19850422  3.47807108]\n",
      " [-1.53715042 -1.46019744  2.99749255]]\n",
      "1683000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10230977815592425\n",
      "[[ 1.05400776  0.81553579 -1.86967321]\n",
      " [ 2.40710931 -0.10996793 -2.29748356]\n",
      " [-3.27971088 -0.19857326  3.47870046]\n",
      " [-1.53742751 -1.4605736   2.9981458 ]]\n",
      "1684000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10228661397735588\n",
      "[[ 1.054216    0.81563014 -1.8699758 ]\n",
      " [ 2.40752793 -0.10985023 -2.29801987]\n",
      " [-3.28027092 -0.19864223  3.47932949]\n",
      " [-1.53770446 -1.46094957  2.99879872]]\n",
      "1685000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1022634730199842\n",
      "[[ 1.05442414  0.8157244  -1.87027819]\n",
      " [ 2.40794631 -0.10973259 -2.2985559 ]\n",
      " [-3.28083067 -0.19871115  3.47995815]\n",
      " [-1.53798127 -1.46132536  2.99945132]]\n",
      "1686000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10224035524695467\n",
      "[[ 1.05463216  0.81581857 -1.87058039]\n",
      " [ 2.40836447 -0.10961499 -2.29909166]\n",
      " [-3.28139011 -0.19878     3.48058645]\n",
      " [-1.53825794 -1.46170097  3.00010359]]\n",
      "1687000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10221726062149174\n",
      "[[ 1.05484008  0.81591266 -1.8708824 ]\n",
      " [ 2.40878239 -0.10949744 -2.29962714]\n",
      " [-3.28194926 -0.19884879  3.48121438]\n",
      " [-1.53853446 -1.46207639  3.00075554]]\n",
      "1688000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10219418910689984\n",
      "[[ 1.05504789  0.81600666 -1.8711842 ]\n",
      " [ 2.40920009 -0.10937994 -2.30016233]\n",
      " [-3.2825081  -0.19891752  3.48184196]\n",
      " [-1.53881084 -1.46245163  3.00140716]]\n",
      "1689000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10217114066656205\n",
      "[[ 1.05525559  0.81610057 -1.87148582]\n",
      " [ 2.40961757 -0.10926249 -2.30069726]\n",
      " [-3.28306665 -0.19898619  3.48246917]\n",
      " [-1.53908708 -1.46282669  3.00205846]]\n",
      "1690000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10214811526394027\n",
      "[[ 1.05546319  0.8161944  -1.87178724]\n",
      " [ 2.41003481 -0.10914509 -2.3012319 ]\n",
      " [-3.28362489 -0.19905481  3.48309603]\n",
      " [-1.53936318 -1.46320156  3.00270943]]\n",
      "1691000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10212511286257518\n",
      "[[ 1.05567067  0.81628814 -1.87208847]\n",
      " [ 2.41045183 -0.10902774 -2.30176626]\n",
      " [-3.28418283 -0.19912336  3.48372252]\n",
      " [-1.53963914 -1.46357625  3.00336008]]\n",
      "1692000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10210213342608597\n",
      "[[ 1.05587805  0.81638179 -1.8723895 ]\n",
      " [ 2.41086862 -0.10891044 -2.30230035]\n",
      " [-3.28474048 -0.19919185  3.48434866]\n",
      " [-1.53991496 -1.46395076  3.0040104 ]]\n",
      "1693000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10207917691816985\n",
      "[[ 1.05608532  0.81647536 -1.87269033]\n",
      " [ 2.41128518 -0.10879319 -2.30283417]\n",
      " [-3.28529782 -0.19926027  3.48497443]\n",
      " [-1.54019063 -1.46432508  3.00466041]]\n",
      "1694000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10205624330260225\n",
      "[[ 1.05629248  0.81656884 -1.87299098]\n",
      " [ 2.41170151 -0.10867599 -2.3033677 ]\n",
      " [-3.28585487 -0.19932864  3.48559985]\n",
      " [-1.54046617 -1.46469923  3.00531008]]\n",
      "1695000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.1020333325432363\n",
      "[[ 1.05649954  0.81666224 -1.87329143]\n",
      " [ 2.41211762 -0.10855884 -2.30390096]\n",
      " [-3.28641162 -0.19939695  3.48622491]\n",
      " [-1.54074157 -1.46507319  3.00595944]]\n",
      "1696000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10201044460400266\n",
      "[[ 1.05670649  0.81675555 -1.87359169]\n",
      " [ 2.4125335  -0.10844174 -2.30443394]\n",
      " [-3.28696807 -0.1994652   3.4868496 ]\n",
      " [-1.54101682 -1.46544697  3.00660847]]\n",
      "1697000 번째 학습중입니다.\n",
      "Accuracy :  0.9866666666666667\n",
      "Loss :      0.10198757944890943\n",
      "[[ 1.05691333  0.81684877 -1.87389175]\n",
      " [ 2.41294916 -0.10832469 -2.30496665]\n",
      " [-3.28752422 -0.19953339  3.48747395]\n",
      " [-1.54129193 -1.46582057  3.00725719]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-2ccf040b9c30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000000000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0msoftmax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"번째 학습중입니다.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-f878b3e6956e>\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, X, T, learning_rate)\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;31m#     col : Softmax-loss node input 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m         \u001b[1;31m# {partial L} over {partial b} = 1 * [{partial L} over {partial H} = dp]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;31m# grads[\"b\"] : (1, 3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1000000000):\n",
    "    softmax.gradient(x, y)\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print(i, \"번째 학습중입니다.\")\n",
    "        print(\"Accuracy : \", softmax.accuracy(x, y))\n",
    "        print(\"Loss :     \", softmax.loss(x, y))\n",
    "        print(softmax.params['W'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
