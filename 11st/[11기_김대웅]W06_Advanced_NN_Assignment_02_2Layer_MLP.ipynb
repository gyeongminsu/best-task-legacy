{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToBig's_11th_W06_Advaced_NN\n",
    "## Assignment_02 : 2Layer MLP with MNIST data\n",
    "### 11기 김대웅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. epoch 수정, batch_size수정, Adam 적용, dropout 적용, batchnormalization을 적용해보고 성능이 어떻게 변하는지 확인해보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_bGXuIj21ELO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2lPN4eMk2vXz"
   },
   "source": [
    "# Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bpXuB7If2K7s"
   },
   "outputs": [],
   "source": [
    "# 불러온 이미지 선처리 하기 위한 단계 (ToTensor : 이미지를 텐서 형태로)\n",
    "# Tensor의 range는 0에서 1로 \n",
    "\n",
    "# 이미지 처리를 위한 transforms.Compose\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data',train=True, download=True,\n",
    "                                           transform=transforms.Compose([\n",
    "                                               transforms.ToTensor(), \n",
    "                                               transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                           ]))\n",
    "                                                                \n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data',train=False, download = True,\n",
    "                                           transform=transforms.Compose([\n",
    "                                               transforms.ToTensor(), \n",
    "                                               transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                           ]))\n",
    "                                                  \n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=128, shuffle=True) # 지정한 batch-size로 묶음\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,  batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O-KsCNVGtidd"
   },
   "source": [
    "#### 데이터 형태 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "EitGQUUstQWq",
    "outputId": "6b436133-9a53-4182-f164-126c38fd10d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Split: train\n",
       "    Root Location: ./data\n",
       "    Transforms (if any): Compose(\n",
       "                             ToTensor()\n",
       "                             Normalize(mean=(0.1307,), std=(0.3081,))\n",
       "                         )\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 444,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "AwxfaatMtbQy",
    "outputId": "f45c27b9-e414-4901-fc8f-f6f545d09276"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Split: test\n",
       "    Root Location: ./data\n",
       "    Transforms (if any): Compose(\n",
       "                             ToTensor()\n",
       "                             Normalize(mean=(0.1307,), std=(0.3081,))\n",
       "                         )\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 445,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_tbqduqtrUG"
   },
   "outputs": [],
   "source": [
    "examples = iter(train_loader)\n",
    "example_data, example_targets = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3J2jbWMH3Uwc",
    "outputId": "bbd568a9-8082-4fd5-87af-caebbcb5bdbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 28, 28])"
      ]
     },
     "execution_count": 447,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "colab_type": "code",
    "id": "iguYPGlp4xvk",
    "outputId": "dad006d3-8943-4738-a43e-ce094f346167"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.figure>"
      ]
     },
     "execution_count": 448,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAFvCAYAAABguDDMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUAAAgDr/Bzie0FY4ZtiYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x396 with 6 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap=\"gray\", interpolation=\"none\")\n",
    "    plt.title(\"Ground Truth : {}\".format(example_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8rLBxadWJ-vt"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qTWSN-dR7LWl"
   },
   "outputs": [],
   "source": [
    "# config\n",
    "src = {'input_size':1*28*28, \n",
    "       'hidden_size1':5, \n",
    "       'hidden_size2':5,\n",
    "       'output_size':10,\n",
    "       'init_weight_range':0.5,\n",
    "       'num_epochs':5,\n",
    "       'batch_size':128,\n",
    "       'learning_rate':1e-3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bszGgtFo6kL7"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, src):\n",
    "        super(Net, self).__init__()\n",
    "        # .Linear Layer\n",
    "        self.fc1 = nn.Linear(src['input_size'], src['hidden_size1'])\n",
    "        self.fc2 = nn.Linear(src['hidden_size1'], src['hidden_size2'])\n",
    "        self.fc3 = nn.Linear(src['hidden_size2'], src['output_size'])\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.init_range = src['init_weight_range']\n",
    "\n",
    "        \n",
    "    # 가중치 초기화  (생략가능)\n",
    "    def init_weight(self):\n",
    "        self.fc1.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "        self.fc2.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "        self.fc3.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "\n",
    "        '''       \n",
    "        for fc in self.seq_fc:\n",
    "            fc.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "        '''\n",
    "    # 위에서는 layer 선언만 한 것이지 구체적 적용방법을 설정하지 않음\n",
    "    # 여기선 구체적인 사용 방법을 설정\n",
    "    # input data를 선언 (여기선 img)\n",
    "    def forward(self, img):\n",
    "        x = img.view(img.shape[0], -1) # image (1 X 3 X 32 X 32)에서 첫 차원은 그대로 두고 뒤 차원들을 다 faltten해 2차원으로 \n",
    "        # 아래의 과정을 거치겠다.\n",
    "        #--------------------\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        y = self.fc3(x)\n",
    "        #--------------------\n",
    "        \n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JU6SiHMl_9wE"
   },
   "outputs": [],
   "source": [
    "model = Net(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EOc-D6P2ACLx"
   },
   "outputs": [],
   "source": [
    "y = model(example_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "dingZcZyAgN5",
    "outputId": "deaea2f6-d710-4ddb-cf28-fa72044b9b92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10])\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UkWdGLOVI_Rm"
   },
   "source": [
    "## Train / Eval\n",
    "### 손실함수 및 optimizer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vsFUGkLCA6jc"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),\n",
    "                     src[\"learning_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wHF9Be6gJBr4"
   },
   "source": [
    "### 1. 기본 모델\n",
    "- 아무것도 적용하지 않은 기준 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6vdrS2xfBL9z"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ueeu7IgtPP5l"
   },
   "outputs": [],
   "source": [
    "model = Net(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4409
    },
    "colab_type": "code",
    "id": "bD8Z8dRyBPxQ",
    "outputId": "91149318-6207-438e-f434-59086e206d98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/400], Loss: 3.1128\n",
      "Epoch [1/5], Step [200/400], Loss: 3.1089\n",
      "Epoch [1/5], Step [300/400], Loss: 3.0893\n",
      "Epoch [1/5], Step [400/400], Loss: 3.0867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:08<00:34,  8.73s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Step [100/400], Loss: 3.0983\n",
      "Epoch [2/5], Step [200/400], Loss: 3.0918\n",
      "Epoch [2/5], Step [300/400], Loss: 3.0696\n",
      "Epoch [2/5], Step [400/400], Loss: 3.1195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:17<00:26,  8.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Step [100/400], Loss: 3.0869\n",
      "Epoch [3/5], Step [200/400], Loss: 3.0971\n",
      "Epoch [3/5], Step [300/400], Loss: 3.0823\n",
      "Epoch [3/5], Step [400/400], Loss: 3.0935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:26<00:17,  8.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Step [100/400], Loss: 3.0931\n",
      "Epoch [4/5], Step [200/400], Loss: 3.0980\n",
      "Epoch [4/5], Step [300/400], Loss: 3.0977\n",
      "Epoch [4/5], Step [400/400], Loss: 3.1007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:35<00:08,  8.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Step [100/400], Loss: 3.0939\n",
      "Epoch [5/5], Step [200/400], Loss: 3.0798\n",
      "Epoch [5/5], Step [300/400], Loss: 3.1053\n",
      "Epoch [5/5], Step [400/400], Loss: 3.1074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:43<00:00,  8.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "model.init_weight()\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(src[\"num_epochs\"])):\n",
    "    current_loss = 0.0  # loss 초기화.\n",
    "    \n",
    "    for i, data in enumerate(train_loader): # 한 번 루프 돌 때마다 Batch-size만큼 처리하도록 trainloader에서 정의함\n",
    "        # get the inputs\n",
    "        inputs, labels = data # 사진과 클래스가 묶여 들어가 있으므로\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad() # gradient를 iter 돌기 전 초기화 시켜줌\n",
    "        \n",
    "        # forward + backward + optimization\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels) # outpuut과 label의 차이를 cross entropy loss로 계산\n",
    "        loss.backward()\n",
    "        optimizer.step() # 이를 optim.SGD로 처리후 W를 update\n",
    "        \n",
    "        # print statistics\n",
    "        # 100 step 마다 확인 100step의 평균값(1step은 batch-size만큼의 Loss를 계산함.)\n",
    "        step = i + 1\n",
    "        current_loss += loss.item()\n",
    "        \n",
    "        if step % 100 == 0 and step !=0:\n",
    "            print(\"Epoch [%d/%d], Step [%d/%d], Loss: %.4f\" %\n",
    "                 (epoch + 1, src[\"num_epochs\"], step, len(train_loader)//100*100, current_loss / 100))\n",
    "            current_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2IqLRD26KIdV"
   },
   "source": [
    "### 평가 데이터를 이용한 네트워크 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "nTE7RrysG45Q",
    "outputId": "2afdc106-7452-4c18-db91-692f50142018"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 10 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "# Test set으로 성능 평가.\n",
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "for i, data in enumerate(test_loader):\n",
    "    inputs, labels = data\n",
    "#     images = images.view(-1, 28*28)\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.shape[0]\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bU72iNWDKKT2"
   },
   "source": [
    "10%의 정확도가 나온다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dHzRtpmLI0gP"
   },
   "source": [
    "### 2. batch size 수정 모델\n",
    "- batch size를 128에서 256로 늘려보았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "suZYUfSTMlmG"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=256, shuffle=True) # 지정한 batch-size로 묶음\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,  batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RId3PeDwqmwy"
   },
   "outputs": [],
   "source": [
    "model = Net(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4229
    },
    "colab_type": "code",
    "id": "6S0KsihjMp0u",
    "outputId": "ee0d9a60-88aa-4e82-97bf-6f3a8393d5d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/200], Loss: 2.6482\n",
      "Epoch [1/5], Step [200/200], Loss: 2.6515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:08<00:33,  8.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Step [100/200], Loss: 2.6553\n",
      "Epoch [2/5], Step [200/200], Loss: 2.6465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:16<00:25,  8.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Step [100/200], Loss: 2.6472\n",
      "Epoch [3/5], Step [200/200], Loss: 2.6626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:24<00:16,  8.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Step [100/200], Loss: 2.6540\n",
      "Epoch [4/5], Step [200/200], Loss: 2.6506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:33<00:08,  8.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Step [100/200], Loss: 2.6543\n",
      "Epoch [5/5], Step [200/200], Loss: 2.6515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:41<00:00,  8.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "model.init_weight()\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(src[\"num_epochs\"])):\n",
    "    current_loss = 0.0  # loss 초기화.\n",
    "    \n",
    "    for i, data in enumerate(train_loader): # 한 번 루프 돌 때마다 Batch-size만큼 처리하도록 trainloader에서 정의함\n",
    "        # get the inputs\n",
    "        inputs, labels = data # 사진과 클래스가 묶여 들어가 있으므로\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad() # gradient를 iter 돌기 전 초기화 시켜줌\n",
    "        \n",
    "        # forward + backward + optimization\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels) # outpuut과 label의 차이를 cross entropy loss로 계산\n",
    "        loss.backward()\n",
    "        optimizer.step() # 이를 optim.SGD로 처리후 W를 update\n",
    "        \n",
    "        # print statistics\n",
    "        # 100 step 마다 확인 100step의 평균값(1step은 batch-size만큼의 Loss를 계산함.)\n",
    "        step = i + 1\n",
    "        current_loss += loss.item()\n",
    "        \n",
    "        if step % 100 == 0 and step !=0:\n",
    "            print(\"Epoch [%d/%d], Step [%d/%d], Loss: %.4f\" %\n",
    "                 (epoch + 1, src[\"num_epochs\"], step, len(train_loader)//100*100, current_loss / 100))\n",
    "            current_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l-qff0uwM64u"
   },
   "source": [
    "### 평가 데이터를 이용한 네트워크 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "0RtLiCbJM64v",
    "outputId": "b6bdd57f-7d69-402b-fc92-f35655b2a39c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 7 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "# Test set으로 성능 평가.\n",
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "for i, data in enumerate(test_loader):\n",
    "    inputs, labels = data\n",
    "#     images = images.view(-1, 28*28)\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.shape[0]\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lGenPNNWNB2d"
   },
   "source": [
    "### 3. epoch 수정 모델\n",
    "- epoch를 5회에서 10회로 늘려보았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AFccs0y6NLNo"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=128, shuffle=True) # 지정한 batch-size로 묶음\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,  batch_size=128, shuffle=False)\n",
    "\n",
    "# config\n",
    "src = {'input_size':1*28*28, \n",
    "       'hidden_size1':5, \n",
    "       'hidden_size2':5,\n",
    "       'output_size':10,\n",
    "       'init_weight_range':0.5,\n",
    "       'num_epochs':10,\n",
    "       'batch_size':128,\n",
    "       'learning_rate':1e-3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EbAI_MpqPY6N"
   },
   "outputs": [],
   "source": [
    "model = Net(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7649
    },
    "colab_type": "code",
    "id": "XGfyjChzNY-d",
    "outputId": "a8609c63-9b91-4f2f-a5ab-50acacf6ccae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/400], Loss: 2.8545\n",
      "Epoch [1/10], Step [200/400], Loss: 2.8513\n",
      "Epoch [1/10], Step [300/400], Loss: 2.8409\n",
      "Epoch [1/10], Step [400/400], Loss: 2.8460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|█         | 1/10 [00:08<01:16,  8.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [100/400], Loss: 2.8516\n",
      "Epoch [2/10], Step [200/400], Loss: 2.8475\n",
      "Epoch [2/10], Step [300/400], Loss: 2.8507\n",
      "Epoch [2/10], Step [400/400], Loss: 2.8328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 2/10 [00:16<01:08,  8.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step [100/400], Loss: 2.8434\n",
      "Epoch [3/10], Step [200/400], Loss: 2.8445\n",
      "Epoch [3/10], Step [300/400], Loss: 2.8504\n",
      "Epoch [3/10], Step [400/400], Loss: 2.8449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███       | 3/10 [00:25<00:59,  8.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [100/400], Loss: 2.8537\n",
      "Epoch [4/10], Step [200/400], Loss: 2.8548\n",
      "Epoch [4/10], Step [300/400], Loss: 2.8290\n",
      "Epoch [4/10], Step [400/400], Loss: 2.8581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:33<00:50,  8.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step [100/400], Loss: 2.8507\n",
      "Epoch [5/10], Step [200/400], Loss: 2.8343\n",
      "Epoch [5/10], Step [300/400], Loss: 2.8346\n",
      "Epoch [5/10], Step [400/400], Loss: 2.8649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 5/10 [00:42<00:42,  8.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Step [100/400], Loss: 2.8388\n",
      "Epoch [6/10], Step [200/400], Loss: 2.8433\n",
      "Epoch [6/10], Step [300/400], Loss: 2.8271\n",
      "Epoch [6/10], Step [400/400], Loss: 2.8805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 6/10 [00:50<00:33,  8.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Step [100/400], Loss: 2.8413\n",
      "Epoch [7/10], Step [200/400], Loss: 2.8363\n",
      "Epoch [7/10], Step [300/400], Loss: 2.8480\n",
      "Epoch [7/10], Step [400/400], Loss: 2.8626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████   | 7/10 [00:58<00:25,  8.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Step [100/400], Loss: 2.8395\n",
      "Epoch [8/10], Step [200/400], Loss: 2.8522\n",
      "Epoch [8/10], Step [300/400], Loss: 2.8504\n",
      "Epoch [8/10], Step [400/400], Loss: 2.8286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 8/10 [01:07<00:16,  8.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Step [100/400], Loss: 2.8526\n",
      "Epoch [9/10], Step [200/400], Loss: 2.8626\n",
      "Epoch [9/10], Step [300/400], Loss: 2.8289\n",
      "Epoch [9/10], Step [400/400], Loss: 2.8386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|█████████ | 9/10 [01:15<00:08,  8.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Step [100/400], Loss: 2.8343\n",
      "Epoch [10/10], Step [200/400], Loss: 2.8537\n",
      "Epoch [10/10], Step [300/400], Loss: 2.8454\n",
      "Epoch [10/10], Step [400/400], Loss: 2.8719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 10/10 [01:24<00:00,  8.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "model.init_weight()\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(src[\"num_epochs\"])):\n",
    "    current_loss = 0.0  # loss 초기화.\n",
    "    \n",
    "    for i, data in enumerate(train_loader): # 한 번 루프 돌 때마다 Batch-size만큼 처리하도록 trainloader에서 정의함\n",
    "        # get the inputs\n",
    "        inputs, labels = data # 사진과 클래스가 묶여 들어가 있으므로\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad() # gradient를 iter 돌기 전 초기화 시켜줌\n",
    "        \n",
    "        # forward + backward + optimization\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels) # outpuut과 label의 차이를 cross entropy loss로 계산\n",
    "        loss.backward()\n",
    "        optimizer.step() # 이를 optim.SGD로 처리후 W를 update\n",
    "        \n",
    "        # print statistics\n",
    "        # 100 step 마다 확인 100step의 평균값(1step은 batch-size만큼의 Loss를 계산함.)\n",
    "        step = i + 1\n",
    "        current_loss += loss.item()\n",
    "        \n",
    "        if step % 100 == 0 and step !=0:\n",
    "            print(\"Epoch [%d/%d], Step [%d/%d], Loss: %.4f\" %\n",
    "                 (epoch + 1, src[\"num_epochs\"], step, len(train_loader)//100*100, current_loss / 100))\n",
    "            current_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yJVuj9wsNrrO"
   },
   "source": [
    "### 평가 데이터를 이용한 네트워크 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Icg_XbOLNrrP",
    "outputId": "2d1b3c06-07b2-4b95-8864-27f2bbeb3415"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 9 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "# Test set으로 성능 평가.\n",
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "for i, data in enumerate(test_loader):\n",
    "    inputs, labels = data\n",
    "#     images = images.view(-1, 28*28)\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.shape[0]\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jygekidlNcju"
   },
   "source": [
    "### 4. adam 적용 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ixC84Ug4NyVV"
   },
   "outputs": [],
   "source": [
    "# config\n",
    "src = {'input_size':1*28*28, \n",
    "       'hidden_size1':5, \n",
    "       'hidden_size2':5,\n",
    "       'output_size':10,\n",
    "       'init_weight_range':0.5,\n",
    "       'num_epochs':5,\n",
    "       'batch_size':128,\n",
    "       'learning_rate':1e-3}\n",
    "\n",
    "model = Net(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GbdFB3TONz2W"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),\n",
    "                     src[\"learning_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4787
    },
    "colab_type": "code",
    "id": "zj9VLMzJORv1",
    "outputId": "34ca40a8-c193-48cb-f4d6-6a43bc3305c1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/400], Loss: 2.2622\n",
      "Epoch [1/5], Step [200/400], Loss: 2.2041\n",
      "Epoch [1/5], Step [300/400], Loss: 2.1622\n",
      "Epoch [1/5], Step [400/400], Loss: 2.1277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:09<00:36,  9.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Step [100/400], Loss: 2.0924\n",
      "Epoch [2/5], Step [200/400], Loss: 2.0757\n",
      "Epoch [2/5], Step [300/400], Loss: 2.0506\n",
      "Epoch [2/5], Step [400/400], Loss: 2.0461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:17<00:27,  9.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Step [100/400], Loss: 2.0345\n",
      "Epoch [3/5], Step [200/400], Loss: 2.0151\n",
      "Epoch [3/5], Step [300/400], Loss: 2.0099\n",
      "Epoch [3/5], Step [400/400], Loss: 2.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:26<00:17,  8.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Step [100/400], Loss: 1.9964\n",
      "Epoch [4/5], Step [200/400], Loss: 1.9938\n",
      "Epoch [4/5], Step [300/400], Loss: 1.9776\n",
      "Epoch [4/5], Step [400/400], Loss: 1.9807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:35<00:08,  8.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Step [100/400], Loss: 1.9650\n",
      "Epoch [5/5], Step [200/400], Loss: 1.9586\n",
      "Epoch [5/5], Step [300/400], Loss: 1.9653\n",
      "Epoch [5/5], Step [400/400], Loss: 1.9581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:44<00:00,  9.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "model.init_weight()\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(src[\"num_epochs\"])):\n",
    "    current_loss = 0.0  # loss 초기화.\n",
    "    \n",
    "    for i, data in enumerate(train_loader): # 한 번 루프 돌 때마다 Batch-size만큼 처리하도록 trainloader에서 정의함\n",
    "        # get the inputs\n",
    "        inputs, labels = data # 사진과 클래스가 묶여 들어가 있으므로\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad() # gradient를 iter 돌기 전 초기화 시켜줌\n",
    "        \n",
    "        # forward + backward + optimization\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels) # outpuut과 label의 차이를 cross entropy loss로 계산\n",
    "        loss.backward()\n",
    "        optimizer.step() # 이를 optim.SGD로 처리후 W를 update\n",
    "        \n",
    "        # print statistics\n",
    "        # 100 step 마다 확인 100step의 평균값(1step은 batch-size만큼의 Loss를 계산함.)\n",
    "        step = i + 1\n",
    "        current_loss += loss.item()\n",
    "        \n",
    "        if step % 100 == 0 and step !=0:\n",
    "            print(\"Epoch [%d/%d], Step [%d/%d], Loss: %.4f\" %\n",
    "                 (epoch + 1, src[\"num_epochs\"], step, len(train_loader)//100*100, current_loss / 100))\n",
    "            current_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x8RFENIbOcP-"
   },
   "source": [
    "### 평가 데이터를 이용한 네트워크 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "T1h93cHoOcP_",
    "outputId": "4d464589-4a4f-4eb3-ce06-0e9820a41c0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 2500 test images: 51 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "# Test set으로 성능 평가.\n",
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "\n",
    "for i, data in enumerate(test_loader):\n",
    "    inputs, labels = data\n",
    "#     images = images.view(-1, 28*28)\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.shape[0]\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 2500 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6FSwJpYnOcQB"
   },
   "source": [
    "51%로 대폭 증가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9H9zNGx7OSFt"
   },
   "source": [
    "### 5. Dropout 적용 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MLQByggxOZ1G"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, src):\n",
    "        super(Net, self).__init__()\n",
    "        # .Linear Layer\n",
    "        self.fc1 = nn.Linear(src['input_size'], src['hidden_size1'])\n",
    "        self.fc2 = nn.Linear(src['hidden_size1'], src['hidden_size2'])\n",
    "        self.fc3 = nn.Linear(src['hidden_size2'], src['output_size'])\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.init_range = src['init_weight_range']\n",
    "\n",
    "        \n",
    "    # 가중치 초기화  (생략가능)\n",
    "    def init_weight(self):\n",
    "        self.fc1.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "        self.fc2.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "        self.fc3.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "\n",
    "        '''       \n",
    "        for fc in self.seq_fc:\n",
    "            fc.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "        '''\n",
    "    # 위에서는 layer 선언만 한 것이지 구체적 적용방법을 설정하지 않음\n",
    "    # 여기선 구체적인 사용 방법을 설정\n",
    "    # input data를 선언 (여기선 img)\n",
    "    def forward(self, img):\n",
    "        x = img.view(img.shape[0], -1) # image (1 X 3 X 32 X 32)에서 첫 차원은 그대로 두고 뒤 차원들을 다 faltten해 2차원으로 \n",
    "        # 아래의 과정을 거치겠다.\n",
    "        #--------------------\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        y = self.fc3(x)\n",
    "        #--------------------\n",
    "        \n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m9KEFJLuQb74"
   },
   "outputs": [],
   "source": [
    "model = Net(src)\n",
    "optimizer = optim.SGD(model.parameters(),\n",
    "                     src[\"learning_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4409
    },
    "colab_type": "code",
    "id": "LcRsBQqcP6qe",
    "outputId": "66fb8c75-ce0f-4ed5-c7e0-5bb11c5332cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/400], Loss: 4.0545\n",
      "Epoch [1/5], Step [200/400], Loss: 2.8762\n",
      "Epoch [1/5], Step [300/400], Loss: 2.6074\n",
      "Epoch [1/5], Step [400/400], Loss: 2.5004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:08<00:34,  8.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Step [100/400], Loss: 2.4177\n",
      "Epoch [2/5], Step [200/400], Loss: 2.4014\n",
      "Epoch [2/5], Step [300/400], Loss: 2.3943\n",
      "Epoch [2/5], Step [400/400], Loss: 2.3755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:17<00:25,  8.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Step [100/400], Loss: 2.3570\n",
      "Epoch [3/5], Step [200/400], Loss: 2.3566\n",
      "Epoch [3/5], Step [300/400], Loss: 2.3535\n",
      "Epoch [3/5], Step [400/400], Loss: 2.3463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:25<00:17,  8.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Step [100/400], Loss: 2.3370\n",
      "Epoch [4/5], Step [200/400], Loss: 2.3353\n",
      "Epoch [4/5], Step [300/400], Loss: 2.3359\n",
      "Epoch [4/5], Step [400/400], Loss: 2.3326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:34<00:08,  8.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Step [100/400], Loss: 2.3334\n",
      "Epoch [5/5], Step [200/400], Loss: 2.3284\n",
      "Epoch [5/5], Step [300/400], Loss: 2.3239\n",
      "Epoch [5/5], Step [400/400], Loss: 2.3188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:42<00:00,  8.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "model.init_weight()\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(src[\"num_epochs\"])):\n",
    "    current_loss = 0.0  # loss 초기화.\n",
    "    \n",
    "    for i, data in enumerate(train_loader): # 한 번 루프 돌 때마다 Batch-size만큼 처리하도록 trainloader에서 정의함\n",
    "        # get the inputs\n",
    "        inputs, labels = data # 사진과 클래스가 묶여 들어가 있으므로\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad() # gradient를 iter 돌기 전 초기화 시켜줌\n",
    "        \n",
    "        # forward + backward + optimization\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels) # outpuut과 label의 차이를 cross entropy loss로 계산\n",
    "        loss.backward()\n",
    "        optimizer.step() # 이를 optim.SGD로 처리후 W를 update\n",
    "        \n",
    "        # print statistics\n",
    "        # 100 step 마다 확인 100step의 평균값(1step은 batch-size만큼의 Loss를 계산함.)\n",
    "        step = i + 1\n",
    "        current_loss += loss.item()\n",
    "        \n",
    "        if step % 100 == 0 and step !=0:\n",
    "            print(\"Epoch [%d/%d], Step [%d/%d], Loss: %.4f\" %\n",
    "                 (epoch + 1, src[\"num_epochs\"], step, len(train_loader)//100*100, current_loss / 100))\n",
    "            current_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "45J6xvFaP6qh"
   },
   "source": [
    "### 평가 데이터를 이용한 네트워크 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "UJtGL-oEP6qi",
    "outputId": "94c1755c-74e8-4888-8e3d-61e55db7158f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 2500 test images: 12 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "# Test set으로 성능 평가.\n",
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "\n",
    "for i, data in enumerate(test_loader):\n",
    "    inputs, labels = data\n",
    "#     images = images.view(-1, 28*28)\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.shape[0]\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 2500 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S8PEscXpQLuK"
   },
   "source": [
    "### 6. batch normalization 적용 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BK7ESXhNQQct"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, src):\n",
    "        super(Net, self).__init__()\n",
    "        # .Linear Layer\n",
    "        self.fc1 = nn.Linear(src['input_size'], src['hidden_size1'])\n",
    "        self.fc2 = nn.Linear(src['hidden_size1'], src['hidden_size2'])\n",
    "        self.fc3 = nn.Linear(src['hidden_size2'], src['output_size'])\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.init_range = src['init_weight_range']\n",
    "        self.bn1 = nn.BatchNorm1d(src['hidden_size1'])\n",
    "        self.bn2 = nn.BatchNorm1d(src['hidden_size2'])\n",
    "        self.bn3 = nn.BatchNorm1d(src['output_size'])\n",
    "\n",
    "\n",
    "        \n",
    "    # 가중치 초기화  (생략가능)\n",
    "    def init_weight(self):\n",
    "        self.fc1.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "        self.fc2.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "        self.fc3.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "        self.bn1.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "        self.bn2.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "        self.bn3.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "\n",
    "        '''       \n",
    "        for fc in self.seq_fc:\n",
    "            fc.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "        '''\n",
    "    # 위에서는 layer 선언만 한 것이지 구체적 적용방법을 설정하지 않음\n",
    "    # 여기선 구체적인 사용 방법을 설정\n",
    "    # input data를 선언 (여기선 img)\n",
    "    def forward(self, img):\n",
    "        x = img.view(img.shape[0], -1) # image (1 X 3 X 32 X 32)에서 첫 차원은 그대로 두고 뒤 차원들을 다 faltten해 2차원으로 \n",
    "        # 아래의 과정을 거치겠다.\n",
    "        #--------------------\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.fc3(x)\n",
    "        y = self.bn3(x)\n",
    "        #--------------------\n",
    "        \n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "99ThB_etRIDU"
   },
   "outputs": [],
   "source": [
    "model = Net(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4409
    },
    "colab_type": "code",
    "id": "79IkUcx0RIii",
    "outputId": "d7ae4c9a-b9a7-4f50-fb9a-cb81005ab57a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/400], Loss: 2.3966\n",
      "Epoch [1/5], Step [200/400], Loss: 2.3933\n",
      "Epoch [1/5], Step [300/400], Loss: 2.3912\n",
      "Epoch [1/5], Step [400/400], Loss: 2.3935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:08<00:35,  8.77s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Step [100/400], Loss: 2.3921\n",
      "Epoch [2/5], Step [200/400], Loss: 2.3927\n",
      "Epoch [2/5], Step [300/400], Loss: 2.3960\n",
      "Epoch [2/5], Step [400/400], Loss: 2.3963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:17<00:26,  8.77s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Step [100/400], Loss: 2.3921\n",
      "Epoch [3/5], Step [200/400], Loss: 2.3957\n",
      "Epoch [3/5], Step [300/400], Loss: 2.3941\n",
      "Epoch [3/5], Step [400/400], Loss: 2.3934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:26<00:17,  8.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Step [100/400], Loss: 2.3930\n",
      "Epoch [4/5], Step [200/400], Loss: 2.3941\n",
      "Epoch [4/5], Step [300/400], Loss: 2.3932\n",
      "Epoch [4/5], Step [400/400], Loss: 2.3932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:35<00:08,  8.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Step [100/400], Loss: 2.3980\n",
      "Epoch [5/5], Step [200/400], Loss: 2.3908\n",
      "Epoch [5/5], Step [300/400], Loss: 2.3928\n",
      "Epoch [5/5], Step [400/400], Loss: 2.3912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:43<00:00,  8.73s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "model.init_weight()\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(src[\"num_epochs\"])):\n",
    "    current_loss = 0.0  # loss 초기화.\n",
    "    \n",
    "    for i, data in enumerate(train_loader): # 한 번 루프 돌 때마다 Batch-size만큼 처리하도록 trainloader에서 정의함\n",
    "        # get the inputs\n",
    "        inputs, labels = data # 사진과 클래스가 묶여 들어가 있으므로\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad() # gradient를 iter 돌기 전 초기화 시켜줌\n",
    "        \n",
    "        # forward + backward + optimization\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels) # outpuut과 label의 차이를 cross entropy loss로 계산\n",
    "        loss.backward()\n",
    "        optimizer.step() # 이를 optim.SGD로 처리후 W를 update\n",
    "        \n",
    "        # print statistics\n",
    "        # 100 step 마다 확인 100step의 평균값(1step은 batch-size만큼의 Loss를 계산함.)\n",
    "        step = i + 1\n",
    "        current_loss += loss.item()\n",
    "        \n",
    "        if step % 100 == 0 and step !=0:\n",
    "            print(\"Epoch [%d/%d], Step [%d/%d], Loss: %.4f\" %\n",
    "                 (epoch + 1, src[\"num_epochs\"], step, len(train_loader)//100*100, current_loss / 100))\n",
    "            current_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dSTI10-jRTO-"
   },
   "source": [
    "### 평가 데이터를 이용한 네트워크 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9L3UHfacRTO-",
    "outputId": "0389697e-b55e-46ba-90b2-b85939378c4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 2500 test images: 7 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "# Test set으로 성능 평가.\n",
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "\n",
    "for i, data in enumerate(test_loader):\n",
    "    inputs, labels = data\n",
    "#     images = images.view(-1, 28*28)\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.shape[0]\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 2500 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iGEL-z_vRK8t"
   },
   "source": [
    "# 7. 혼합\n",
    "- epoch :10\n",
    "- batch_size : 256\n",
    "- Adam Optimizer\n",
    "- dropout\n",
    "- batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OOXVPMnaRyit"
   },
   "outputs": [],
   "source": [
    "# config\n",
    "src = {'input_size':1*28*28, \n",
    "       'hidden_size1':10, \n",
    "       'hidden_size2':10,\n",
    "       'output_size':10,\n",
    "       'init_weight_range':0.5,\n",
    "       'num_epochs':10,\n",
    "       'batch_size':1024,\n",
    "       'learning_rate':1e-4}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=src[\"batch_size\"], shuffle=True) # 지정한 batch-size로 묶음\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,  batch_size=src[\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CudordJGRyiu"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ud_PiCFbSFh3"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, src):\n",
    "        super(Net, self).__init__()\n",
    "        # .Linear Layer\n",
    "        self.fc1 = nn.Linear(src['input_size'], src['hidden_size1'])\n",
    "        self.fc2 = nn.Linear(src['hidden_size1'], src['hidden_size2'])\n",
    "        self.fc3 = nn.Linear(src['hidden_size2'], src['output_size'])\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.init_range = src['init_weight_range']\n",
    "        self.bn1 = nn.BatchNorm1d(src['hidden_size1'])\n",
    "        self.bn2 = nn.BatchNorm1d(src['hidden_size2'])\n",
    "        self.bn3 = nn.BatchNorm1d(src['output_size'])\n",
    "\n",
    "\n",
    "        \n",
    "    # 가중치 초기화  (생략가능)\n",
    "    def init_weight(self):\n",
    "        # He \n",
    "        torch.nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        torch.nn.init.kaiming_normal_(self.fc2.weight)\n",
    "        torch.nn.init.kaiming_uniform_(self.fc3.weight)\n",
    "        self.bn1.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "        self.bn2.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "        self.bn3.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "\n",
    "\n",
    "        '''       \n",
    "        for fc in self.seq_fc:\n",
    "            fc.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "        '''\n",
    "    # 위에서는 layer 선언만 한 것이지 구체적 적용방법을 설정하지 않음\n",
    "    # 여기선 구체적인 사용 방법을 설정\n",
    "    # input data를 선언 (여기선 img)\n",
    "    def forward(self, img):\n",
    "        x = img.view(img.shape[0], -1) \n",
    "        # 아래의 과정을 거치겠다.\n",
    "        #--------------------\n",
    "        x = self.fc1(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.relu1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.relu2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.fc3(x)\n",
    "        y = self.bn3(x)\n",
    "        #--------------------\n",
    "        \n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OOhyL9ZcS11k"
   },
   "outputs": [],
   "source": [
    "model = Net(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XXsaDPEMh9oK"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7937
    },
    "colab_type": "code",
    "id": "T40HxcL8SDWk",
    "outputId": "bf56fbe8-9192-4586-a7d0-51b5834e02b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|█         | 1/10 [00:09<01:28,  9.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1, train loss : 2.3412, valid loss : 2.3187, valid acc : 6.00%\n",
      "0 / 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 2/10 [00:19<01:18,  9.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 2, train loss : 2.3401, valid loss : 2.3187, valid acc : 6.00%\n",
      "0 / 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███       | 3/10 [00:29<01:08,  9.81s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 3, train loss : 2.3429, valid loss : 2.3184, valid acc : 6.00%\n",
      "0 / 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:39<00:58,  9.81s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 4, train loss : 2.3426, valid loss : 2.3186, valid acc : 6.00%\n",
      "0 / 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 5/10 [00:48<00:48,  9.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5, train loss : 2.3421, valid loss : 2.3187, valid acc : 6.00%\n",
      "0 / 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 6/10 [00:58<00:39,  9.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 6, train loss : 2.3414, valid loss : 2.3184, valid acc : 6.00%\n",
      "0 / 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████   | 7/10 [01:08<00:29,  9.77s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 7, train loss : 2.3430, valid loss : 2.3185, valid acc : 6.00%\n",
      "0 / 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 8/10 [01:18<00:19,  9.79s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 8, train loss : 2.3413, valid loss : 2.3182, valid acc : 6.00%\n",
      "0 / 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|█████████ | 9/10 [01:28<00:09,  9.77s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 9, train loss : 2.3422, valid loss : 2.3187, valid acc : 6.00%\n",
      "0 / 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 10/10 [01:37<00:00,  9.79s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 10, train loss : 2.3404, valid loss : 2.3187, valid acc : 6.00%\n"
     ]
    }
   ],
   "source": [
    "model.init_weight()\n",
    "\n",
    "mean_train_losses = []\n",
    "mean_valid_losses = []\n",
    "valid_acc_list = []\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(src[\"num_epochs\"])):\n",
    "    #current_loss = 0.0  # loss 초기화.\n",
    "    model.train()\n",
    "    \n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    for i, data in enumerate(train_loader): # 한 번 루프 돌 때마다 128개씩 처리하도록 trainloader에서 정의함\n",
    "        # get the inputs\n",
    "        inputs, labels = data # 사진과 클래스가 묶여 들어가 있으므로\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad() # gradient를 iter 돌기 전 초기화 시켜줌\n",
    "        \n",
    "        # forward + backward + optimization\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels) # outpuut과 label의 차이를 cross entropy loss로 계산\n",
    "        loss.backward()\n",
    "        optimizer.step() # 이를 optim.SGD로 처리후 W를 update\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        if (i * src['batch_size']) % (src['batch_size'] * 100) == 0:\n",
    "            print(f'{i * 512} / 50000')\n",
    "        \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            inputs, labels = data\n",
    "        #     images = images.view(-1, 28*28)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            valid_losses.append(loss.item())\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.shape[0]\n",
    "            correct += (predicted == labels).sum()\n",
    "\n",
    "    mean_train_losses.append(np.mean(train_losses))\n",
    "    mean_valid_losses.append(np.mean(valid_losses))\n",
    "\n",
    "    accuracy = 100*correct/total\n",
    "    valid_acc_list.append(accuracy)\n",
    "    print('epoch : {}, train loss : {:.4f}, valid loss : {:.4f}, valid acc : {:.2f}%'\\\n",
    "         .format(epoch+1, np.mean(train_losses), np.mean(valid_losses), accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oKqqIR5jSpmt"
   },
   "source": [
    "### 평가 데이터를 이용한 네트워크 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ELnn6rM9Spmt",
    "outputId": "4a364d87-2605-40b0-d4bf-b30850f08d93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 2500 test images: 6 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "# Test set으로 성능 평가.\n",
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "\n",
    "for i, data in enumerate(test_loader):\n",
    "    inputs, labels = data\n",
    "#     images = images.view(-1, 28*28)\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.shape[0]\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 2500 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SXUBC5faU5XD"
   },
   "source": [
    "#### 다 적용했는데 오히려 성능이 좋지않다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OrMIwdtVU_Nb"
   },
   "source": [
    "## 2. 자신이 만든 모델로 test시 실제 값을 맞추지 못한 사진에 대해서 실제 레이블과, 예측한 레이블을 동시에 프린트\n",
    "- 제일 좋았던 Adam optimizer 적용모델로 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I8rxXL80Z_8T"
   },
   "outputs": [],
   "source": [
    "# config\n",
    "src = {'input_size':1*28*28, \n",
    "       'hidden_size1':5, \n",
    "       'hidden_size2':5,\n",
    "       'output_size':10,\n",
    "       'init_weight_range':0.5,\n",
    "       'num_epochs':5,\n",
    "       'batch_size':128,\n",
    "       'learning_rate':1e-3}\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=src[\"batch_size\"], shuffle=True) # 지정한 batch-size로 묶음\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,  batch_size=src[\"batch_size\"], shuffle=False)\n",
    "\n",
    "model = Net(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NNKW7A03Z_8U"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),\n",
    "                     src[\"learning_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4787
    },
    "colab_type": "code",
    "id": "kpKr3iliZ_8V",
    "outputId": "5d3b8277-94b6-4a8f-a0fe-e90b0a403fcf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/400], Loss: 2.2869\n",
      "Epoch [1/5], Step [200/400], Loss: 2.2049\n",
      "Epoch [1/5], Step [300/400], Loss: 2.1648\n",
      "Epoch [1/5], Step [400/400], Loss: 2.1346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:09<00:36,  9.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Step [100/400], Loss: 2.0904\n",
      "Epoch [2/5], Step [200/400], Loss: 2.0674\n",
      "Epoch [2/5], Step [300/400], Loss: 2.0517\n",
      "Epoch [2/5], Step [400/400], Loss: 2.0431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:18<00:27,  9.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Step [100/400], Loss: 2.0346\n",
      "Epoch [3/5], Step [200/400], Loss: 2.0127\n",
      "Epoch [3/5], Step [300/400], Loss: 2.0240\n",
      "Epoch [3/5], Step [400/400], Loss: 2.0215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:27<00:18,  9.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Step [100/400], Loss: 2.0058\n",
      "Epoch [4/5], Step [200/400], Loss: 1.9943\n",
      "Epoch [4/5], Step [300/400], Loss: 1.9919\n",
      "Epoch [4/5], Step [400/400], Loss: 1.9917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:36<00:09,  9.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Step [100/400], Loss: 1.9914\n",
      "Epoch [5/5], Step [200/400], Loss: 1.9879\n",
      "Epoch [5/5], Step [300/400], Loss: 1.9848\n",
      "Epoch [5/5], Step [400/400], Loss: 1.9856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:45<00:00,  9.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "model.init_weight()\n",
    "\n",
    "for epoch in tqdm(range(src[\"num_epochs\"])):\n",
    "    current_loss = 0.0  # loss 초기화.\n",
    "    \n",
    "    for i, data in enumerate(train_loader): # 한 번 루프 돌 때마다 128개씩 처리하도록 trainloader에서 정의함\n",
    "        # get the inputs\n",
    "        inputs, labels = data # 사진과 클래스가 묶여 들어가 있으므로\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad() # gradient를 iter 돌기 전 초기화 시켜줌\n",
    "        \n",
    "        # forward + backward + optimization\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels) # outpuut과 label의 차이를 cross entropy loss로 계산\n",
    "        loss.backward()\n",
    "        optimizer.step() # 이를 optim.SGD로 처리후 W를 update\n",
    "        \n",
    "        # print statistics\n",
    "        # 100 step 마다 확인 = 12800개 image에 대한 loss값 (1step당 128개에 대한 loss이므로)\n",
    "        # 확인해야 하는 loss는 1회 부터 현재 iter까지 누적된 loss의 평균값\n",
    "        step = i + 1\n",
    "        current_loss += loss.item()\n",
    "        \n",
    "        if step % 100 == 0 and step !=0:\n",
    "            print(\"Epoch [%d/%d], Step [%d/%d], Loss: %.4f\" %\n",
    "                 (epoch + 1, src[\"num_epochs\"], step, len(train_loader)//100 * 100, current_loss / 100))\n",
    "            current_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y0zr3RHjZ_8X"
   },
   "source": [
    "### 평가 데이터를 이용한 네트워크 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "guTt5wRgZ_8Y",
    "outputId": "4ba85281-a4e5-4bba-bdd8-83067d5dfa70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 2500 test images: 24 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "# Test set으로 성능 평가.\n",
    "correct = 0\n",
    "total = 0\n",
    "for i, data in enumerate(test_loader):\n",
    "    inputs, labels = data\n",
    "#     images = images.view(-1, 28*28)\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.shape[0]\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 2500 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "colab_type": "code",
    "id": "CnHmwcwcbS0m",
    "outputId": "7e698eef-aa9e-473d-9933-c136e72a066d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.figure>"
      ]
     },
     "execution_count": 537,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhMAAAFvCAYAAADwq0kDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJElSJr5MSJKkTP4PBZW6KLO/xogAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x396 with 16 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(inputs[i][0], cmap=\"gray\", interpolation=\"none\")\n",
    "    plt.title(\"Truth/Predict : {0}/{1}\".format(labels[i], predicted[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[11기 김대웅]W06_Advanced_NN_Assignment_02.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
