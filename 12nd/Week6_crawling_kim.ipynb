{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffd8e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "from selenium import webdriver\n",
    "import random\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1731978",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_contents=[]\n",
    "post_date=[]\n",
    "comment_contents=[]\n",
    "comment_writer=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466235e3",
   "metadata": {},
   "source": [
    "### 과제 1: Selenium을 이용한 인스타 크롤링 수도코드 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5c1e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "insta_url = \"https://www.instagram.com\" # 인스타 url \n",
    "browser = webdriver.Chrome() # 브라우저 on\n",
    "browser.get(insta_url) # 접속"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5847e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for scroll in range(1,100) : # 스크롤 한 번 할때마다 50개씩 늘어난다고 가정\n",
    "    # 게시물 태그 추출\n",
    "    post_tags = browser.find_elements_by_class_name('posts_tag')\n",
    "    # 게시물 정보 추출\n",
    "    for post in post_tags :\n",
    "        post_contents.append( (post.find_element_by_tag_name('contents')).text )\n",
    "        post_date.append( (post.find_element_by_tag_name('d')).text )\n",
    "        # 게시물 클릭\n",
    "        post_button = browser.find_element_by_xpath('//*[@id=\"react-root\"]/section/main/article/div[2]/div/div[4]/div[2]')\n",
    "        post_button.click()\n",
    "        # 댓글 태그 추출\n",
    "        comment_tags= browser.find_elements_by_class_name('comments_tag')\n",
    "        # 댓글 정보 추출\n",
    "        for comment in comment_tags:\n",
    "            comment_contents.append( (comment.find_element_by_tag_name('comment_contents')).text )\n",
    "            comment_writer.append( (comment.find_element_by_tag_name('wrt')).text)\n",
    "    \n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\") # 스크롤 끝까지\n",
    "    sleep(random.uniform(0,1)) # 휴식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b996446",
   "metadata": {},
   "source": [
    "### 과제 2: 다음 영화 사이트 2년치 데이터 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d02ad0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 동적 크롤링 (Selenium)\n",
    "def daum_movie_crawler_selenium():\n",
    "    \n",
    "    #변수입력받기(다양한 방식 시도)\n",
    "    this_year=int(input('몇 년도부터 수집할까요?'))\n",
    "    for_year=int(input('지금부터 과거 몇 년치 데이터를 수집해야하나요?'))\n",
    "    \n",
    "    #리스트 생성\n",
    "    titles=[]\n",
    "    net_grade=[]\n",
    "    cri_grade=[]\n",
    "    aud_list=[]\n",
    "    \n",
    "    #브라우저 실행\n",
    "    main_url = 'https://movie.daum.net/boxoffice/yearly?year='+str(this_year)\n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get(main_url)\n",
    "    reg=re.compile('\\d') #  수 추출을 위한 정규표현식    \n",
    "    \n",
    "    for times in range(for_year):\n",
    "        links=[]\n",
    "        poster_table=browser.find_elements_by_class_name('wrap_movie') # 포스터 테이블\n",
    "        exist_verify_table=browser.find_elements_by_class_name('img_g') # 정보 존재 검정용 테이블\n",
    "        \n",
    "        for poster,exist_verify in zip(poster_table,exist_verify_table):\n",
    "            \n",
    "            # 정보 담고있는 테이블\n",
    "            info_table = poster.find_element_by_tag_name('a')\n",
    "            \n",
    "            # 존재 검정용 변수\n",
    "            ex_num=exist_verify.get_attribute('src')\n",
    "            \n",
    "            # 제목 추출 \n",
    "            title = info_table.text\n",
    "            titles.append(title)\n",
    "            \n",
    "            # 검정\n",
    "            if len((str(ex_num))) <= 15: \n",
    "                net_grade.append(None)\n",
    "                cri_grade.append(None)\n",
    "                links.append(None)\n",
    "                continue\n",
    "            \n",
    "            # 평점 테이블\n",
    "            score_table= reg.findall(poster.find_element_by_class_name('info_grade').text)\n",
    "            \n",
    "            # 네티즌 평점\n",
    "            net_score = float(score_table[1])+float(score_table[3])/10\n",
    "            net_grade.append(net_score)\n",
    "            \n",
    "            # 평론가 평점\n",
    "            try :\n",
    "                cri_score = float(score_table[5])+float(score_table[7])/10\n",
    "                cri_grade.append(cri_score)\n",
    "            except Exception as e :\n",
    "                cri_grade.append(None)\n",
    "                print(e,'Error at'+str(title))\n",
    "                \n",
    "             # 링크 추출\n",
    "            link = info_table.get_attribute('href')\n",
    "            links.append(link)\n",
    "        \n",
    "        for link in links:\n",
    "            try :\n",
    "                browser.get(link) # 이동\n",
    "                aud_list.append(int(''.join(reg.findall(browser.find_element_by_id('totalAudience').text))))\n",
    "            except Exception as e :\n",
    "                aud_list.append(None)\n",
    "            \n",
    "        browser.get(main_url)\n",
    "        button=browser.find_element_by_xpath('//*[@id=\"divCalendarBox\"]/a')\n",
    "        button.click()\n",
    "            \n",
    "    data = pd.concat([pd.Series(titles),pd.Series(net_grade),pd.Series(cri_grade),pd.Series(aud_list)],axis=1)            \n",
    "    data.columns=['title','netizen_score','critic_grade','totalAudience']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298778fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s=daum_movie_crawler_selenium()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fcae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 정적 크롤링(Request)\n",
    "from time import sleep\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from random import randint\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import lxml.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e332b470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(table):\n",
    "    score = table.findAll('span',{\"class\" : 'num_grade'})\n",
    "    first=float(score[0].text)\n",
    "    second=float(score[2].text)/10\n",
    "    return (first+second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93f3224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daum_movie_crawler(start_year,end_year):\n",
    "    #추출할 데이터 리스트생성\n",
    "    titles=[]\n",
    "    net_grade=[]\n",
    "    cri_grade=[]\n",
    "    aud_list=[]\n",
    "    \n",
    "    for year in range(int(start_year),int(end_year+1)):\n",
    "        #원활한 크롤링을 위한 헤더\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; InteSl Mac O X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "        #url 입력\n",
    "        main_url = 'https://movie.daum.net/boxoffice/yearly?year='+str(year)\n",
    "        response = requests.get(main_url,headers=headers) #접속\n",
    "    \n",
    "        #테이블 분리\n",
    "        body_table = bs(response.text,'lxml')\n",
    "        poster_table = body_table.find_all('div',class_='wrap_movie') # 포스터 테이블  \n",
    "        exist_verify_table=body_table.find_all(class_='img_g') # 정보가 존재하는지 검정용 테이블\n",
    " \n",
    "        reg=re.compile('\\d') #  관객수 추출을 위한 정규표현식\n",
    "        reg2=re.compile('src.*/') # 이미지 링크가 없는경우 다른 정보도 없는 것 발견, 따라서 링크 부분의 길이가 짧으면 \n",
    "                                  # 변수를 NA값으로 채워서 용이한 df생성 의도\n",
    "    \n",
    "    \n",
    "        # 제목 , 네티즌 평점, 평론가 평점 추출\n",
    "        for poster,exist_verify in zip(poster_table,exist_verify_table):\n",
    "            # 제목 추출 \n",
    "            title = poster.find('a', class_='name_movie #title').text\n",
    "            titles.append(title)\n",
    "            # 검정\n",
    "            if len(str(reg2.findall(str(exist_verify)))) <= 15: \n",
    "                net_grade.append(None)\n",
    "                cri_grade.append(None)\n",
    "                aud_list.append(None)\n",
    "                continue\n",
    "            \n",
    "            # 네티즌 평점\n",
    "            net_grade_table = poster.find(\"span\",{\"class\":\"wrap_grade grade_netizen\"})\n",
    "            net_grade.append(compute_score(net_grade_table))\n",
    "            \n",
    "            # 평론가 평점\n",
    "            try : \n",
    "                critic_grade_table= poster.find(\"span\",{\"class\":\"wrap_grade grade_critic\"})\n",
    "                cri_grade.append(compute_score(critic_grade_table))\n",
    "            except Exception as e :\n",
    "                cri_grade.append(None)\n",
    "                print(e,'Error at {} for {}'.format(year,title))\n",
    "                \n",
    "            # 누적 관객수\n",
    "            \n",
    "            movie_id=(''.join(reg.findall(poster.find('a')['href'])))        \n",
    "            aud_url='https://movie.daum.net/moviedb/main/totalAudience.json?movieId='+movie_id # 링크 확보\n",
    "            response = requests.get(aud_url,headers=headers)\n",
    "            try : \n",
    "                aud_list.append(int(''.join(reg.findall(response.text))))\n",
    "            except Exception as e :\n",
    "                aud_list.append(None)\n",
    "                print(e,str(movie_id)+'에서 누적관객추출 실패')\n",
    "                \n",
    "            \n",
    "    data = pd.concat([pd.Series(titles),pd.Series(net_grade),pd.Series(cri_grade),pd.Series(aud_list)],axis=1)            \n",
    "    data.columns=['title','netizen_score','critic_grade','totalAudience']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26c1912",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=daum_movie_crawler(2018,2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a134ded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='totalAudience',inplace=True,ascending=False)\n",
    "df_s.sort_values(by='totalAudience',inplace=True,ascending=False)\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c922c37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_s.info()) # 구조, 결측치 동일 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81e9ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치는 데이터타입을 float이나 int로 만들기 위해 None을 넣어주었음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24033394",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('과제.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
