{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3963332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1번. AlexNet모델구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ed9fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO ##\n",
    "\n",
    "######################################################\n",
    "#  Calculate the number of parameters in this layer  #\n",
    "######################################################\n",
    "\n",
    "Conv_1 = (11*11*3) * 96 + 96 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141c049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO \n",
    "\n",
    "######################################################\n",
    "#  Calculate the number of parameters in this layer  #\n",
    "######################################################\n",
    "\n",
    "Max_pool_1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0b808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO \n",
    "\n",
    "######################################################\n",
    "#  Calculate the number of parameters in this layer  #\n",
    "######################################################\n",
    "\n",
    "Conv_2 = (5*5*96)*256+256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5b5b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO \n",
    "\n",
    "######################################################\n",
    "#  Calculate the number of parameters in this layer  #\n",
    "######################################################\n",
    "\n",
    "Max_pool_2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80301b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO \n",
    "\n",
    "######################################################\n",
    "#  Calculate the number of parameters in this layer  #\n",
    "######################################################\n",
    "\n",
    "Conv_3 = (3*3*256)*384 +384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058a5bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO \n",
    "\n",
    "######################################################\n",
    "#  Calculate the number of parameters in this layer  #\n",
    "######################################################\n",
    "\n",
    "Conv_4 = (3*3*384)*384 +384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35565913",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO \n",
    "\n",
    "######################################################\n",
    "#  Calculate the number of parameters in this layer  #\n",
    "######################################################\n",
    "\n",
    "Conv_5 = (3*3*384)*256 +256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aa1fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO \n",
    "\n",
    "######################################################\n",
    "#  Calculate the number of parameters in this layer  #\n",
    "######################################################\n",
    "\n",
    "Max_pool_3 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b0307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO \n",
    "\n",
    "######################################################\n",
    "#  Calculate the number of parameters in this layer  #\n",
    "######################################################\n",
    "\n",
    "FC1 = (6*6*256)*4096 + 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836e8592",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO \n",
    "\n",
    "######################################################\n",
    "#  Calculate the number of parameters in this layer  #\n",
    "######################################################\n",
    "\n",
    "FC2 = 4096 * 4096 + 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1b2391",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO \n",
    "\n",
    "######################################################\n",
    "#  Calculate the number of parameters in this layer  #\n",
    "######################################################\n",
    "\n",
    "FC3 = 4096 * 1000 + 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dffcdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2번. AlexNet구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fefbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Lambda\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.engine.topology import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbd352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (227, 227, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff86947",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(96, (11, 11), strides=4,\n",
    "                 padding='same', input_shape=input_shape))\n",
    "model.add(Conv2D(256, (5, 5), activation='relu', padding='same'))\n",
    "model.add(LocalResponseNormalization(input_shape=model.output_shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "model.add(Conv2D(384, (3, 3), activation='relu', padding='same'))\n",
    "model.add(LocalResponseNormalization(input_shape=model.output_shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "model.add(Conv2D(384, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1000, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce1878e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.SGD(lr=0.01, decay=5e-5, momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab3b240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets,transforms\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "transform = transforms.Compose(\n",
    "    [transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4339a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transformer)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16dcda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = torch.utils.data.DataLoader(dataset=training_dataset, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e3af31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=3, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Dropout(0.6),\n",
    "            nn.Linear(4096, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.6),\n",
    "            nn.Linear(2048, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(2048, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_features = self.features(x)\n",
    "        flatten = conv_features.view(conv_features.size(0), -1)\n",
    "        fc = self.fc_layers(flatten)\n",
    "        return fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eb3c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 128\n",
    "log_batch = 200\n",
    "train_list = []\n",
    "test_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb02c6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNet()\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1b6311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model summary\n",
    "summary(model,(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d7a058",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503feb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_classified = 0\n",
    "        total = 0\n",
    "        start_time = time.time()\n",
    "        for i, data in enumerate(training_loader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct_classified += (predicted == labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "            if i % log_batch == log_batch - 1:\n",
    "                avg_loss = running_loss / log_batch\n",
    "                print('Epoch: %d/%d Batch: %5d loss: %.3f' % (epoch + 1, epochs, i + 1, avg_loss))\n",
    "                running_loss = 0.0\n",
    "        print(\"Time/epoch: {} sec\".format(time.time() - start_time))\n",
    "        train_acc = (100 * correct_classified / total)\n",
    "        train_list.append(train_acc)\n",
    "        print('Train accuracy : %d %%' % train_acc)\n",
    "        torch.save(net.state_dict(), \"model.h5\") # 모델을 저장\n",
    "        correct_classified = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                images, labels = data\n",
    "                inputs, labels = images.to(device), labels.to(device)\n",
    "                outputs = net(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct_classified += (predicted == labels).sum().item()\n",
    "            test_acc = (100 * correct_classified / total)\n",
    "            test_list.append(test_acc)\n",
    "            print('Test accuracy : %d %%' % test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd4740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab에서 돌린 결과값\n",
    "# Epoch: 1/20 Batch:   200 loss: 1.271\n",
    "# Epoch: 1/20 Batch:   400 loss: 1.176\n",
    "# Time/epoch: 51.72108054161072 sec\n",
    "# Train accuracy of the network images: 56 %\n",
    "# Test accuracy of the network: 58 %\n",
    "# Epoch: 2/20 Batch:   200 loss: 1.048\n",
    "# Epoch: 2/20 Batch:   400 loss: 1.004\n",
    "# Time/epoch: 51.59315204620361 sec\n",
    "# Train accuracy of the network images: 64 %\n",
    "# Test accuracy of the network: 64 %\n",
    "# Epoch: 3/20 Batch:   200 loss: 0.903\n",
    "# Epoch: 3/20 Batch:   400 loss: 0.888\n",
    "# Time/epoch: 51.604798316955566 sec\n",
    "# Train accuracy of the network images: 68 %\n",
    "# Test accuracy of the network: 68 %\n",
    "# Epoch: 4/20 Batch:   200 loss: 0.780\n",
    "# Epoch: 4/20 Batch:   400 loss: 0.809\n",
    "# Time/epoch: 51.63756847381592 sec\n",
    "# Train accuracy of the network images: 72 %\n",
    "# Test accuracy of the network: 70 %\n",
    "# Epoch: 5/20 Batch:   200 loss: 0.712\n",
    "# Epoch: 5/20 Batch:   400 loss: 0.720\n",
    "# Time/epoch: 51.69989371299744 sec\n",
    "# Train accuracy of the network images: 75 %\n",
    "# Test accuracy of the network: 71 %\n",
    "# Epoch: 6/20 Batch:   200 loss: 0.637\n",
    "# Epoch: 6/20 Batch:   400 loss: 0.666\n",
    "# Time/epoch: 51.617228746414185 sec\n",
    "# Train accuracy of the network images: 77 %\n",
    "# Test accuracy of the network: 72 %\n",
    "# Epoch: 7/20 Batch:   200 loss: 0.592\n",
    "# Epoch: 7/20 Batch:   400 loss: 0.610\n",
    "# Time/epoch: 51.64090609550476 sec\n",
    "# Train accuracy of the network images: 79 %\n",
    "# Test accuracy of the network: 74 %\n",
    "# Epoch: 8/20 Batch:   200 loss: 0.547\n",
    "# Epoch: 8/20 Batch:   400 loss: 0.561\n",
    "# Time/epoch: 51.69233179092407 sec\n",
    "# Train accuracy of the network images: 80 %\n",
    "# Test accuracy of the network: 75 %\n",
    "# Epoch: 9/20 Batch:   200 loss: 0.486\n",
    "# Epoch: 9/20 Batch:   400 loss: 0.519\n",
    "# Time/epoch: 51.62518811225891 sec\n",
    "# Train accuracy of the network images: 82 %\n",
    "# Test accuracy of the network: 74 %\n",
    "# Epoch: 10/20 Batch:   200 loss: 0.458\n",
    "# Epoch: 10/20 Batch:   400 loss: 0.494\n",
    "# Time/epoch: 51.65696334838867 sec\n",
    "# Train accuracy of the network images: 83 %\n",
    "# Test accuracy of the network: 75 %\n",
    "# Epoch: 11/20 Batch:   200 loss: 0.413\n",
    "# Epoch: 11/20 Batch:   400 loss: 0.458\n",
    "# Time/epoch: 51.61623287200928 sec\n",
    "# Train accuracy of the network images: 84 %\n",
    "# Test accuracy of the network: 75 %\n",
    "# Epoch: 12/20 Batch:   200 loss: 0.407\n",
    "# Epoch: 12/20 Batch:   400 loss: 0.427\n",
    "# Time/epoch: 51.5536003112793 sec\n",
    "# Train accuracy of the network images: 85 %\n",
    "# Test accuracy of the network: 75 %\n",
    "# Epoch: 13/20 Batch:   200 loss: 0.370\n",
    "# Epoch: 13/20 Batch:   400 loss: 0.391\n",
    "# Time/epoch: 51.65504288673401 sec\n",
    "# Train accuracy of the network images: 86 %\n",
    "# Test accuracy of the network: 75 %\n",
    "# Epoch: 14/20 Batch:   200 loss: 0.353\n",
    "# Epoch: 14/20 Batch:   400 loss: 0.377\n",
    "# Time/epoch: 51.59739279747009 sec\n",
    "# Train accuracy of the network images: 87 %\n",
    "# Test accuracy of the network: 76 %\n",
    "# Epoch: 15/20 Batch:   200 loss: 0.324\n",
    "# Epoch: 15/20 Batch:   400 loss: 0.352\n",
    "# Time/epoch: 51.5103600025177 sec\n",
    "# Train accuracy of the network images: 88 %\n",
    "# Test accuracy of the network: 76 %\n",
    "# Epoch: 16/20 Batch:   200 loss: 0.292\n",
    "# Epoch: 16/20 Batch:   400 loss: 0.348\n",
    "# Time/epoch: 51.63554072380066 sec\n",
    "# Train accuracy of the network images: 88 %\n",
    "# Test accuracy of the network: 75 %\n",
    "# Epoch: 17/20 Batch:   200 loss: 0.287\n",
    "# Epoch: 17/20 Batch:   400 loss: 0.321\n",
    "# Time/epoch: 51.56595015525818 sec\n",
    "# Train accuracy of the network images: 89 %\n",
    "# Test accuracy of the network: 76 %\n",
    "# Epoch: 18/20 Batch:   200 loss: 0.273\n",
    "# Epoch: 18/20 Batch:   400 loss: 0.293\n",
    "# Time/epoch: 51.497596979141235 sec\n",
    "# Train accuracy of the network images: 90 %\n",
    "# Test accuracy of the network: 76 %\n",
    "# Epoch: 19/20 Batch:   200 loss: 0.252\n",
    "# Epoch: 19/20 Batch:   400 loss: 0.285\n",
    "# Time/epoch: 51.631884813308716 sec\n",
    "# Train accuracy of the network images: 90 %\n",
    "# Test accuracy of the network: 76 %\n",
    "# Epoch: 20/20 Batch:   200 loss: 0.245\n",
    "# Epoch: 20/20 Batch:   400 loss: 0.265\n",
    "# Time/epoch: 51.55575180053711 sec\n",
    "# Train accuracy of the network images: 91 %\n",
    "# Test accuracy of the network: 75 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343893fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd38b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_list, label='Train ACC')\n",
    "plt.plot(test_list, label='Test ACC')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f94952",
   "metadata": {},
   "source": [
    ": 그래프로 표현했을 때 Train Accuracy는 계속 증가하지만 Test Accuracy는 75%에서 멈춘것을 봐서 overfitting 되어서 75%에서 증가하지않을 것을 알 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
