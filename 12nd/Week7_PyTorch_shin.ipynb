{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52f14da9",
   "metadata": {},
   "source": [
    "## 1번 과제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650d14e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a374f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63af70e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/content/drive/My Drive/data/fashionmnist/fashion-mnist_train.csv')\n",
    "test_data = pd.read_csv('/content/drive/My Drive/data/fashionmnist/fashion-mnist_test.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deacc35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 데이터와 라벨 데이터 분리\n",
    "train_x = np.array(train_data.iloc[:,1:])\n",
    "train_y = np.array(train_data['label'])\n",
    "test_x = np.array(test_data.iloc[:,1:])\n",
    "test_y = np.array(test_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a172b954",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953cec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화 \n",
    "# 임의로 3번사진을 가져옵니다.\n",
    "image_array = np.array(train_x[3]).reshape(28,28)\n",
    "pic = Image.fromarray(image_array.astype('uint8'))\n",
    "plt.imshow(pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a83937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e15c518",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91ea77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 선택\n",
    "random_seed = 0\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 40\n",
    "batch_size = 32\n",
    " \n",
    "input_size = 784\n",
    "h1_size = 512\n",
    "h2_size = 512 \n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e34388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 클래스로 만들고 파이토치의 dataloader로 만들어주면 손쉽게 훈련에서 사용할 수 있습니다.\n",
    "# 함수들은 dataloader로 데이터를 끌고올 때 사용됩니다.\n",
    "class FashionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        # import and initialize dataset\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    " \n",
    "    def __len__(self):\n",
    "        # returns length of data\n",
    "        return len(self.X)\n",
    "    \n",
    "dataset = FashionDataset(train_x, train_y)\n",
    "testset = FashionDataset(test_x, test_y)\n",
    "print(type(dataset))\n",
    "print(len(dataset))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d82a8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8e57b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다층 신경망 클래스 정의\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, h1_size, h2_size):\n",
    "        super(MLP, self).__init__()\n",
    "        # 파라미터 정의\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.h1_size = h1_size\n",
    "        self.h2_size = h2_size  \n",
    "        \n",
    "        # 신경망 정의\n",
    "        # Sequential로 한꺼번에 묶어서 처리 할 수 있습니다.\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(self.input_size, self.h1_size, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.h1_size, self.h2_size, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.h2_size, self.output_size, bias=True)\n",
    "        )\n",
    " \n",
    "    def forward(self, x):\n",
    "        # 학습을 위해 텐서 shape을 바꿔줌\n",
    "        x = x.view(-1, 784)\n",
    "        x = self.layers(x.float())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c95352",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_mlp = MLP(input_size, output_size, h1_size, h2_size).to(device)\n",
    "print(my_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed886195",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(my_mlp.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd04d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 측정 데이터를 쌓을 dictionary\n",
    "performance = {'test_acc': [],'test_loss': []} \n",
    " \n",
    "for epoch in range(num_epochs):\n",
    "    # train\n",
    "    my_mlp.train()\n",
    "    # iter, image, label 반복문\n",
    "    for i, (x, y) in enumerate(dataloader):\n",
    "        # 모델에 데이터를 흘려 넣어줍니다.\n",
    "        x, y = x.to(device), y.to(device) \n",
    "        outputs = my_mlp(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        # optimizer의 변화도 버퍼(gradient buffer)를 0으로 설정하고, 무작위 값으로 역전파를 합니다.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # 가중치 업데이트 \n",
    "        optimizer.step()\n",
    " \n",
    "    # eval\n",
    "    y_pred, y_true = [], []\n",
    "    test_acc = 0\n",
    "    test_loss = 0\n",
    "    my_mlp.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            # Loss\n",
    "            outputs = my_mlp(x)   # 예측 label \n",
    "            loss = criterion(outputs, y)\n",
    "            test_loss += loss.item()\n",
    "            # Accuracy\n",
    "            y_true += list(y.cpu())   # 정답 label\n",
    "            y_pred += list(np.argmax(F.softmax(outputs).cpu(), axis=1)) # 소프트맥스 확률값에서 argmax로 제일 높은 인덱스를 뽑자\n",
    "            # sklearn의 정확도 측정 모듈 accuracy_score\n",
    "            acc = accuracy_score(y_true, y_pred)\n",
    "            test_acc += acc\n",
    " \n",
    "        # 누적된 통계치들에 batch를 반복한 횟수로 나누자\n",
    "        # 반복 횟수 = batch size 32로 잡았으면 testset size가 1만이니까 10k / 32 해서 313\n",
    "        test_acc = test_acc / len(test_loader.batch_sampler)\n",
    "        test_loss = test_loss / len(test_loader.batch_sampler)\n",
    " \n",
    "        performance[\"test_acc\"].append(test_acc)\n",
    "        performance[\"test_loss\"].append(test_loss)\n",
    " \n",
    "        # 성능 출력\n",
    "        if epoch % 5 == 0:\n",
    "            print(f\"Epoch: {epoch}, Test Loss: {test_loss:.5f}, Test Acc: {test_acc:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3081e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### 참고자료\n",
    "# * https://medium.com/biaslyai/pytorch-introduction-to-neural-network-feedforward-neural-network-model-e7231cff47cb\n",
    "# * https://www.kaggle.com/pinocookie/pytorch-simple-mlp\n",
    "# * https://tutorials.pytorch.kr/beginner/pytorch_with_examples.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ea3900",
   "metadata": {},
   "source": [
    "## 2번 과제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af956f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ea062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d66217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 32 * 32 * 3\n",
    "hidden_size = 128\n",
    "output_size = 10\n",
    "epoch_size = 50\n",
    "batch_size = 32\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c83c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657bdf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR 10 dataload\n",
    "# torchvision에서 여러 데이터를 제공한다. 만약 여기에 없으면 어쩔 수 없이 전처리를 다 해줘야 한다...\n",
    " \n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    " \n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    " \n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e588faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ced96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Batch Normalization\n",
    "# * 기존의 신경망 성능을 높이려는 시도들이 있어왔다. 대표적으로 input과 weight을 표준화시킨는 것.\n",
    "# * 그러나 문제는 hidden layer가 학습을 진행하면서 input distribution이 불안정해지게 된다.이를 Internal Covariate Shift\n",
    "# 라고 한다. 예를 들자면 가족오락관에서 귀마개를 끼고서하는 게임에서 사람을 거칠 수록 이상한 정답이 나오는 이치와 비슷하다고 함. 두 번째 가중치 값이 있다면 이 가중치는 이전 가중치 W1와 입력값에 따라 분포가 달라진다. 즉 W2가 불안정해진다.\n",
    "# \n",
    "# 1단계\n",
    "# * hidden input -> Batch Normalization -> Activation Funciton 의 구조를 가지면 된다.\n",
    "# * 보통 신경망은 mini batch로 학습하니 각 batch마다 표준화를 시킨다.\n",
    "# * batch_size = m일 때 \n",
    "# * $ {\\ μ_β} = {1 \\over m} * {\\sum_i}X_iW_i  $  (배치 평균)\n",
    "# * $ {\\ σ_β} = {1 \\over m} * {\\sum_i}(X_iW_i - μ_β$)2 (배치 표준편차)\n",
    "# * Activation $ a = f({\\ XW_i - μ_β \\over \\ σ_β})$\n",
    "# \n",
    "# 2단계\n",
    "# * 그러나 이 상태라면 grdient update에서 bias가 무시된다. sigmoid의 경우 활성화 결과값들이 sigmoid의 중간 선형부분에 위치하게 된다. 이런식으로 나쁜 Normalization을 고칠 감마와 베타라는 파라미터가 추가된다.\n",
    "# * $ {\\ a} = γ*({\\ XW_i - μ_β \\over \\ σ_β}) + β $ (이 친구도 마치 또 다른 신경망 같다. 얘네도 학습이 된다는 것)\n",
    "# * 이 값을 실제 신경망의 활성화 함수 입력으로 넣어주면 된다.\n",
    "# \n",
    "# Test단계\n",
    "# * 평가 시에는 학습 때 썼던 Batch별 통계값의 평균을 사용하거나 move average를 사용한다.\n",
    "# * $ \\hat{\\mu} \\gets \\alpha \\hat{\\mu} + (1-\\alpha) \\mu_{\\mathcal{B}}^{(i)}$ (알파는 momentum값으로 누구는 0.9를 사용하라고 하고, 파이토치에서는 default가 0.1이다.)\n",
    "# * $ \\hat{\\sigma} \\gets \\alpha \\hat{\\sigma} + (1-\\alpha) \\sigma_{\\mathcal{B}}^{(i)}$\n",
    "# \n",
    "# \n",
    "# 장점\n",
    "# \n",
    "# \n",
    "# 1.   bias 무시 X\n",
    "# 2.   hidden input 표준화\n",
    "# 3.   vanishing gradient 방지(actiation값을 적당한 크기로 유지)\n",
    "# 4.   interval covariate shift 방지\n",
    "# 5.   Dropout 안해도 됨. 같은 효과를 내기 떄문이라고 함\n",
    "# 6.   Learning Rate 크게 해도 됨 -> 시간단축\n",
    "# \n",
    "# \n",
    "# 텐서플로나 파이토치에서 쉽게 신경망에 추가할 수 있는 클래스를 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092de60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 드롭아웃\n",
    "# * 과적합을 막는 방법 중 하나\n",
    "# * 뉴런의 연결을 임의로 삭제\n",
    "# * 단, 테스트 시 모든 노드 사용함.\n",
    "# * 일정 확률로 강력한 뉴런이 무시될 수도 있다. 강력한 뉴런은 학습 데이터에 확신을 가지고 있다는 뜻이고, 그러한 뉴런이 많으면 일반화 능력이 떨어질 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32ff964",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) # input, output\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.num_flat_features(x))        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9329993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout\n",
    "class DropoutNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DropoutNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) # input, output\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ab4cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Normalization\n",
    "class BNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BNNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.bn1(self.linear1(x)))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610e8201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 골라서 해보자\n",
    "# net = Net().to(device)\n",
    "# net = DropoutNet().to(device)\n",
    "net = BNNet().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009a5b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a832376",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = {'test_acc': [],'test_loss': []} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbd04ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epoch_size):\n",
    "    net.train()\n",
    "    for i, (x, y) in enumerate(trainloader):\n",
    "        inputs, labels = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    total_label = 0\n",
    "    correct = 0\n",
    "    test_loss = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in testloader:\n",
    "            images, labels = x.to(device), y.to(device)\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total_label += labels.size(0)\n",
    " \n",
    "        test_acc = 100*correct/total_label\n",
    "        test_loss = test_loss / len(testloader.batch_sampler)\n",
    "        performance[\"test_acc\"].append(test_acc)\n",
    "        performance[\"test_loss\"].append(test_loss)\n",
    " \n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch: {epoch}, loss: {test_loss:.5f}, acc: {test_acc:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2bc261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "# 갓대웅님의 시각화 코드 참조 했습니다.\n",
    "fig = plt.figure()\n",
    "ax_acc = fig.add_subplot()\n",
    "ax_acc.plot(range(epoch_size), performance['test_acc'], label='acc', color='darkred')\n",
    "ax_acc.grid(linestyle='--', color='lavender')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Validation Accuracy(%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b41b193",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_loss = ax_acc.twinx()\n",
    "ax_loss.plot(range(epoch_size), performance['test_loss'], label='loss', color='darkblue')\n",
    "ax_loss.grid(linestyle='--', color='lavender')\n",
    "plt.ylabel('Validation Error')\n",
    "ax_loss.yaxis.tick_right()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991d8652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# * Basic NN\n",
    "# * hidden_size = 128, LR = 0.0001\n",
    "# \n",
    "# * 빠르게 과적합하는 모습을 확인할 수 있었습니다.\n",
    "# ![basic_128.png](attachment:basic_128.png)\n",
    "# \n",
    "# * Dropout\n",
    "# ![do_256.png](attachment:do_256.png)\n",
    "# \n",
    "# * Batch Normalize\n",
    "# ![bn_1.png](attachment:bn_1.png)\n",
    "# * 60까지 찍어주고 있습니다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
