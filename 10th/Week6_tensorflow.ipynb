{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5e1857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.chdir(\"C:/Users/kebee/Desktop/toobig/6주차 TensorFlow-Tutorials/6주차 TensorFlow-Tutorials\") \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4435f2db",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "import pandas as pd\n",
    "doc = pd.read_csv(\"white.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74596b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 보기\n",
    "doc.head(6)\n",
    "\n",
    "type(doc.y)\n",
    " \n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cca43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#str로 레이블 타입 바꾸기\n",
    "doc.y= doc.y.astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6182d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#레이블 벨런스 및 수 확인 \n",
    "doc.y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a91795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#레이블 행렬 구조 확인 \n",
    "doc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb883f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "#변수와 레이블 분리 \n",
    "X_data=doc.iloc[:,0:11]\n",
    "y_data = doc.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4bfe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#레이블 원핫 인코딩 적용 \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "y_data1 = y_data.values\n",
    "y_data1 = ohe.fit_transform(y_data1.reshape(-1, 1)).toarray()\n",
    "y_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7137d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training데이터와 test데이터 나누기 \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data, y_data1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6e6e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 1.  sigmoid 함수이용, GradientDescentOptimizer \n",
    " \n",
    "X = tf.placeholder(tf.float32,[None, 11])\n",
    "Y = tf.placeholder(tf.float32,[None, 7])\n",
    " \n",
    "#초기값 \n",
    "W1 = tf.Variable(tf.random_normal([11,7],stddev=0.01))\n",
    "b1 = tf.Variable(tf.zeros([7]))\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    " \n",
    "#cross entropy cost function 사용\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=hypothesis, labels=Y))\n",
    "#GradientDescent optimizer사용 \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    " \n",
    "# 예측값 H(X) > 0.5 이면  true, 아니면 false\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "# 0이나 1의 값을 트레이닝 횟수만큼 평균치 계산\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    " \n",
    "#훈련 \n",
    "init = tf.global_variables_initializer()\n",
    "sess= tf.Session()\n",
    "sess.run(init)\n",
    " \n",
    "#10000번 돌리고 1000번당 출력 \n",
    "for step in range(10001):\n",
    "    cost_val,  _ = sess.run([cost, optimizer], feed_dict={X:X_train, Y:Y_train})\n",
    "    if step % 1000 == 0:\n",
    "        print(step, '\\t', cost_val)\n",
    "            \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2368342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#정확도 27%\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "is_correct = tf.equal(tf.argmax(predicted,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct,tf.float32))\n",
    "print('정확도 : ', sess.run(accuracy, feed_dict={X: X_test, Y: Y_test}))\n",
    " \n",
    "\n",
    "# In[152]:\n",
    " \n",
    "\n",
    "# 2.  Layer 확대와 Node 수변경, sigmoid 함수이용, Adamoptimizer \n",
    " \n",
    "X = tf.placeholder(tf.float32,[None, 11])\n",
    "Y = tf.placeholder(tf.float32,[None, 7])\n",
    " \n",
    "#layer수 3개 \n",
    "W1 = tf.Variable(tf.random_normal([11,10],stddev=0.01))\n",
    "b1 = tf.Variable(tf.zeros([10]))\n",
    "h1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    " \n",
    "W2 = tf.Variable(tf.random_normal([10,10],stddev=0.01))\n",
    "b2 = tf.Variable(tf.zeros([10]))\n",
    "h2 = tf.sigmoid(tf.matmul(h1, W2) + b2)\n",
    " \n",
    "W3 = tf.Variable(tf.random_normal([10,7],stddev=0.01))\n",
    "b3 = tf.Variable(tf.zeros([7]))\n",
    "hypothesis = tf.matmul(h2, W3) + b3\n",
    " \n",
    "\n",
    "#cross entropy cost function 사용\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=hypothesis, labels=Y))\n",
    "# Adam사용 \n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.1).minimize(cost)\n",
    " \n",
    "# 예측값 H(X) > 0.5 is true, else false\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "# 0이나 1의 값을 트레이닝 횟수만큼 평균치 계산\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    " \n",
    "#훈련\n",
    "init = tf.global_variables_initializer()\n",
    "sess= tf.Session()\n",
    "sess.run(init)\n",
    " \n",
    "#10000번 돌리고 1000번당 출력 \n",
    " \n",
    "#실행 및 출력\n",
    " \n",
    "for step in range(10001):\n",
    "    cost_val,  _ = sess.run([cost, optimizer], feed_dict={X:X_train, Y:Y_train})\n",
    "    if step % 1000 == 0:\n",
    "        print(step, '\\t', cost_val)\n",
    "            \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2979e55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "is_correct = tf.equal(tf.argmax(predicted,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct,tf.float32))\n",
    "print('정확도 : ', sess.run(accuracy, feed_dict={X: X_test, Y: Y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508b32e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Weight 초기화하는Xavier 알고리즘, Layer 확대와Node 수변경, Adamoptimizer, relu 함수이용 \n",
    " \n",
    "tf.reset_default_graph()\n",
    " \n",
    "#layer수 3개 \n",
    " \n",
    "X = tf.placeholder(tf.float32,[None, 11])\n",
    "Y = tf.placeholder(tf.float32,[None, 7])\n",
    " \n",
    "W1 = tf.get_variable(\"W1\",shape = [11,10],initializer = tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.zeros([10]))\n",
    "h1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    " \n",
    "W2 = tf.get_variable(\"W2\",shape = [10,10],initializer = tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.zeros([10]))\n",
    "h2 = tf.nn.relu(tf.matmul(h1, W2) + b2)\n",
    " \n",
    "W3 = tf.get_variable(\"W3\",shape = [10,7] ,initializer = tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.zeros([7]))\n",
    "hypothesis = tf.matmul(h2, W3) + b3\n",
    " \n",
    "#cross entropy cost function 사용\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7655afb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=hypothesis, labels=Y))\n",
    "#adam optimizer 사용 \n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# 예측값 H(X) > 0.5 is true, else false\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "# 0이나 1의 값을 트레이닝 횟수만큼 평균치 계산\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    " \n",
    "#훈련\n",
    "init = tf.global_variables_initializer()\n",
    "sess= tf.Session()\n",
    "sess.run(init)\n",
    " \n",
    "#실행 및 출력\n",
    "for step in range(10001):\n",
    "    cost_val,  _ = sess.run([cost, optimizer], feed_dict={X:X_train, Y:Y_train})\n",
    "    if step % 1000 == 0:\n",
    "        print(step, '\\t', cost_val)\n",
    "            \n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20edfe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "is_correct = tf.equal(tf.argmax(predicted,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct,tf.float32))\n",
    "print('정확도 : ', sess.run(accuracy, feed_dict={X: X_test, Y: Y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e8f7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Dropout, sigmoid 함수이용, GradientDescentOptimizer, Layer 확대와 Node 수변경 \n",
    " \n",
    "X = tf.placeholder(tf.float32,[None, 11])\n",
    "Y = tf.placeholder(tf.float32,[None, 7])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    " \n",
    "#layer수 3개\n",
    "W1 = tf.Variable(tf.random_normal([11,30],stddev=0.01))\n",
    "b1 = tf.Variable(tf.zeros([30]))\n",
    "h1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "h1 = tf.nn.dropout(h1, keep_prob)\n",
    " \n",
    " \n",
    " \n",
    "W2 = tf.Variable(tf.random_normal([30,256],stddev=0.01))\n",
    "b2 = tf.Variable(tf.zeros([256]))\n",
    "h2 = tf.sigmoid(tf.matmul(h1, W2) + b2)\n",
    "h2 = tf.nn.dropout(h2, keep_prob)\n",
    "\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256,7],stddev=0.01))\n",
    "b3 = tf.Variable(tf.zeros([7]))\n",
    "hypothesis = tf.matmul(h2, W3) + b3\n",
    " \n",
    "#cross entropy cost function 사용\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=hypothesis, labels=Y))\n",
    "#GradientDescent optimizer사용 \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    " \n",
    "#훈련\n",
    "init = tf.global_variables_initializer()\n",
    "sess= tf.Session()\n",
    "sess.run(init)\n",
    " \n",
    "#실행 및 출력\n",
    "#드롭아웃 0.8 확률로 적용 \n",
    "for step in range(10001):\n",
    "    cost_val,  _ = sess.run([cost, optimizer], feed_dict={X:X_train, Y:Y_train,keep_prob:0.8})\n",
    "    if step % 1000 == 0:\n",
    "        print(step, '\\t', cost_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3e0fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "is_correct = tf.equal(tf.argmax(predicted,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct,tf.float32))\n",
    "#테스트할 때는 드롭아웃을 적용하지 않는다 \n",
    "print('정확도 : ', sess.run(accuracy, feed_dict={X: X_test, Y: Y_test,keep_prob:1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a45027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Dropout, relu 함수이용, Layer 확대와Node 수변경, Adamoptimizer, Weight 초기화하는Xavier 알고리즘이용 \n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    " \n",
    "#layer 4개 \n",
    "X = tf.placeholder(tf.float32,[None, 11])\n",
    "Y = tf.placeholder(tf.float32,[None, 7])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    " \n",
    "#Weight 초기화하는Xavier 알고리즘\n",
    "W1 = tf.get_variable(\"W1\",shape = [11,20],initializer = tf.contrib.layers.xavier_initializer())\n",
    "#bias담기\n",
    "b1 = tf.Variable(tf.zeros([20]))\n",
    "#relu함수 \n",
    "h1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "#dropout적용\n",
    "h1 = tf.nn.dropout(h1, keep_prob)\n",
    "\n",
    "\n",
    "#Weight 초기화하는Xavier 알고리즘\n",
    " \n",
    "W2 = tf.get_variable(\"W2\",shape = [20,80],initializer = tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.zeros([80]))\n",
    "h2 = tf.nn.relu(tf.matmul(h1, W2) + b2)\n",
    "h2 = tf.nn.dropout(h2, keep_prob)\n",
    "\n",
    "\n",
    "W3 = tf.get_variable(\"W3\",shape = [80,30] ,initializer = tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.zeros([30]))\n",
    "h3 = tf.nn.relu(tf.matmul(h2, W3) + b3)\n",
    "h3 = tf.nn.dropout(h3, keep_prob)\n",
    " \n",
    "W4 = tf.get_variable(\"W4\",shape = [30,7] ,initializer = tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.zeros([7]))\n",
    "h4 = tf.nn.dropout(h3, keep_prob)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hypothesis = tf.matmul(h4, W4) + b4\n",
    " \n",
    "#cross entropy cost function 사용\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=hypothesis, labels=Y))\n",
    "#adam optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.1).minimize(cost)\n",
    " \n",
    "#실행 및 출력\n",
    " \n",
    "init = tf.global_variables_initializer()\n",
    "sess= tf.Session()\n",
    "sess.run(init)\n",
    " \n",
    "for step in range(10001):\n",
    "    cost_val,  _ = sess.run([cost, optimizer], feed_dict={X:X_train, Y:Y_train,keep_prob:0.8})\n",
    "    if step % 1000 == 0:\n",
    "        print(step, '\\t', cost_val)\n",
    "        \n",
    "\n",
    "# 테스트 \n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "is_correct = tf.equal(tf.argmax(predicted,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct,tf.float32))\n",
    "print('정확도 : ', sess.run(accuracy, feed_dict={X: X_test, Y: Y_test,keep_prob:1}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
