{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150093cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Week08 Assignment: CNN with Keras\n",
    "\n",
    "# Getting Started\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation,Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, ZeroPadding2D, BatchNormalization, Add, AveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d9698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 데이터 편집\n",
    "K.set_image_data_format('channels_last')\n",
    "path = 'C:/Users/YY/Documents/Data/Dataset/train'\n",
    "\n",
    "# 데이터 늘리기(Rock 데이터 수)\n",
    "# Augmentation tool 선언\n",
    "image_gen = ImageDataGenerator(\n",
    "#featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=.15,\n",
    "    height_shift_range=.15,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42545eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(generator):\n",
    "\"\"\"\n",
    "    :param generator: ImageDataGenerator\n",
    "    :return: 변형된 10배수의 사진들이 저장된다.\n",
    "    \"\"\"\n",
    "    classes_list = os.listdir(path)\n",
    "\n",
    "for class_name in classes_list:\n",
    "        img_list = os.listdir(os.path.join(path, class_name))\n",
    "\n",
    "for img_name in img_list:\n",
    "# 각각의 이미지의 path name을 정의하고 로드 후 array로 변환한다.\n",
    "            img_path_name = os.path.join(path, class_name, img_name)\n",
    "            img = image.load_img(img_path_name)\n",
    "            img = image.img_to_array(img)\n",
    "\n",
    "# generator에 넣기 위해 rank를 4로 맞춰준다.\n",
    "            img = img.reshape((1,) + img.shape)\n",
    "\n",
    "            i = 0\n",
    "\n",
    "            for batch in generator.flow(img, batch_size=1, save_to_dir=os.path.join(path, class_name),\n",
    "                save_prefix=class_name, save_format='jpg'):\n",
    "# 각각의 이미지에 대해 10번만 수행한다.\n",
    "                i += 1\n",
    "                if i > 10:\n",
    "break\n",
    "\n",
    "augment(image_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0013c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 케라스 loading 메서드를 쓰는 것이 속도가 훨씬 좋습니다.\n",
    "def LoadPreprocess(path):\n",
    "\n",
    "    dataset = []\n",
    "    y = []\n",
    "\n",
    "# classes_list: path내에 있는 폴더명을 리스트로 만듦\n",
    "    classes_list = os.listdir(path)\n",
    "\n",
    "for class_number, class_name in enumerate(classes_list):\n",
    "# img_list: 'rock.jpg'과 같은 이미지명을 담은 리스트임\n",
    "        img_list = os.listdir(os.path.join(path, class_name))\n",
    "\n",
    "for img_number, img_name in enumerate(img_list):\n",
    "# 각각의 이미지의 path name을 정의한다.\n",
    "            img_path_name = os.path.join(path, class_name, img_name)\n",
    "\n",
    "# 이미지 로드\n",
    "            img = image.load_img(img_path_name, target_size=(64, 64))\n",
    "\n",
    "# 이미지를 np.array로 바꿔줌\n",
    "            # shape은 (height, width, channels) = (128, 128, 3)\n",
    "            img_input = image.img_to_array(img)\n",
    "            dataset.append(img_input)\n",
    "            y.append(class_number)\n",
    "\n",
    "    dataset = np.array(dataset)\n",
    "    y = np.array(y)\n",
    "    Y = np.eye(3)[y.astype(int)]\n",
    "    dataset = dataset.astype('float64')\n",
    "    dataset /= 255\n",
    "    return dataset, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc22a59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Block 및 모델 정의\n",
    "# 모델은 Resnet50\n",
    "# 효과적인 학습이 가능할 뿐만 아니라 VGG나 inception 계열보다 학습할 Parameter의 양도 적음\n",
    "# 먼저 2종류의 block을 정의함\n",
    "def Identity_block(X, kernel, filters, stage, block):\n",
    "\"\"\"\n",
    "    X -- 인풋 텐서 (examples, height_prev, width_prev, channel_prev)\n",
    "    kernel -- 커널 사이즈를 나타내는 정수(중간에 한 번 축소를 위해 정의)\n",
    "    filters -- CONV layer의 필터 수를 담은 리스트\n",
    "    stage -- 단계를 나타내는 정수\n",
    "    block -- 단계 내 몇 번째 블록인지 나타내는 문자열\n",
    "\n",
    "    Returns: X -- output of the identity block, 텐서: (height, width, channel)\n",
    "    \"\"\"\n",
    "    # Setting\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    F1, F2, F3 = filters\n",
    "    X_shortcut = X\n",
    "\n",
    "# 1st Component\n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base+'2a',\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "# 2nd Compoenent\n",
    "    X = Conv2D(filters=F2, kernel_size=(kernel, kernel), strides=(1, 1), padding='same', name=conv_name_base+'2b',\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "# 3rd Component\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base+'2c',\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "\n",
    "# 위에서 저장한 X_shortcut을 다시 추가해준다.\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70c9f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv_block(X, kernel, filters, stage, block, s=2):\n",
    "\"\"\"\n",
    "    s -- strides를 나타냄(중간에 한 번 축소를 위해 정의)\n",
    "\n",
    "    Returns: X -- output of the convolutional block, 텐서: (height, width, channel)\n",
    "    \"\"\"\n",
    "    # Setting\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    F1, F2, F3 = filters\n",
    "    X_shortcut = X\n",
    "\n",
    "# 1st Component\n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), name=conv_name_base+'2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base+'2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "# 2nd Compoenent\n",
    "    X = Conv2D(filters=F2, kernel_size=(kernel, kernel), strides=(1, 1), name=conv_name_base+'2b', padding='same', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base+'2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "# 3rd Component\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), name=conv_name_base+'2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base+'2c')(X)\n",
    "\n",
    "# Shortcut에도 1X1 conv를 적용해 준다.\n",
    "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), name=conv_name_base+'1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base+'1')(X_shortcut)\n",
    "\n",
    "# 위에서 저장한 X_shortcut을 다시 추가해준다.\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a531508",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(Model):\n",
    "def __init__(self, in_shape=(128, 128, 3), classes=3):\n",
    "self.in_shape = in_shape\n",
    "self.classes = classes\n",
    "self.BuildModel()\n",
    "super().__init__(self.X_input, self.Y)\n",
    "self.compile()\n",
    "\n",
    "\n",
    "def BuildModel(self):\n",
    "        in_shape = self.in_shape\n",
    "        classes = self.classes\n",
    "        X_input = Input(shape=in_shape)\n",
    "        X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "# Stage 1\n",
    "        X = Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2), name='conv1',\n",
    "                   kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "        X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "        X = Activation('relu')(X)\n",
    "        X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "# Stage 2\n",
    "        X = Conv_block(X, kernel=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
    "        X = Identity_block(X, kernel=3, filters=[64, 64, 256], stage=2, block='b')\n",
    "        X = Identity_block(X, kernel=3, filters=[64, 64, 256], stage=2, block='c')\n",
    "\n",
    "# Stage 3\n",
    "        X = Conv_block(X, kernel=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
    "        X = Identity_block(X, kernel=3, filters=[128, 128, 512], stage=3, block='b')\n",
    "        X = Identity_block(X, kernel=3, filters=[128, 128, 512], stage=3, block='c')\n",
    "        X = Identity_block(X, kernel=3, filters=[128, 128, 512], stage=3, block='d')\n",
    "\n",
    "# Stage 4\n",
    "        X = Conv_block(X, kernel=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n",
    "        X = Identity_block(X, kernel=3, filters=[256, 256, 1024], stage=4, block='b')\n",
    "        X = Identity_block(X, kernel=3, filters=[256, 256, 1024], stage=4, block='c')\n",
    "        X = Identity_block(X, kernel=3, filters=[256, 256, 1024], stage=4, block='d')\n",
    "        X = Identity_block(X, kernel=3, filters=[256, 256, 1024], stage=4, block='e')\n",
    "        X = Identity_block(X, kernel=3, filters=[256, 256, 1024], stage=4, block='kernel')\n",
    "\n",
    "# Stage 5\n",
    "        X = Conv_block(X, kernel=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n",
    "        X = Identity_block(X, kernel=3, filters=[512, 512, 2048], stage=5, block='b')\n",
    "        X = Identity_block(X, kernel=3, filters=[512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "        X = AveragePooling2D(pool_size=(2, 2), strides=None, padding='valid', name='avg_pool')(X)\n",
    "        X = Flatten()(X)\n",
    "        Y = Dense(units=classes, activation='softmax', name='fc' + str(classes), kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "\n",
    "self.X_input, self.Y = X_input, Y\n",
    "\n",
    "# Create model\n",
    "        # model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
    "\n",
    "\n",
    "    def compile(self):\n",
    "        Model.compile(self, optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5f7b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 학습\n",
    "dataset, Y = LoadPreprocess(path=path)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(dataset, Y, test_size=0.1, stratify=Y, random_state=0)\n",
    "\n",
    "print(\"X shape: \", X_train.shape)\n",
    "print(\"Y shape: \", Y_train.shape)\n",
    "\n",
    "Resnet = CNN(in_shape=(64, 64, 3), classes=3)\n",
    "# Resnet.summary()\n",
    "Resnet.fit(X_train, Y_train, batch_size=32, epochs=5, validation_data=(X_val, Y_val), callbacks=[EarlyStopping(patience=10)])\n",
    "\n",
    "\n",
    "# 결과: Epoch5가 끝난 이후의 Validation Accuracy는 100%\n",
    "\n",
    "\n",
    "\n",
    "# Test: 70개의 새로운 이미지\n",
    "test_path = path = 'C:/Users/YY/Documents/Data/Dataset/test'\n",
    "X_test, Y_test = LoadPreprocess(path=test_path)\n",
    "print(\"X shape: \", X_test.shape)\n",
    "print(\"Y shape: \", Y_test.shape)\n",
    "Y_predicted = Resnet.predict(X_test, batch_size=32)\n",
    "P = np.argmax(Y_predicted, axis=1)\n",
    "T = np.argmax(Y_test, axis=1)\n",
    "np.sum(P == T) / 70\n",
    "\n",
    "# 정확도는 100%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
