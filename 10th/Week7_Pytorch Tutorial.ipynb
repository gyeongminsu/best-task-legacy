{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89f9e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f81193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 데이터 로딩\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5236e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Config\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "# Hyper parameters\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b65775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Build the model (1) -- 큰 의미 없는 모델\n",
    "class CNN(nn.Module):\n",
    "def __init__(self, num_classes=10):\n",
    "super(CNN, self).__init__()\n",
    "self.block1 = nn.Sequential(\n",
    "# kernel_size = (5X5)\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(num_features=16, momentum=0.1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(num_features=16, momentum=0.1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(num_features=32, momentum=0.1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(num_features=32, momentum=0.1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "self.fc = nn.Linear(8*8*32, num_classes)\n",
    "\n",
    "def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.fc(x)\n",
    "return output\n",
    "\n",
    "# model = CNN(num_classes=num_classes).to(device)\n",
    "# 이후 아래 코드를 이용하여 학습을 진행한 결과 74%의 정확도에 머물렀다. (Epochs=10)\n",
    "\n",
    "\n",
    "#3 Build the model (2) -- ResNet 이용\n",
    "class ConvBlock(nn.Module):\n",
    "\n",
    "def __init__(self, in_channel, out_channel, stride=1):\n",
    "super(ConvBlock, self).__init__()\n",
    "# Resnet50의 경우 block 내에 conv+bn 세트가 3개인데 simple하게 2개만 쌓았다.\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "self.bn1 = nn.BatchNorm2d(num_features=out_channel)\n",
    "self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "self.bn2 = nn.BatchNorm2d(num_features=out_channel)\n",
    "\n",
    "# Skip connection을 위해 shortcut을 생성한다.\n",
    "        # 이 Block은 Identity Block이 아니라 Convolutional Block으로 설계하였기 때문에\n",
    "        # 아래처럼 작은 1X1 Convolutional Layer를 추가한다.\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "# 첫 MakeLayer에서는 아래와 같은 shortcut을 넣지 않는다는 의미이다.\n",
    "        # 그 다음부터 channel이 확장되거나 stride를 1보다 크게 하여 (점점 깊어지면서) 정보를 압축할 때 shortcut을 이용하겠다는 의미.\n",
    "        if stride != 1 or in_channel != out_channel:\n",
    "self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channel)\n",
    "            )\n",
    "\n",
    "def forward(self, x):\n",
    "# 2번의 Convolutional Layer + Batch Norm Layer를 통과한 뒤,\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "\n",
    "# 활성화 함수를 적용하기 전에 shortcut을 더해준다.\n",
    "        out = out + self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        out = out.cuda()\n",
    "return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0cfebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "def __init__(self, block, num_blocks, num_classes=10):\n",
    "super(ResNet, self).__init__()\n",
    "self.in_channel = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "self.bn1 = nn.BatchNorm2d(num_features=64)\n",
    "self.layer1 = self.MakeLayer(block=block, out_channel=64, num_blocks=num_blocks[0], stride=1)\n",
    "self.layer2 = self.MakeLayer(block=block, out_channel=128, num_blocks=num_blocks[1], stride=2)\n",
    "self.layer3 = self.MakeLayer(block=block, out_channel=256, num_blocks=num_blocks[2], stride=2)\n",
    "self.layer4 = self.MakeLayer(block=block, out_channel=512, num_blocks=num_blocks[3], stride=2)\n",
    "self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "def MakeLayer(self, block, out_channel, num_blocks, stride):\n",
    "# Convblock으로 형성한 Layer들을 nn.Sequential을 이용하여 구성한다.\n",
    "        # stride가 1일 경우 아래 strides = [1, 1]\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "\n",
    "# Block 형성이 끝난 이후에는 채널 확장을 위해 self.in_channel = out_channel로 확장된 채널 수로 업데이트를 해준다.\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channel, out_channel, stride))\n",
    "self.in_channel = out_channel\n",
    "return nn.Sequential(*layers)\n",
    "\n",
    "def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        out = out.cuda()\n",
    "return out\n",
    "\n",
    "\n",
    "learning_rate = 0.01\n",
    "# 0.001로 낮춤\n",
    "\n",
    "model = ResNet(block=ConvBlock, num_blocks=[2,2,2,2], num_classes=10)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "    model = torch.nn.DataParallel(model, device_ids=range(torch.cuda.device_count()))\n",
    "\n",
    "\n",
    "#4 Train the network\n",
    "def Train(epochs=1):\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "# get the inputs\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "# zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "# forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "# print statistics\n",
    "            # item(): retrieve a single value\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            print_op = 500\n",
    "\n",
    "            if (i + 1) % print_op == 0:    # print every `print_op` mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / print_op))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "\n",
    "Train(epochs=15)\n",
    "# learning_rate = 0.01로 Epoch 15까지\n",
    "# learning_rate = 0.001로 Epoch 5 추가\n",
    "\n",
    "\n",
    "#5 Test\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "class_correct = list(0.0 for i in range(10))\n",
    "class_total = list(0.0 for i in range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c190b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "for data in testloader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1) # prediction\n",
    "        c = (predicted == labels).squeeze()\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "# torch.save(model, 'C:/Users/YY/Documents/Winter Project/Spring/epoch20.pt')\n",
    "# Resnet18: Test 정확도는 78% 수준(과적합 됨)\n",
    "# Data Augmentation을 통해 더욱 Robust한 모델을 구성할 수 있을 것"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
